{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import gc\n",
    "import klib\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Paths to datasets\n",
    "train_path = r\"C:\\Users\\paulo\\OneDrive\\Documents\\kaggle_competition_2_datasets\\train.csv\"\n",
    "test_path = r\"C:\\Users\\paulo\\OneDrive\\Documents\\kaggle_competition_2_datasets\\test.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def import_data(path, index_col=None):\n",
    "    \"\"\"Import data from a CSV file and optimize memory usage.\"\"\"\n",
    "    df = pd.read_csv(path, index_col=index_col)\n",
    "    return reduce_mem_usage(df)\n",
    "\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\"Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.\"\"\"\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if isinstance(col_type, pd.IntervalDtype):\n",
    "            continue\n",
    "\n",
    "        if str(col_type)[:3] == 'int':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                df[col] = df[col].astype(np.int8)\n",
    "            elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                df[col] = df[col].astype(np.int16)\n",
    "            elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                df[col] = df[col].astype(np.int32)\n",
    "            elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                df[col] = df[col].astype(np.int64)  \n",
    "        elif str(col_type)[:5] == 'float':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "            else:\n",
    "                df[col] = df[col].astype(np.float64)\n",
    "    return df\n",
    "\n",
    "def feature_engineering(df):\n",
    "    \"\"\"Feature engineering on the dataset.\"\"\"\n",
    "    # Binning age and converting to categorical labels instead of intervals\n",
    "    age_bins = pd.cut(df['Age'], bins=7, labels=False)\n",
    "    df['Age_Type'] = age_bins\n",
    "    df['Vehicle_Age'] = df['Vehicle_Age'].astype('category').cat.codes\n",
    "    df['Vehicle_Damage'] = df['Vehicle_Damage'].astype('category').cat.codes\n",
    "    df['Previously_Insured'] = df['Previously_Insured'].astype('category').cat.codes\n",
    "\n",
    "    df['Age_x_Vehicle_Age'] = df['Age_Type'] * df['Vehicle_Age']\n",
    "    df['Age_x_Vehicle_Damage'] = df['Age_Type'] * df['Vehicle_Damage']\n",
    "    df['Age_x_Previously_Insured'] = df['Age_Type'] * df['Previously_Insured']\n",
    "\n",
    "    fac_pre = ['Policy_Sales_Channel', 'Vehicle_Damage', 'Annual_Premium', 'Vintage', 'Age_Type']\n",
    "    col_pre = []\n",
    "    for i in fac_pre:\n",
    "        df['Previously_Insured_x_' + i] = pd.factorize(df['Previously_Insured'].astype(str) + df[i].astype(str))[0]\n",
    "        col_pre.append('Previously_Insured_x_' + i)\n",
    "\n",
    "    fac_pro = fac_pre[1:]\n",
    "    col_pro = []\n",
    "    for i in fac_pro:\n",
    "        df['Policy_Sales_Channel_x_' + i] = pd.factorize(df['Policy_Sales_Channel'].astype(str) + df[i].astype(str))[0]\n",
    "        col_pro.append('Policy_Sales_Channel_x_' + i)\n",
    "    return df, col_pre, col_pro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load and optimize data\n",
    "train_df = import_data(train_path, index_col='id')\n",
    "test_df = import_data(test_path, index_col='id')\n",
    "\n",
    "# Combine train and test datasets for consistent transformation\n",
    "full_df = pd.concat([train_df, test_df], axis=0)\n",
    "\n",
    "# Convert columns to category type\n",
    "less = ['Gender', 'Vehicle_Age', 'Vehicle_Damage', 'Policy_Sales_Channel']\n",
    "for col in less:\n",
    "    full_df[col] = full_df[col].astype('category')\n",
    "\n",
    "# Apply feature engineering to the combined dataset\n",
    "full_df, col_pre, col_pro = feature_engineering(full_df)\n",
    "\n",
    "# Split back into train and test sets\n",
    "train_df = full_df.iloc[:len(train_df), :]\n",
    "test_df = full_df.iloc[len(train_df):, :]\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "X = train_df.drop('Response', axis=1)\n",
    "y = train_df['Response']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1995"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the ColumnTransformer\n",
    "coltrans = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(sparse_output=False, dtype=np.float32), ['Gender', 'Vehicle_Damage']),\n",
    "        ('minmax', MinMaxScaler(), ['Age', 'Region_Code', 'Previously_Insured', 'Policy_Sales_Channel', 'Vintage']),\n",
    "        ('ordinal', OrdinalEncoder(categories=[[0, 1, 2]], dtype=np.float32), ['Vehicle_Age']),\n",
    "        ('robust', RobustScaler(), ['Annual_Premium']),\n",
    "        ('standard', StandardScaler(), ['Age_Type', 'Age_x_Vehicle_Age', 'Age_x_Vehicle_Damage', 'Age_x_Previously_Insured']),\n",
    "        ('standard_2', StandardScaler(), col_pre + col_pro),\n",
    "    ],\n",
    "    remainder='passthrough'  # Keeps columns not specified in transformers\n",
    ")\n",
    "\n",
    "# Fit the transformer on the training data and transform both training and validation sets\n",
    "X_train = coltrans.fit_transform(X_train)\n",
    "X_valid = coltrans.transform(X_valid)\n",
    "test_df = coltrans.transform(test_df.drop('Response', axis=1))\n",
    "\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = len(train_df[train_df['Response'] == 0]) / len(train_df[train_df['Response'] == 1])\n",
    "\n",
    "class_weights = {0: 1, 1: ratio}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StratifiedKFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m skfold \u001b[38;5;241m=\u001b[39m \u001b[43mStratifiedKFold\u001b[49m(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'StratifiedKFold' is not defined"
     ]
    }
   ],
   "source": [
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define CatBoost parameters\n",
    "cat_params = {\n",
    "    'loss_function': 'Logloss',\n",
    "    'eval_metric': 'AUC',\n",
    "    'class_names': [0, 1],\n",
    "    'learning_rate': 0.05,\n",
    "    'iterations': 5000,\n",
    "    'depth': 9,\n",
    "    'random_strength': 0,\n",
    "    'l2_leaf_reg': 0.5,\n",
    "    'task_type': 'GPU',  # Ensure your environment supports GPU\n",
    "    'allow_writing_files': False,\n",
    "    'verbose': 100,\n",
    "    'class_weights': class_weights \n",
    "    # 'thread_count': -1\n",
    "}\n",
    "\n",
    "# Initialize lists to store out-of-fold predictions, models, and AUC scores\n",
    "cat_preds = []\n",
    "cat_aucs = []\n",
    "\n",
    "test_pool = Pool(test_df.astype(str), cat_features=X.columns.values)\n",
    "\n",
    "# CatBoost Model\n",
    "for fold, (train_idx, test_idx) in enumerate(skfold.split(X, y)):\n",
    "    \n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_valid, y_valid = X.iloc[test_idx], y.iloc[test_idx]\n",
    "    \n",
    "    train_pool = Pool(X_train.astype(str), y_train, cat_features=X.columns.values)\n",
    "    valid_pool = Pool(X_valid.astype(str), y_valid, cat_features=X.columns.values)\n",
    "    \n",
    "    model = CatBoostClassifier(**cat_params)\n",
    "    model.fit(train_pool, eval_set=valid_pool, early_stopping_rounds=50, verbose=100)\n",
    "    \n",
    "    valid_preds = model.predict_proba(X_valid.astype(str))[:, 1]\n",
    "    auc_score = roc_auc_score(y_valid, valid_preds)\n",
    "    cat_aucs.append(auc_score)\n",
    "    logging.info(f\"Validation AUC score for fold {fold + 1}: {auc_score:.6f}\")\n",
    "    \n",
    "    test_pred = model.predict_proba(test_pool)[:, 1]\n",
    "    cat_preds.append(test_pred)\n",
    "    \n",
    "    # Clear memory\n",
    "    del X_train, y_train, X_valid, y_valid, train_pool, valid_pool, model\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "# Calculate overall AUC score for CatBoost\n",
    "auc_mean_cat = np.mean(cat_aucs)\n",
    "auc_std_cat = np.std(cat_aucs)\n",
    "\n",
    "# Average the predictions from each fold for CatBoost\n",
    "test_pred_cat = np.mean(cat_preds, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Reimport the test_df to get the original index\n",
    "test_df = import_data(test_path, index_col='id')\n",
    "\n",
    "# Create a submission DataFrame using the original test index\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df.index,\n",
    "    'Response': test_pred_cat\n",
    "})\n",
    "\n",
    "# Save the submission DataFrame to a CSV file\n",
    "submission.to_csv('submission_cat.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
