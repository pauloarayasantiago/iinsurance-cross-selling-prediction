{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import gc\n","from sklearn.model_selection import StratifiedKFold, train_test_split\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler, RobustScaler\n","from sklearn.compose import ColumnTransformer\n","from sklearn.metrics import roc_auc_score\n","import xgboost as xgb\n","import joblib\n","\n","# Paths to datasets\n","train_path = r\"C:\\Users\\paulo\\OneDrive\\Documents\\kaggle_competition_2_datasets\\train.csv\"\n","test_path = r\"C:\\Users\\paulo\\OneDrive\\Documents\\kaggle_competition_2_datasets\\test.csv\"\n","\n","def import_data(path, index_col=None):\n","    \"\"\"Import data from a CSV file and optimize memory usage.\"\"\"\n","    df = pd.read_csv(path, index_col=index_col)\n","    return reduce_mem_usage(df)\n","\n","def reduce_mem_usage(df):\n","    \"\"\"Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.\"\"\"\n","    for col in df.columns:\n","        col_type = df[col].dtype\n","        if isinstance(col_type, pd.IntervalDtype):\n","            continue\n","\n","        if str(col_type)[:3] == 'int':\n","            c_min = df[col].min()\n","            c_max = df[col].max()\n","            if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n","                df[col] = df[col].astype(np.int8)\n","            elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n","                df[col] = df[col].astype(np.int16)\n","            elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n","                df[col] = df[col].astype(np.int32)\n","            elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n","                df[col] = df[col].astype(np.int64)  \n","        elif str(col_type)[:5] == 'float':\n","            c_min = df[col].min()\n","            c_max = df[col].max()\n","            if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n","                df[col] = df[col].astype(np.float32)\n","            else:\n","                df[col] = df[col].astype(np.float64)\n","    return df\n","\n","def feature_engineering(df):\n","    \"\"\"Feature engineering on the dataset.\"\"\"\n","    # Binning age and converting to categorical labels instead of intervals\n","    age_bins = pd.cut(df['Age'], bins=7, labels=False)\n","    df['Age_Type'] = age_bins\n","    df['Vehicle_Age'] = df['Vehicle_Age'].astype('category').cat.codes\n","    df['Vehicle_Damage'] = df['Vehicle_Damage'].astype('category').cat.codes\n","    df['Previously_Insured'] = df['Previously_Insured'].astype('category').cat.codes\n","\n","    df['Age_x_Vehicle_Age'] = df['Age_Type'] * df['Vehicle_Age']\n","    df['Age_x_Vehicle_Damage'] = df['Age_Type'] * df['Vehicle_Damage']\n","    df['Age_x_Previously_Insured'] = df['Age_Type'] * df['Previously_Insured']\n","\n","    fac_pre = ['Policy_Sales_Channel', 'Vehicle_Damage', 'Annual_Premium', 'Vintage', 'Age_Type']\n","    col_pre = []\n","    for i in fac_pre:\n","        df['Previously_Insured_x_' + i] = pd.factorize(df['Previously_Insured'].astype(str) + df[i].astype(str))[0]\n","        col_pre.append('Previously_Insured_x_' + i)\n","\n","    fac_pro = fac_pre[1:]\n","    col_pro = []\n","    for i in fac_pro:\n","        df['Policy_Sales_Channel_x_' + i] = pd.factorize(df['Policy_Sales_Channel'].astype(str) + df[i].astype(str))[0]\n","        col_pro.append('Policy_Sales_Channel_x_' + i)\n","    return df, col_pre, col_pro\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Load and optimize data\n","train_df = import_data(train_path, index_col='id')\n","test_df = import_data(test_path, index_col='id')\n","\n","# Combine train and test datasets for consistent transformation\n","full_df = pd.concat([train_df, test_df], axis=0)\n","\n","# Convert columns to category type\n","less = ['Gender', 'Vehicle_Age', 'Vehicle_Damage', 'Policy_Sales_Channel']\n","for col in less:\n","    full_df[col] = full_df[col].astype('category')\n","\n","# Apply feature engineering to the combined dataset\n","full_df, col_pre, col_pro = feature_engineering(full_df)\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Split back into train and test sets\n","train_df = full_df.iloc[:len(train_df), :]\n","test_df = full_df.iloc[len(train_df):, :]\n","\n","# Split the training data into training and validation sets\n","X = train_df.drop('Response', axis=1)\n","y = train_df['Response']\n","\n","X_train, X_valid, y_train, y_valid = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["123"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Define the ColumnTransformer\n","coltrans = ColumnTransformer(\n","    transformers=[\n","        ('cat', OneHotEncoder(sparse_output=False, dtype=np.float32), ['Gender', 'Vehicle_Damage']),\n","        ('minmax', MinMaxScaler(), ['Age', 'Region_Code', 'Previously_Insured', 'Policy_Sales_Channel', 'Vintage']),\n","        ('ordinal', OrdinalEncoder(categories=[[0, 1, 2]], dtype=np.float32), ['Vehicle_Age']),\n","        ('robust', RobustScaler(), ['Annual_Premium']),\n","        ('standard', StandardScaler(), ['Age_Type', 'Age_x_Vehicle_Age', 'Age_x_Vehicle_Damage', 'Age_x_Previously_Insured']),\n","        ('standard_2', StandardScaler(), col_pre + col_pro),\n","    ],\n","    remainder='passthrough'  # Keeps columns not specified in transformers\n",")\n","\n","# Fit the transformer on the training data and transform both training and validation sets\n","X_train = coltrans.fit_transform(X_train)\n","X_valid = coltrans.transform(X_valid)\n","test_df = coltrans.transform(test_df.drop('Response', axis=1))\n","\n","gc.collect()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training fold 1\n","[0]\ttrain-auc:0.85397\tvalid-auc:0.85421\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[5], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m dtrain \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(X_train_fold, label\u001b[38;5;241m=\u001b[39my_train_fold)\n\u001b[0;32m     35\u001b[0m dvalid \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(X_valid_fold, label\u001b[38;5;241m=\u001b[39my_valid_fold)\n\u001b[1;32m---> 37\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdvalid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m valid_preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(dvalid, iteration_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, model\u001b[38;5;241m.\u001b[39mbest_iteration))\n\u001b[0;32m     47\u001b[0m auc_score \u001b[38;5;241m=\u001b[39m roc_auc_score(y_valid_fold, valid_preds)\n","File \u001b[1;32mc:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\xgboost\\core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2100\u001b[0m     _check_call(\n\u001b[1;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2104\u001b[0m     )\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Calculate the ratio for scale_pos_weight\n","ratio = len(train_df[train_df['Response'] == 0]) / len(train_df[train_df['Response'] == 1])\n","\n","# Define XGBoost parameters\n","xgb_params = {\n","    'random_state': 512,\n","    'objective': \"binary:logistic\",\n","    'eval_metric': 'auc',\n","    'learning_rate': 0.12,\n","    'max_bin': 225000,\n","    'subsample': 0.8,\n","    'reg_alpha': 0.15,\n","    'min_child_weight': 14,\n","    'colsample_bytree': 0.6,\n","    'gamma': 0.1,\n","    'reg_lambda': 0.75,\n","    'max_depth': 8,\n","    'scale_pos_weight': ratio,\n","    # 'tree_method': 'hist',\n","    # 'device': 'cuda',\n","}\n","\n","# Initialize lists to store out-of-fold predictions and AUC scores\n","xgb_preds = []\n","xgb_aucs = []\n","\n","# Train XGBoost model with cross-validation\n","skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","for fold, (train_idx, valid_idx) in enumerate(skf.split(X_train, y_train)):\n","    print(f\"Training fold {fold + 1}\")\n","    X_train_fold, y_train_fold = X_train[train_idx], y_train.iloc[train_idx]\n","    X_valid_fold, y_valid_fold = X_train[valid_idx], y_train.iloc[valid_idx]\n","    \n","    dtrain = xgb.DMatrix(X_train_fold, label=y_train_fold)\n","    dvalid = xgb.DMatrix(X_valid_fold, label=y_valid_fold)\n","    \n","    model = xgb.train(\n","        xgb_params,\n","        dtrain,\n","        num_boost_round=3000,\n","        evals=[(dtrain, 'train'), (dvalid, 'valid')],\n","        verbose_eval=100,\n","        early_stopping_rounds=10,\n","    )\n","    \n","    valid_preds = model.predict(dvalid, iteration_range=(0, model.best_iteration))\n","    auc_score = roc_auc_score(y_valid_fold, valid_preds)\n","    xgb_aucs.append(auc_score)\n","    \n","    dtest = xgb.DMatrix(test_df)\n","    test_pred = model.predict(dtest, iteration_range=(0, model.best_iteration))\n","    xgb_preds.append(test_pred)\n","    \n","    # Save the model for this fold\n","    model.save_model(f'xgb_model_fold_{fold + 1}.json')\n","    \n","    # Clear memory\n","    del X_train_fold, y_train_fold, X_valid_fold, y_valid_fold, dtrain, dvalid, model\n","    gc.collect()\n","\n","# Calculate overall AUC score for XGBoost\n","auc_mean_xgb = np.mean(xgb_aucs)\n","auc_std_xgb = np.std(xgb_aucs)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["['test_pred_xgb.pkl']"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Average the predictions from each fold for XGBoost\n","test_pred_xgb = np.mean(xgb_preds, axis=0)\n","joblib.dump(test_pred_xgb, 'test_pred_xgb3.pkl')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\paulo\\AppData\\Local\\Temp\\ipykernel_10884\\3486884307.py:26: DeprecationWarning: is_interval_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.IntervalDtype)` instead\n","  if pd.api.types.is_interval_dtype(col_type):\n","C:\\Users\\paulo\\AppData\\Local\\Temp\\ipykernel_10884\\3486884307.py:26: DeprecationWarning: is_interval_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.IntervalDtype)` instead\n","  if pd.api.types.is_interval_dtype(col_type):\n","C:\\Users\\paulo\\AppData\\Local\\Temp\\ipykernel_10884\\3486884307.py:26: DeprecationWarning: is_interval_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.IntervalDtype)` instead\n","  if pd.api.types.is_interval_dtype(col_type):\n","C:\\Users\\paulo\\AppData\\Local\\Temp\\ipykernel_10884\\3486884307.py:26: DeprecationWarning: is_interval_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.IntervalDtype)` instead\n","  if pd.api.types.is_interval_dtype(col_type):\n","C:\\Users\\paulo\\AppData\\Local\\Temp\\ipykernel_10884\\3486884307.py:26: DeprecationWarning: is_interval_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.IntervalDtype)` instead\n","  if pd.api.types.is_interval_dtype(col_type):\n","C:\\Users\\paulo\\AppData\\Local\\Temp\\ipykernel_10884\\3486884307.py:26: DeprecationWarning: is_interval_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.IntervalDtype)` instead\n","  if pd.api.types.is_interval_dtype(col_type):\n","C:\\Users\\paulo\\AppData\\Local\\Temp\\ipykernel_10884\\3486884307.py:26: DeprecationWarning: is_interval_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.IntervalDtype)` instead\n","  if pd.api.types.is_interval_dtype(col_type):\n"]}],"source":["# Reimport the test_df to get the original index\n","test_df = import_data(test_path, index_col='id')\n","\n","# Create a submission DataFrame using the original test index\n","submission = pd.DataFrame({\n","    'id': test_df.index,\n","    'Response': test_pred_xgb\n","})\n","\n","# Save the submission DataFrame to a CSV file\n","submission.to_csv('submission_xgb3.csv', index=False)\n"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":8930475,"sourceId":73291,"sourceType":"competition"},{"sourceId":189806873,"sourceType":"kernelVersion"},{"sourceId":189806878,"sourceType":"kernelVersion"},{"sourceId":189813334,"sourceType":"kernelVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":4}
