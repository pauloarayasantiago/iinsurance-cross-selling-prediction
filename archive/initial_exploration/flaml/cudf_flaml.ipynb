{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting cudf-cu11\n",
      "  Downloading cudf_cu11-24.6.1.tar.gz (2.6 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [56 lines of output]\n",
      "        File \"C:\\Users\\paulo\\AppData\\Local\\Temp\\pip-build-env-bu089ex6\\overlay\\Lib\\site-packages\\nvidia_stub\\wheel.py\", line 147, in download_wheel\n",
      "          return download_manual(wheel_directory, distribution, version)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\paulo\\AppData\\Local\\Temp\\pip-build-env-bu089ex6\\overlay\\Lib\\site-packages\\nvidia_stub\\wheel.py\", line 114, in download_manual\n",
      "          raise RuntimeError(f\"Didn't find wheel for {distribution} {version}\")\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\paulo\\AppData\\Local\\Temp\\pip-build-env-bu089ex6\\overlay\\Lib\\site-packages\\nvidia_stub\\wheel.py\", line 147, in download_wheel\n",
      "          return download_manual(wheel_directory, distribution, version)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\paulo\\AppData\\Local\\Temp\\pip-build-env-bu089ex6\\overlay\\Lib\\site-packages\\nvidia_stub\\wheel.py\", line 114, in download_manual\n",
      "          raise RuntimeError(f\"Didn't find wheel for {distribution} {version}\")\n",
      "      RuntimeError: Didn't find wheel for cudf-cu11 24.6.1\n",
      "      \n",
      "      During handling of the above exception, another exception occurred:\n",
      "      \n",
      "      Traceback (most recent call last):\n",
      "        File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "          main()\n",
      "        File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 152, in prepare_metadata_for_build_wheel\n",
      "          whl_basename = backend.build_wheel(metadata_directory, config_settings)\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\paulo\\AppData\\Local\\Temp\\pip-build-env-bu089ex6\\overlay\\Lib\\site-packages\\nvidia_stub\\buildapi.py\", line 29, in build_wheel\n",
      "          return download_wheel(pathlib.Path(wheel_directory), config_settings)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\paulo\\AppData\\Local\\Temp\\pip-build-env-bu089ex6\\overlay\\Lib\\site-packages\\nvidia_stub\\wheel.py\", line 149, in download_wheel\n",
      "          report_install_failure(distribution, version, exception_context)\n",
      "        File \"C:\\Users\\paulo\\AppData\\Local\\Temp\\pip-build-env-bu089ex6\\overlay\\Lib\\site-packages\\nvidia_stub\\error.py\", line 63, in report_install_failure\n",
      "          raise InstallFailedError(\n",
      "      nvidia_stub.error.InstallFailedError:\n",
      "      *******************************************************************************\n",
      "      \n",
      "      The installation of cudf-cu11 for version 24.6.1 failed.\n",
      "      \n",
      "      This is a special placeholder package which downloads a real wheel package\n",
      "      from https://pypi.nvidia.com. If https://pypi.nvidia.com is not reachable, we\n",
      "      cannot download the real wheel file to install.\n",
      "      \n",
      "      You might try installing this package via\n",
      "      ```\n",
      "      $ pip install --extra-index-url https://pypi.nvidia.com cudf-cu11\n",
      "      ```\n",
      "      \n",
      "      Here is some debug information about your platform to include in any bug\n",
      "      report:\n",
      "      \n",
      "      Python Version: CPython 3.12.4\n",
      "      Operating System: Windows 11\n",
      "      CPU Architecture: AMD64\n",
      "      Driver Version: 555.85\n",
      "      CUDA Version: 12.5\n",
      "      \n",
      "      *******************************************************************************\n",
      "      \n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "%pip install cudf-cu11 cuml-cu11 --extra-index-url=https://pypi.ngc.nvidia.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cudf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcudf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cudf'"
     ]
    }
   ],
   "source": [
    "import cudf\n",
    "import numpy as np\n",
    "from cuml.preprocessing import StandardScaler\n",
    "from cuml.cluster import KMeans\n",
    "from flaml import AutoML\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the datasets using cuDF\n",
    "train_df = cudf.read_csv(\"train.csv\", index_col='id')\n",
    "test_df = cudf.read_csv(\"test.csv\", index_col='id')\n",
    "\n",
    "# Transform binary variables\n",
    "train_df['Gender'] = train_df['Gender'].map({'Male': 1, 'Female': 0})\n",
    "train_df['Vehicle_Damage'] = train_df['Vehicle_Damage'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Define binary variables and drop Driving_License due to limited variability\n",
    "binary = ['Gender', 'Driving_License', 'Previously_Insured', 'Vehicle_Damage', 'Response']\n",
    "train_df = train_df.drop(['Driving_License'], axis=1)\n",
    "\n",
    "# Group rare categories in categorical variables\n",
    "def group_rare_categories(df, column, threshold=0.01):\n",
    "    category_freq = df[column].value_counts(normalize=True)\n",
    "    rare_categories = category_freq[category_freq < threshold].index\n",
    "    df[column] = df[column].applymap(lambda x: 'Other' if x in rare_categories else x)\n",
    "    return df\n",
    "\n",
    "categorical = ['Region_Code', 'Vehicle_Age', 'Policy_Sales_Channel']\n",
    "for col in categorical:\n",
    "    train_df = group_rare_categories(train_df, col, 0.01)\n",
    "\n",
    "# Handle continuous variables\n",
    "continuous_numeric = ['Age', 'Vintage', 'Annual_Premium']\n",
    "Q1 = train_df['Annual_Premium'].quantile(0.25)\n",
    "Q3 = train_df['Annual_Premium'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "train_df['Outlier_Annual_Premium'] = ((train_df['Annual_Premium'] < lower_bound) | (train_df['Annual_Premium'] > upper_bound)).astype(int)\n",
    "train_df = train_df[(train_df['Annual_Premium'] >= lower_bound) & (train_df['Annual_Premium'] <= upper_bound)]\n",
    "train_df = train_df.drop('Outlier_Annual_Premium', axis=1)\n",
    "\n",
    "# Standardize the continuous variables\n",
    "scaler = StandardScaler()\n",
    "scaled_continuous_vars = scaler.fit_transform(train_df[continuous_numeric])\n",
    "\n",
    "# Apply KMeans clustering\n",
    "optimal_clusters = 4\n",
    "kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)\n",
    "clusters = kmeans.fit_predict(scaled_continuous_vars)\n",
    "train_df['Cluster'] = clusters\n",
    "\n",
    "# Ordinal Encoding for Vehicle_Age and One-Hot Encoding for other categorical variables\n",
    "train_df['Vehicle_Age'] = train_df['Vehicle_Age'].map({'< 1 Year': 0, '1-2 Year': 1, '> 2 Years': 2})\n",
    "train_df = cudf.get_dummies(train_df, columns=categorical, drop_first=True)\n",
    "\n",
    "# Feature engineering\n",
    "def feature_engineering(df):\n",
    "    df['Age_Vehicle_Age'] = df['Age'] * df['Vehicle_Age']\n",
    "    df['Age_Previously_Insured'] = df['Age'] * df['Previously_Insured']\n",
    "    df['Vehicle_Age_Damage'] = df['Vehicle_Age'] * df['Vehicle_Damage']\n",
    "    df['Previously_Insured_Damage'] = df['Previously_Insured'] * df['Vehicle_Damage']\n",
    "    df['Age_squared'] = df['Age'] ** 2\n",
    "    df['Vehicle_Age_squared'] = df['Vehicle_Age'] ** 2\n",
    "    df['Annual_Premium_per_Age'] = df['Annual_Premium'] / (df['Age'] + 1)\n",
    "    return df\n",
    "\n",
    "train_df = feature_engineering(train_df)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = train_df.drop('Response', axis=1)\n",
    "y = train_df['Response']\n",
    "\n",
    "# Convert to pandas DataFrame for FLAML\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.to_pandas(), y.to_pandas(), test_size=0.2, stratify=y.to_pandas(), random_state=42)\n",
    "\n",
    "# Initialize AutoML\n",
    "automl = AutoML()\n",
    "\n",
    "# Define settings for AutoML\n",
    "settings = {\n",
    "    \"time_budget\": 1800,  # reduce time budget to 30 minutes for efficiency\n",
    "    \"metric\": 'roc_auc',  # primary metric\n",
    "    \"task\": 'classification',  # task type\n",
    "    \"log_file_name\": \"automl.log\",  # log file\n",
    "    \"seed\": 42  # random seed\n",
    "}\n",
    "\n",
    "# Train models with AutoML\n",
    "automl.fit(X_train=X_train, y_train=y_train, **settings)\n",
    "\n",
    "# Print the best model and its parameters\n",
    "print(f\"Best model: {automl.best_estimator}\")\n",
    "print(f\"Best hyperparameters: {automl.best_config}\")\n",
    "print(f\"Best ROC-AUC on validation data: {automl.best_loss}\")\n",
    "\n",
    "# Evaluate the best model on the training set\n",
    "y_train_pred_prob = automl.predict_proba(X_train)[:, 1]\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_pred_prob)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_test_pred_prob = automl.predict_proba(X_test)[:, 1]\n",
    "test_roc_auc = roc_auc_score(y_test, y_test_pred_prob)\n",
    "\n",
    "# Print the train and test ROC-AUC scores\n",
    "print(\"Train ROC-AUC Score:\", train_roc_auc)\n",
    "print(\"Test ROC-AUC Score:\", test_roc_auc)\n",
    "\n",
    "# Plot ROC curve for the best model on the test set\n",
    "fpr, tpr, _ = roc_curve(y_test, y_test_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Train the best model on the full dataset\n",
    "best_model = automl.best_estimator\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the retrained best model on the test set\n",
    "y_test_pred_prob_full = best_model.predict_proba(X_test)[:, 1]\n",
    "test_roc_auc_full = roc_auc_score(y_test, y_test_pred_prob_full)\n",
    "\n",
    "# Print the test ROC-AUC score for the retrained best model\n",
    "print(\"Test ROC-AUC Score after retraining on full data:\", test_roc_auc_full)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
