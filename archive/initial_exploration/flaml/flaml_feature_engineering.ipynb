{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3upQlsTWLoT2"
      },
      "source": [
        "# **Import Libraries**\n",
        "Importing necessary libraries for data manipulation, visualization, and clustering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmaS42rMKKv_",
        "outputId": "8aab59aa-a3ca-4041-ff68-a7aba22a8315"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TLelkNMLrm2"
      },
      "source": [
        "# **Load and Sample Data**\n",
        "Loading the datasets and sampling a fraction of them to speed up processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s_mJ7Uh7KZLb"
      },
      "outputs": [],
      "source": [
        "# Load the datasets\n",
        "train_df = pd.read_csv(\"train.csv\", index_col='id')\n",
        "test_df = pd.read_csv(\"test.csv\", index_col='id')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTEfkh70Ltiz"
      },
      "source": [
        "# **Transform Binary Variables**\n",
        "Mapping binary variables to numerical values and defining binary variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vDdoaJgNKcXR"
      },
      "outputs": [],
      "source": [
        "# Transform binary variables\n",
        "train_df['Gender'] = train_df['Gender'].map({'Male': 1, 'Female': 0})\n",
        "train_df['Vehicle_Damage'] = train_df['Vehicle_Damage'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# Define binary variables\n",
        "binary = ['Gender', 'Driving_License', 'Previously_Insured', 'Vehicle_Damage', 'Response']\n",
        "\n",
        "# Drop Driving_License due to limited variability\n",
        "train_df = train_df.drop(['Driving_License'], axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-HbjfVrLxmk"
      },
      "source": [
        "# **Group Rare Categories**\n",
        "Grouping rare categories in categorical variables to reduce the dimensionality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wQc53GXhKew3"
      },
      "outputs": [],
      "source": [
        "# Define categorical variables\n",
        "categorical = ['Region_Code', 'Vehicle_Age', 'Policy_Sales_Channel']\n",
        "\n",
        "# Function to group rare categories\n",
        "def group_rare_categories(df, column, threshold=0.01):\n",
        "    category_freq = df[column].value_counts(normalize=True)\n",
        "    rare_categories = category_freq[category_freq < threshold].index\n",
        "    df[column] = df[column].apply(lambda x: 'Other' if x in rare_categories else x)\n",
        "    return df\n",
        "\n",
        "# Group rare categories in categorical variables\n",
        "train_df = group_rare_categories(train_df, 'Region_Code', 0.01)\n",
        "train_df = group_rare_categories(train_df, 'Policy_Sales_Channel', 0.01)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSCmUDkoL0n4"
      },
      "source": [
        "# **Handle Continuous Variables**\n",
        "Handling outliers and standardizing continuous numeric variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eG_iHG-YKhnM"
      },
      "outputs": [],
      "source": [
        "# Define continuous numeric variables\n",
        "continuous_numeric = ['Age', 'Vintage', 'Annual_Premium']\n",
        "\n",
        "# Calculate the IQR for Annual_Premium\n",
        "Q1 = train_df['Annual_Premium'].quantile(0.25)\n",
        "Q3 = train_df['Annual_Premium'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Define the lower and upper bounds for outliers\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Identify outliers and create an outlier flag\n",
        "train_df['Outlier_Annual_Premium'] = ((train_df['Annual_Premium'] < lower_bound) | (train_df['Annual_Premium'] > upper_bound)).astype(int)\n",
        "\n",
        "# Remove outliers from the dataset based on IQR method\n",
        "train_df = train_df[(train_df['Annual_Premium'] >= lower_bound) & (train_df['Annual_Premium'] <= upper_bound)]\n",
        "train_df = train_df.drop('Outlier_Annual_Premium', axis=1)\n",
        "\n",
        "# Standardize the continuous variables\n",
        "scaler = StandardScaler()\n",
        "scaled_continuous_vars = scaler.fit_transform(train_df[continuous_numeric])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsT_F1lGL7Vn"
      },
      "source": [
        "# **KMeans Clustering**\n",
        "Applying KMeans clustering to the standardized continuous variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "ouys4e3nL8Jn",
        "outputId": "8b2f34c1-8697-47a3-b603-764f7fef3c61"
      },
      "outputs": [],
      "source": [
        "# Based on the elbow plot, choose the optimal number of clusters (e.g., 4)\n",
        "optimal_clusters = 4\n",
        "\n",
        "# Apply KMeans clustering\n",
        "kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)\n",
        "clusters = kmeans.fit_predict(scaled_continuous_vars)\n",
        "\n",
        "# Add cluster labels to the DataFrame\n",
        "train_df['Cluster'] = clusters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tC6dl6C3OJo8"
      },
      "source": [
        "# **One-Hot and Ordinal Encoding**\n",
        "Apply one-hot encoding to `Region_Code` and `Policy_Sales_Channel`, and ordinal encoding to `Vehicle_Age`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "y3vR2aFgOfUW"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Previously_Insured</th>\n",
              "      <th>Vehicle_Age</th>\n",
              "      <th>Vehicle_Damage</th>\n",
              "      <th>Annual_Premium</th>\n",
              "      <th>Vintage</th>\n",
              "      <th>Response</th>\n",
              "      <th>Cluster</th>\n",
              "      <th>Region_Code_3.0</th>\n",
              "      <th>...</th>\n",
              "      <th>Region_Code_50.0</th>\n",
              "      <th>Region_Code_Other</th>\n",
              "      <th>Policy_Sales_Channel_122.0</th>\n",
              "      <th>Policy_Sales_Channel_124.0</th>\n",
              "      <th>Policy_Sales_Channel_152.0</th>\n",
              "      <th>Policy_Sales_Channel_154.0</th>\n",
              "      <th>Policy_Sales_Channel_156.0</th>\n",
              "      <th>Policy_Sales_Channel_157.0</th>\n",
              "      <th>Policy_Sales_Channel_160.0</th>\n",
              "      <th>Policy_Sales_Channel_Other</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>58911.0</td>\n",
              "      <td>288</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38043.0</td>\n",
              "      <td>254</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>31951.0</td>\n",
              "      <td>294</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28150.0</td>\n",
              "      <td>197</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>27128.0</td>\n",
              "      <td>190</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 40 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Gender  Age  Previously_Insured  Vehicle_Age  Vehicle_Damage  \\\n",
              "id                                                                 \n",
              "1        1   43                   0            2               1   \n",
              "2        0   25                   1            0               0   \n",
              "4        0   36                   1            1               0   \n",
              "5        0   31                   1            0               0   \n",
              "6        1   23                   1            0               0   \n",
              "\n",
              "    Annual_Premium  Vintage  Response  Cluster  Region_Code_3.0  ...  \\\n",
              "id                                                               ...   \n",
              "1          58911.0      288         1        2            False  ...   \n",
              "2          38043.0      254         0        1            False  ...   \n",
              "4          31951.0      294         0        1            False  ...   \n",
              "5          28150.0      197         0        1            False  ...   \n",
              "6          27128.0      190         0        1            False  ...   \n",
              "\n",
              "    Region_Code_50.0  Region_Code_Other  Policy_Sales_Channel_122.0  \\\n",
              "id                                                                    \n",
              "1              False              False                       False   \n",
              "2              False              False                       False   \n",
              "4              False              False                       False   \n",
              "5              False              False                       False   \n",
              "6              False              False                       False   \n",
              "\n",
              "    Policy_Sales_Channel_124.0  Policy_Sales_Channel_152.0  \\\n",
              "id                                                           \n",
              "1                        False                       False   \n",
              "2                        False                        True   \n",
              "4                        False                        True   \n",
              "5                        False                        True   \n",
              "6                        False                        True   \n",
              "\n",
              "    Policy_Sales_Channel_154.0  Policy_Sales_Channel_156.0  \\\n",
              "id                                                           \n",
              "1                        False                       False   \n",
              "2                        False                       False   \n",
              "4                        False                       False   \n",
              "5                        False                       False   \n",
              "6                        False                       False   \n",
              "\n",
              "    Policy_Sales_Channel_157.0  Policy_Sales_Channel_160.0  \\\n",
              "id                                                           \n",
              "1                        False                       False   \n",
              "2                        False                       False   \n",
              "4                        False                       False   \n",
              "5                        False                       False   \n",
              "6                        False                       False   \n",
              "\n",
              "    Policy_Sales_Channel_Other  \n",
              "id                              \n",
              "1                        False  \n",
              "2                        False  \n",
              "4                        False  \n",
              "5                        False  \n",
              "6                        False  \n",
              "\n",
              "[5 rows x 40 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ordinal Encoding for Vehicle_Age\n",
        "train_df_encoded = train_df.copy()  # Create a copy of the original DataFrame\n",
        "train_df_encoded['Vehicle_Age'] = train_df_encoded['Vehicle_Age'].map({'< 1 Year': 0, '1-2 Year': 1, '> 2 Years': 2})\n",
        "\n",
        "# One-Hot Encoding for other categorical variables\n",
        "categorical = ['Region_Code', 'Policy_Sales_Channel']\n",
        "\n",
        "# Apply one-hot encoding\n",
        "train_df_encoded = pd.get_dummies(train_df_encoded, columns=categorical, drop_first=True)\n",
        "\n",
        "# Display the first few rows of the transformed train dataset\n",
        "train_df_encoded.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4dIbT72GvpSa"
      },
      "outputs": [],
      "source": [
        "def feature_engineering(df):\n",
        "    df['Age_Vehicle_Age'] = df['Age'] * df['Vehicle_Age']\n",
        "    df['Age_Previously_Insured'] = df['Age'] * df['Previously_Insured']\n",
        "    df['Vehicle_Age_Damage'] = df['Vehicle_Age'] * df['Vehicle_Damage']\n",
        "    df['Previously_Insured_Damage'] = df['Previously_Insured'] * df['Vehicle_Damage']\n",
        "    df['Age_squared'] = df['Age'] ** 2\n",
        "    df['Vehicle_Age_squared'] = df['Vehicle_Age'] ** 2\n",
        "    df['Annual_Premium_per_Age'] = df['Annual_Premium'] / (df['Age'] + 1)\n",
        "    return df\n",
        "\n",
        "# Apply feature engineering\n",
        "train_df_encoded = feature_engineering(train_df_encoded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sOcc0sDhRgAP"
      },
      "outputs": [],
      "source": [
        "# Separate features and target variable\n",
        "X = train_df_encoded.drop('Response', axis=1)\n",
        "y = train_df_encoded['Response']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RbZk5O1Uglik"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "v5_0yDZCJ9iZ"
      },
      "outputs": [],
      "source": [
        "# !pip install flaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7_KrtkosKFDl"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[flaml.automl.logger: 07-08 11:18:31] {1680} INFO - task = classification\n",
            "[flaml.automl.logger: 07-08 11:18:31] {1691} INFO - Evaluation method: holdout\n",
            "[flaml.automl.logger: 07-08 11:18:56] {1789} INFO - Minimizing error metric: 1-roc_auc\n",
            "[flaml.automl.logger: 07-08 11:18:56] {1901} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
            "[flaml.automl.logger: 07-08 11:18:56] {2219} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:18:59] {2345} INFO - Estimated sufficient time budget=19685720s. Estimated necessary time budget=483284s.\n",
            "[flaml.automl.logger: 07-08 11:18:59] {2392} INFO -  at 103.2s,\testimator lgbm's best error=0.1545,\tbest estimator lgbm's best error=0.1545\n",
            "[flaml.automl.logger: 07-08 11:18:59] {2219} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:19:01] {2392} INFO -  at 105.2s,\testimator lgbm's best error=0.1530,\tbest estimator lgbm's best error=0.1530\n",
            "[flaml.automl.logger: 07-08 11:19:01] {2219} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:19:02] {2392} INFO -  at 105.7s,\testimator lgbm's best error=0.1438,\tbest estimator lgbm's best error=0.1438\n",
            "[flaml.automl.logger: 07-08 11:19:02] {2219} INFO - iteration 3, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:19:02] {2392} INFO -  at 106.2s,\testimator lgbm's best error=0.1392,\tbest estimator lgbm's best error=0.1392\n",
            "[flaml.automl.logger: 07-08 11:19:02] {2219} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:19:03] {2392} INFO -  at 106.7s,\testimator lgbm's best error=0.1382,\tbest estimator lgbm's best error=0.1382\n",
            "[flaml.automl.logger: 07-08 11:19:03] {2219} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:19:03] {2392} INFO -  at 107.2s,\testimator lgbm's best error=0.1382,\tbest estimator lgbm's best error=0.1382\n",
            "[flaml.automl.logger: 07-08 11:19:03] {2219} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:19:04] {2392} INFO -  at 107.9s,\testimator lgbm's best error=0.1369,\tbest estimator lgbm's best error=0.1369\n",
            "[flaml.automl.logger: 07-08 11:19:04] {2219} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:19:05] {2392} INFO -  at 108.8s,\testimator lgbm's best error=0.1369,\tbest estimator lgbm's best error=0.1369\n",
            "[flaml.automl.logger: 07-08 11:19:05] {2219} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:19:06] {2392} INFO -  at 109.7s,\testimator lgbm's best error=0.1369,\tbest estimator lgbm's best error=0.1369\n",
            "[flaml.automl.logger: 07-08 11:19:06] {2219} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:19:07] {2392} INFO -  at 110.6s,\testimator lgbm's best error=0.1358,\tbest estimator lgbm's best error=0.1358\n",
            "[flaml.automl.logger: 07-08 11:19:07] {2219} INFO - iteration 10, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:19:09] {2392} INFO -  at 113.1s,\testimator lgbm's best error=0.1358,\tbest estimator lgbm's best error=0.1358\n",
            "[flaml.automl.logger: 07-08 11:19:09] {2219} INFO - iteration 11, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:19:10] {2392} INFO -  at 113.8s,\testimator lgbm's best error=0.1358,\tbest estimator lgbm's best error=0.1358\n",
            "[flaml.automl.logger: 07-08 11:19:10] {2219} INFO - iteration 12, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:19:11] {2392} INFO -  at 114.6s,\testimator lgbm's best error=0.1358,\tbest estimator lgbm's best error=0.1358\n",
            "[flaml.automl.logger: 07-08 11:19:11] {2219} INFO - iteration 13, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:19:12] {2392} INFO -  at 115.7s,\testimator lgbm's best error=0.1322,\tbest estimator lgbm's best error=0.1322\n",
            "[flaml.automl.logger: 07-08 11:19:12] {2219} INFO - iteration 14, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:19:16] {2392} INFO -  at 120.3s,\testimator lgbm's best error=0.1322,\tbest estimator lgbm's best error=0.1322\n",
            "[flaml.automl.logger: 07-08 11:19:16] {2219} INFO - iteration 15, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:19:18] {2392} INFO -  at 121.9s,\testimator lgbm's best error=0.1295,\tbest estimator lgbm's best error=0.1295\n",
            "[flaml.automl.logger: 07-08 11:19:18] {2219} INFO - iteration 16, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 11:19:19] {2392} INFO -  at 122.4s,\testimator xgboost's best error=0.1560,\tbest estimator lgbm's best error=0.1295\n",
            "[flaml.automl.logger: 07-08 11:19:19] {2219} INFO - iteration 17, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 11:19:19] {2392} INFO -  at 122.8s,\testimator xgboost's best error=0.1560,\tbest estimator lgbm's best error=0.1295\n",
            "[flaml.automl.logger: 07-08 11:19:19] {2219} INFO - iteration 18, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 11:19:20] {2392} INFO -  at 123.4s,\testimator xgboost's best error=0.1435,\tbest estimator lgbm's best error=0.1295\n",
            "[flaml.automl.logger: 07-08 11:19:20] {2219} INFO - iteration 19, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 11:19:20] {2392} INFO -  at 123.9s,\testimator xgboost's best error=0.1435,\tbest estimator lgbm's best error=0.1295\n",
            "[flaml.automl.logger: 07-08 11:19:20] {2219} INFO - iteration 20, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:19:21] {2392} INFO -  at 124.8s,\testimator lgbm's best error=0.1295,\tbest estimator lgbm's best error=0.1295\n",
            "[flaml.automl.logger: 07-08 11:19:21] {2219} INFO - iteration 21, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:19:29] {2392} INFO -  at 132.5s,\testimator lgbm's best error=0.1258,\tbest estimator lgbm's best error=0.1258\n",
            "[flaml.automl.logger: 07-08 11:19:29] {2219} INFO - iteration 22, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 11:19:29] {2392} INFO -  at 133.1s,\testimator xgboost's best error=0.1396,\tbest estimator lgbm's best error=0.1258\n",
            "[flaml.automl.logger: 07-08 11:19:29] {2219} INFO - iteration 23, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 11:19:30] {2392} INFO -  at 133.6s,\testimator extra_tree's best error=0.1640,\tbest estimator lgbm's best error=0.1258\n",
            "[flaml.automl.logger: 07-08 11:19:30] {2219} INFO - iteration 24, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 11:19:30] {2392} INFO -  at 134.2s,\testimator extra_tree's best error=0.1640,\tbest estimator lgbm's best error=0.1258\n",
            "[flaml.automl.logger: 07-08 11:19:30] {2219} INFO - iteration 25, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 11:19:31] {2392} INFO -  at 134.8s,\testimator extra_tree's best error=0.1483,\tbest estimator lgbm's best error=0.1258\n",
            "[flaml.automl.logger: 07-08 11:19:31] {2219} INFO - iteration 26, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 11:19:32] {2392} INFO -  at 135.4s,\testimator extra_tree's best error=0.1483,\tbest estimator lgbm's best error=0.1258\n",
            "[flaml.automl.logger: 07-08 11:19:32] {2219} INFO - iteration 27, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 11:19:32] {2392} INFO -  at 135.9s,\testimator extra_tree's best error=0.1483,\tbest estimator lgbm's best error=0.1258\n",
            "[flaml.automl.logger: 07-08 11:19:32] {2219} INFO - iteration 28, current learner rf\n",
            "[flaml.automl.logger: 07-08 11:19:33] {2392} INFO -  at 136.5s,\testimator rf's best error=0.1619,\tbest estimator lgbm's best error=0.1258\n",
            "[flaml.automl.logger: 07-08 11:19:33] {2219} INFO - iteration 29, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 11:19:33] {2392} INFO -  at 136.9s,\testimator xgboost's best error=0.1396,\tbest estimator lgbm's best error=0.1258\n",
            "[flaml.automl.logger: 07-08 11:19:33] {2219} INFO - iteration 30, current learner rf\n",
            "[flaml.automl.logger: 07-08 11:19:34] {2392} INFO -  at 137.5s,\testimator rf's best error=0.1619,\tbest estimator lgbm's best error=0.1258\n",
            "[flaml.automl.logger: 07-08 11:19:34] {2219} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:20:07] {2392} INFO -  at 170.8s,\testimator lgbm's best error=0.1251,\tbest estimator lgbm's best error=0.1251\n",
            "[flaml.automl.logger: 07-08 11:20:07] {2219} INFO - iteration 32, current learner rf\n",
            "[flaml.automl.logger: 07-08 11:20:08] {2392} INFO -  at 171.4s,\testimator rf's best error=0.1442,\tbest estimator lgbm's best error=0.1251\n",
            "[flaml.automl.logger: 07-08 11:20:08] {2219} INFO - iteration 33, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 11:20:08] {2392} INFO -  at 172.0s,\testimator extra_tree's best error=0.1483,\tbest estimator lgbm's best error=0.1251\n",
            "[flaml.automl.logger: 07-08 11:20:08] {2219} INFO - iteration 34, current learner rf\n",
            "[flaml.automl.logger: 07-08 11:20:09] {2392} INFO -  at 172.7s,\testimator rf's best error=0.1442,\tbest estimator lgbm's best error=0.1251\n",
            "[flaml.automl.logger: 07-08 11:20:09] {2219} INFO - iteration 35, current learner rf\n",
            "[flaml.automl.logger: 07-08 11:20:09] {2392} INFO -  at 173.2s,\testimator rf's best error=0.1442,\tbest estimator lgbm's best error=0.1251\n",
            "[flaml.automl.logger: 07-08 11:20:09] {2219} INFO - iteration 36, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 11:20:10] {2392} INFO -  at 173.8s,\testimator extra_tree's best error=0.1468,\tbest estimator lgbm's best error=0.1251\n",
            "[flaml.automl.logger: 07-08 11:20:10] {2219} INFO - iteration 37, current learner rf\n",
            "[flaml.automl.logger: 07-08 11:20:11] {2392} INFO -  at 174.4s,\testimator rf's best error=0.1442,\tbest estimator lgbm's best error=0.1251\n",
            "[flaml.automl.logger: 07-08 11:20:11] {2219} INFO - iteration 38, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 11:20:11] {2392} INFO -  at 175.1s,\testimator xgboost's best error=0.1396,\tbest estimator lgbm's best error=0.1251\n",
            "[flaml.automl.logger: 07-08 11:20:11] {2219} INFO - iteration 39, current learner rf\n",
            "[flaml.automl.logger: 07-08 11:20:12] {2392} INFO -  at 175.7s,\testimator rf's best error=0.1428,\tbest estimator lgbm's best error=0.1251\n",
            "[flaml.automl.logger: 07-08 11:20:12] {2219} INFO - iteration 40, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 11:20:12] {2392} INFO -  at 176.3s,\testimator xgboost's best error=0.1369,\tbest estimator lgbm's best error=0.1251\n",
            "[flaml.automl.logger: 07-08 11:20:12] {2219} INFO - iteration 41, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 11:20:13] {2392} INFO -  at 176.8s,\testimator xgboost's best error=0.1369,\tbest estimator lgbm's best error=0.1251\n",
            "[flaml.automl.logger: 07-08 11:20:13] {2219} INFO - iteration 42, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:20:18] {2392} INFO -  at 182.3s,\testimator lgbm's best error=0.1251,\tbest estimator lgbm's best error=0.1251\n",
            "[flaml.automl.logger: 07-08 11:20:18] {2219} INFO - iteration 43, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 11:20:19] {2392} INFO -  at 182.9s,\testimator xgboost's best error=0.1369,\tbest estimator lgbm's best error=0.1251\n",
            "[flaml.automl.logger: 07-08 11:20:19] {2219} INFO - iteration 44, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 11:20:20] {2392} INFO -  at 183.5s,\testimator extra_tree's best error=0.1416,\tbest estimator lgbm's best error=0.1251\n",
            "[flaml.automl.logger: 07-08 11:20:20] {2219} INFO - iteration 45, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 11:20:20] {2392} INFO -  at 184.1s,\testimator extra_tree's best error=0.1416,\tbest estimator lgbm's best error=0.1251\n",
            "[flaml.automl.logger: 07-08 11:20:20] {2219} INFO - iteration 46, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 11:20:21] {2392} INFO -  at 184.8s,\testimator xgboost's best error=0.1360,\tbest estimator lgbm's best error=0.1251\n",
            "[flaml.automl.logger: 07-08 11:20:21] {2219} INFO - iteration 47, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 11:20:22] {2392} INFO -  at 185.5s,\testimator extra_tree's best error=0.1416,\tbest estimator lgbm's best error=0.1251\n",
            "[flaml.automl.logger: 07-08 11:20:22] {2219} INFO - iteration 48, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:20:53] {2392} INFO -  at 217.3s,\testimator lgbm's best error=0.1218,\tbest estimator lgbm's best error=0.1218\n",
            "[flaml.automl.logger: 07-08 11:20:53] {2219} INFO - iteration 49, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 11:20:54] {2392} INFO -  at 217.9s,\testimator extra_tree's best error=0.1416,\tbest estimator lgbm's best error=0.1218\n",
            "[flaml.automl.logger: 07-08 11:20:54] {2219} INFO - iteration 50, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 11:20:55] {2392} INFO -  at 218.5s,\testimator extra_tree's best error=0.1416,\tbest estimator lgbm's best error=0.1218\n",
            "[flaml.automl.logger: 07-08 11:20:55] {2219} INFO - iteration 51, current learner rf\n",
            "[flaml.automl.logger: 07-08 11:20:55] {2392} INFO -  at 219.1s,\testimator rf's best error=0.1425,\tbest estimator lgbm's best error=0.1218\n",
            "[flaml.automl.logger: 07-08 11:20:55] {2219} INFO - iteration 52, current learner rf\n",
            "[flaml.automl.logger: 07-08 11:20:56] {2392} INFO -  at 219.7s,\testimator rf's best error=0.1421,\tbest estimator lgbm's best error=0.1218\n",
            "[flaml.automl.logger: 07-08 11:20:56] {2219} INFO - iteration 53, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:21:23] {2392} INFO -  at 246.7s,\testimator lgbm's best error=0.1218,\tbest estimator lgbm's best error=0.1218\n",
            "[flaml.automl.logger: 07-08 11:21:23] {2219} INFO - iteration 54, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:21:31] {2392} INFO -  at 254.7s,\testimator lgbm's best error=0.1218,\tbest estimator lgbm's best error=0.1218\n",
            "[flaml.automl.logger: 07-08 11:21:31] {2219} INFO - iteration 55, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 11:21:31] {2392} INFO -  at 255.3s,\testimator extra_tree's best error=0.1412,\tbest estimator lgbm's best error=0.1218\n",
            "[flaml.automl.logger: 07-08 11:21:31] {2219} INFO - iteration 56, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:23:51] {2392} INFO -  at 395.2s,\testimator lgbm's best error=0.1217,\tbest estimator lgbm's best error=0.1217\n",
            "[flaml.automl.logger: 07-08 11:23:51] {2219} INFO - iteration 57, current learner catboost\n",
            "[flaml.automl.logger: 07-08 11:23:52] {2392} INFO -  at 396.1s,\testimator catboost's best error=0.1399,\tbest estimator lgbm's best error=0.1217\n",
            "[flaml.automl.logger: 07-08 11:23:52] {2219} INFO - iteration 58, current learner catboost\n",
            "[flaml.automl.logger: 07-08 11:23:56] {2392} INFO -  at 400.1s,\testimator catboost's best error=0.1399,\tbest estimator lgbm's best error=0.1217\n",
            "[flaml.automl.logger: 07-08 11:23:56] {2219} INFO - iteration 59, current learner catboost\n",
            "[flaml.automl.logger: 07-08 11:23:58] {2392} INFO -  at 402.0s,\testimator catboost's best error=0.1316,\tbest estimator lgbm's best error=0.1217\n",
            "[flaml.automl.logger: 07-08 11:23:58] {2219} INFO - iteration 60, current learner rf\n",
            "[flaml.automl.logger: 07-08 11:23:59] {2392} INFO -  at 402.8s,\testimator rf's best error=0.1421,\tbest estimator lgbm's best error=0.1217\n",
            "[flaml.automl.logger: 07-08 11:23:59] {2219} INFO - iteration 61, current learner catboost\n",
            "[flaml.automl.logger: 07-08 11:24:21] {2392} INFO -  at 425.3s,\testimator catboost's best error=0.1316,\tbest estimator lgbm's best error=0.1217\n",
            "[flaml.automl.logger: 07-08 11:24:21] {2219} INFO - iteration 62, current learner rf\n",
            "[flaml.automl.logger: 07-08 11:24:22] {2392} INFO -  at 425.9s,\testimator rf's best error=0.1421,\tbest estimator lgbm's best error=0.1217\n",
            "[flaml.automl.logger: 07-08 11:24:22] {2219} INFO - iteration 63, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 11:24:23] {2392} INFO -  at 426.4s,\testimator xgboost's best error=0.1360,\tbest estimator lgbm's best error=0.1217\n",
            "[flaml.automl.logger: 07-08 11:24:23] {2219} INFO - iteration 64, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 11:24:24] {2392} INFO -  at 427.4s,\testimator xgboost's best error=0.1360,\tbest estimator lgbm's best error=0.1217\n",
            "[flaml.automl.logger: 07-08 11:24:24] {2219} INFO - iteration 65, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:27:12] {2392} INFO -  at 595.6s,\testimator lgbm's best error=0.1212,\tbest estimator lgbm's best error=0.1212\n",
            "[flaml.automl.logger: 07-08 11:27:12] {2219} INFO - iteration 66, current learner catboost\n",
            "[flaml.automl.logger: 07-08 11:27:20] {2392} INFO -  at 603.4s,\testimator catboost's best error=0.1248,\tbest estimator lgbm's best error=0.1212\n",
            "[flaml.automl.logger: 07-08 11:27:20] {2219} INFO - iteration 67, current learner catboost\n",
            "[flaml.automl.logger: 07-08 11:27:52] {2392} INFO -  at 636.1s,\testimator catboost's best error=0.1248,\tbest estimator lgbm's best error=0.1212\n",
            "[flaml.automl.logger: 07-08 11:27:52] {2219} INFO - iteration 68, current learner catboost\n",
            "[flaml.automl.logger: 07-08 11:28:07] {2392} INFO -  at 651.2s,\testimator catboost's best error=0.1242,\tbest estimator lgbm's best error=0.1212\n",
            "[flaml.automl.logger: 07-08 11:28:07] {2219} INFO - iteration 69, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:30:23] {2392} INFO -  at 787.3s,\testimator lgbm's best error=0.1212,\tbest estimator lgbm's best error=0.1212\n",
            "[flaml.automl.logger: 07-08 11:30:23] {2219} INFO - iteration 70, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 11:30:24] {2392} INFO -  at 787.8s,\testimator xgboost's best error=0.1360,\tbest estimator lgbm's best error=0.1212\n",
            "[flaml.automl.logger: 07-08 11:30:24] {2219} INFO - iteration 71, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 11:30:25] {2392} INFO -  at 788.8s,\testimator xgboost's best error=0.1360,\tbest estimator lgbm's best error=0.1212\n",
            "[flaml.automl.logger: 07-08 11:30:25] {2219} INFO - iteration 72, current learner catboost\n",
            "[flaml.automl.logger: 07-08 11:30:36] {2392} INFO -  at 799.6s,\testimator catboost's best error=0.1213,\tbest estimator lgbm's best error=0.1212\n",
            "[flaml.automl.logger: 07-08 11:30:36] {2219} INFO - iteration 73, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 11:30:37] {2392} INFO -  at 800.4s,\testimator xgboost's best error=0.1353,\tbest estimator lgbm's best error=0.1212\n",
            "[flaml.automl.logger: 07-08 11:30:37] {2219} INFO - iteration 74, current learner catboost\n",
            "[flaml.automl.logger: 07-08 11:31:54] {2392} INFO -  at 878.1s,\testimator catboost's best error=0.1213,\tbest estimator lgbm's best error=0.1212\n",
            "[flaml.automl.logger: 07-08 11:31:54] {2219} INFO - iteration 75, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 11:31:55] {2392} INFO -  at 878.8s,\testimator xgboost's best error=0.1353,\tbest estimator lgbm's best error=0.1212\n",
            "[flaml.automl.logger: 07-08 11:31:55] {2219} INFO - iteration 76, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:33:09] {2392} INFO -  at 952.7s,\testimator lgbm's best error=0.1206,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:33:09] {2219} INFO - iteration 77, current learner rf\n",
            "[flaml.automl.logger: 07-08 11:33:10] {2392} INFO -  at 953.4s,\testimator rf's best error=0.1409,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:33:10] {2219} INFO - iteration 78, current learner catboost\n",
            "[flaml.automl.logger: 07-08 11:33:37] {2392} INFO -  at 980.7s,\testimator catboost's best error=0.1213,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:33:37] {2219} INFO - iteration 79, current learner rf\n",
            "[flaml.automl.logger: 07-08 11:33:37] {2392} INFO -  at 981.3s,\testimator rf's best error=0.1409,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:33:37] {2219} INFO - iteration 80, current learner rf\n",
            "[flaml.automl.logger: 07-08 11:33:38] {2392} INFO -  at 982.1s,\testimator rf's best error=0.1401,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:33:38] {2219} INFO - iteration 81, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 11:33:39] {2392} INFO -  at 982.8s,\testimator extra_tree's best error=0.1412,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:33:39] {2219} INFO - iteration 82, current learner rf\n",
            "[flaml.automl.logger: 07-08 11:33:40] {2392} INFO -  at 983.6s,\testimator rf's best error=0.1401,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:33:40] {2219} INFO - iteration 83, current learner catboost\n",
            "[flaml.automl.logger: 07-08 11:35:03] {2392} INFO -  at 1066.6s,\testimator catboost's best error=0.1213,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:35:03] {2219} INFO - iteration 84, current learner catboost\n",
            "[flaml.automl.logger: 07-08 11:35:04] {2392} INFO -  at 1067.5s,\testimator catboost's best error=0.1213,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:35:04] {2219} INFO - iteration 85, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 11:35:05] {2392} INFO -  at 1069.1s,\testimator xgboost's best error=0.1323,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:35:05] {2219} INFO - iteration 86, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 11:35:09] {2392} INFO -  at 1073.1s,\testimator xgboost's best error=0.1297,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:35:09] {2219} INFO - iteration 87, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 11:35:11] {2392} INFO -  at 1074.4s,\testimator xgboost's best error=0.1297,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:35:11] {2219} INFO - iteration 88, current learner catboost\n",
            "[flaml.automl.logger: 07-08 11:35:11] {2392} INFO -  at 1074.9s,\testimator catboost's best error=0.1213,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:35:11] {2219} INFO - iteration 89, current learner catboost\n",
            "[flaml.automl.logger: 07-08 11:35:16] {2392} INFO -  at 1080.3s,\testimator catboost's best error=0.1213,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:35:16] {2219} INFO - iteration 90, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 11:35:23] {2392} INFO -  at 1086.4s,\testimator xgboost's best error=0.1297,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:35:23] {2219} INFO - iteration 91, current learner catboost\n",
            "[flaml.automl.logger: 07-08 11:35:24] {2392} INFO -  at 1088.3s,\testimator catboost's best error=0.1213,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:35:24] {2219} INFO - iteration 92, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 11:35:25] {2392} INFO -  at 1088.9s,\testimator extra_tree's best error=0.1412,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:35:25] {2219} INFO - iteration 93, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 11:35:28] {2392} INFO -  at 1091.7s,\testimator xgboost's best error=0.1297,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:35:28] {2219} INFO - iteration 94, current learner catboost\n",
            "[flaml.automl.logger: 07-08 11:35:52] {2392} INFO -  at 1115.6s,\testimator catboost's best error=0.1213,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:35:52] {2219} INFO - iteration 95, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:39:18] {2392} INFO -  at 1321.6s,\testimator lgbm's best error=0.1206,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:39:18] {2219} INFO - iteration 96, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 11:39:20] {2392} INFO -  at 1323.9s,\testimator xgboost's best error=0.1297,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:39:20] {2219} INFO - iteration 97, current learner catboost\n",
            "[flaml.automl.logger: 07-08 11:39:27] {2392} INFO -  at 1331.1s,\testimator catboost's best error=0.1213,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:39:27] {2219} INFO - iteration 98, current learner catboost\n",
            "[flaml.automl.logger: 07-08 11:40:16] {2392} INFO -  at 1379.4s,\testimator catboost's best error=0.1213,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:40:16] {2219} INFO - iteration 99, current learner rf\n",
            "[flaml.automl.logger: 07-08 11:40:16] {2392} INFO -  at 1380.2s,\testimator rf's best error=0.1401,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:40:16] {2219} INFO - iteration 100, current learner rf\n",
            "[flaml.automl.logger: 07-08 11:40:17] {2392} INFO -  at 1381.0s,\testimator rf's best error=0.1401,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:40:17] {2219} INFO - iteration 101, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 11:40:26] {2392} INFO -  at 1389.5s,\testimator xgboost's best error=0.1293,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:40:26] {2219} INFO - iteration 102, current learner catboost\n",
            "[flaml.automl.logger: 07-08 11:40:35] {2392} INFO -  at 1398.8s,\testimator catboost's best error=0.1213,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:40:35] {2219} INFO - iteration 103, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:41:54] {2392} INFO -  at 1478.0s,\testimator lgbm's best error=0.1206,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:41:54] {2219} INFO - iteration 104, current learner catboost\n",
            "[flaml.automl.logger: 07-08 11:42:14] {2392} INFO -  at 1497.5s,\testimator catboost's best error=0.1209,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:42:14] {2219} INFO - iteration 105, current learner rf\n",
            "[flaml.automl.logger: 07-08 11:42:14] {2392} INFO -  at 1498.3s,\testimator rf's best error=0.1401,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:42:14] {2219} INFO - iteration 106, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 11:42:15] {2392} INFO -  at 1498.8s,\testimator xgb_limitdepth's best error=0.1391,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:42:15] {2219} INFO - iteration 107, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 11:42:15] {2392} INFO -  at 1499.3s,\testimator xgb_limitdepth's best error=0.1375,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:42:15] {2219} INFO - iteration 108, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 11:42:16] {2392} INFO -  at 1499.9s,\testimator xgb_limitdepth's best error=0.1375,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:42:16] {2219} INFO - iteration 109, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 11:42:17] {2392} INFO -  at 1500.4s,\testimator xgb_limitdepth's best error=0.1375,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:42:17] {2219} INFO - iteration 110, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 11:42:17] {2392} INFO -  at 1501.1s,\testimator xgb_limitdepth's best error=0.1375,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:42:17] {2219} INFO - iteration 111, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 11:42:18] {2392} INFO -  at 1501.6s,\testimator xgb_limitdepth's best error=0.1375,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:42:18] {2219} INFO - iteration 112, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:46:22] {2392} INFO -  at 1745.6s,\testimator lgbm's best error=0.1206,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:46:22] {2219} INFO - iteration 113, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 11:46:22] {2392} INFO -  at 1746.3s,\testimator xgb_limitdepth's best error=0.1353,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:46:22] {2219} INFO - iteration 114, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 11:46:23] {2392} INFO -  at 1747.0s,\testimator xgb_limitdepth's best error=0.1353,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:46:23] {2219} INFO - iteration 115, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 11:46:24] {2392} INFO -  at 1747.6s,\testimator xgb_limitdepth's best error=0.1353,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:46:24] {2219} INFO - iteration 116, current learner rf\n",
            "[flaml.automl.logger: 07-08 11:46:25] {2392} INFO -  at 1748.4s,\testimator rf's best error=0.1401,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:46:25] {2219} INFO - iteration 117, current learner rf\n",
            "[flaml.automl.logger: 07-08 11:46:25] {2392} INFO -  at 1749.3s,\testimator rf's best error=0.1358,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:46:25] {2219} INFO - iteration 118, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 11:46:26] {2392} INFO -  at 1749.9s,\testimator xgb_limitdepth's best error=0.1353,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:46:26] {2219} INFO - iteration 119, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 11:46:27] {2392} INFO -  at 1750.5s,\testimator extra_tree's best error=0.1412,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:46:27] {2219} INFO - iteration 120, current learner rf\n",
            "[flaml.automl.logger: 07-08 11:46:28] {2392} INFO -  at 1751.4s,\testimator rf's best error=0.1358,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:46:28] {2219} INFO - iteration 121, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 11:46:28] {2392} INFO -  at 1752.3s,\testimator xgb_limitdepth's best error=0.1345,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:46:28] {2219} INFO - iteration 122, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 11:46:29] {2392} INFO -  at 1752.9s,\testimator xgb_limitdepth's best error=0.1345,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:46:29] {2219} INFO - iteration 123, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 11:46:30] {2392} INFO -  at 1754.3s,\testimator xgb_limitdepth's best error=0.1303,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:46:30] {2219} INFO - iteration 124, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 11:46:31] {2392} INFO -  at 1754.9s,\testimator xgb_limitdepth's best error=0.1303,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:46:31] {2219} INFO - iteration 125, current learner rf\n",
            "[flaml.automl.logger: 07-08 11:46:32] {2392} INFO -  at 1756.0s,\testimator rf's best error=0.1352,\tbest estimator lgbm's best error=0.1206\n",
            "[flaml.automl.logger: 07-08 11:46:32] {2219} INFO - iteration 126, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:50:30] {2392} INFO -  at 1994.2s,\testimator lgbm's best error=0.1175,\tbest estimator lgbm's best error=0.1175\n",
            "[flaml.automl.logger: 07-08 11:50:30] {2219} INFO - iteration 127, current learner rf\n",
            "[flaml.automl.logger: 07-08 11:50:32] {2392} INFO -  at 1995.6s,\testimator rf's best error=0.1349,\tbest estimator lgbm's best error=0.1175\n",
            "[flaml.automl.logger: 07-08 11:50:32] {2219} INFO - iteration 128, current learner rf\n",
            "[flaml.automl.logger: 07-08 11:50:33] {2392} INFO -  at 1996.8s,\testimator rf's best error=0.1342,\tbest estimator lgbm's best error=0.1175\n",
            "[flaml.automl.logger: 07-08 11:50:33] {2219} INFO - iteration 129, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 11:50:34] {2392} INFO -  at 1997.5s,\testimator extra_tree's best error=0.1386,\tbest estimator lgbm's best error=0.1175\n",
            "[flaml.automl.logger: 07-08 11:50:34] {2219} INFO - iteration 130, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 11:50:37] {2392} INFO -  at 2000.8s,\testimator xgb_limitdepth's best error=0.1299,\tbest estimator lgbm's best error=0.1175\n",
            "[flaml.automl.logger: 07-08 11:50:37] {2219} INFO - iteration 131, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 11:50:38] {2392} INFO -  at 2001.5s,\testimator extra_tree's best error=0.1386,\tbest estimator lgbm's best error=0.1175\n",
            "[flaml.automl.logger: 07-08 11:50:38] {2219} INFO - iteration 132, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 11:50:38] {2392} INFO -  at 2002.1s,\testimator extra_tree's best error=0.1375,\tbest estimator lgbm's best error=0.1175\n",
            "[flaml.automl.logger: 07-08 11:50:38] {2219} INFO - iteration 133, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 11:50:39] {2392} INFO -  at 2002.8s,\testimator extra_tree's best error=0.1375,\tbest estimator lgbm's best error=0.1175\n",
            "[flaml.automl.logger: 07-08 11:50:39] {2219} INFO - iteration 134, current learner rf\n",
            "[flaml.automl.logger: 07-08 11:50:40] {2392} INFO -  at 2003.6s,\testimator rf's best error=0.1342,\tbest estimator lgbm's best error=0.1175\n",
            "[flaml.automl.logger: 07-08 11:50:40] {2219} INFO - iteration 135, current learner rf\n",
            "[flaml.automl.logger: 07-08 11:50:41] {2392} INFO -  at 2005.1s,\testimator rf's best error=0.1342,\tbest estimator lgbm's best error=0.1175\n",
            "[flaml.automl.logger: 07-08 11:50:41] {2219} INFO - iteration 136, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 11:50:42] {2392} INFO -  at 2005.9s,\testimator extra_tree's best error=0.1355,\tbest estimator lgbm's best error=0.1175\n",
            "[flaml.automl.logger: 07-08 11:50:42] {2219} INFO - iteration 137, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 11:50:44] {2392} INFO -  at 2008.2s,\testimator xgb_limitdepth's best error=0.1299,\tbest estimator lgbm's best error=0.1175\n",
            "[flaml.automl.logger: 07-08 11:50:44] {2219} INFO - iteration 138, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 11:50:45] {2392} INFO -  at 2009.0s,\testimator extra_tree's best error=0.1343,\tbest estimator lgbm's best error=0.1175\n",
            "[flaml.automl.logger: 07-08 11:50:45] {2219} INFO - iteration 139, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:52:51] {2392} INFO -  at 2135.0s,\testimator lgbm's best error=0.1175,\tbest estimator lgbm's best error=0.1175\n",
            "[flaml.automl.logger: 07-08 11:52:51] {2219} INFO - iteration 140, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 11:52:52] {2392} INFO -  at 2135.7s,\testimator extra_tree's best error=0.1343,\tbest estimator lgbm's best error=0.1175\n",
            "[flaml.automl.logger: 07-08 11:52:52] {2219} INFO - iteration 141, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 11:52:59] {2392} INFO -  at 2142.7s,\testimator xgboost's best error=0.1293,\tbest estimator lgbm's best error=0.1175\n",
            "[flaml.automl.logger: 07-08 11:52:59] {2219} INFO - iteration 142, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 11:53:00] {2392} INFO -  at 2143.5s,\testimator extra_tree's best error=0.1343,\tbest estimator lgbm's best error=0.1175\n",
            "[flaml.automl.logger: 07-08 11:53:00] {2219} INFO - iteration 143, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 11:53:01] {2392} INFO -  at 2144.5s,\testimator extra_tree's best error=0.1343,\tbest estimator lgbm's best error=0.1175\n",
            "[flaml.automl.logger: 07-08 11:53:01] {2219} INFO - iteration 144, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 11:53:01] {2392} INFO -  at 2145.3s,\testimator extra_tree's best error=0.1343,\tbest estimator lgbm's best error=0.1175\n",
            "[flaml.automl.logger: 07-08 11:53:01] {2219} INFO - iteration 145, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 11:53:03] {2392} INFO -  at 2147.2s,\testimator extra_tree's best error=0.1320,\tbest estimator lgbm's best error=0.1175\n",
            "[flaml.automl.logger: 07-08 11:53:03] {2219} INFO - iteration 146, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 11:53:05] {2392} INFO -  at 2148.6s,\testimator extra_tree's best error=0.1320,\tbest estimator lgbm's best error=0.1175\n",
            "[flaml.automl.logger: 07-08 11:53:05] {2219} INFO - iteration 147, current learner rf\n",
            "[flaml.automl.logger: 07-08 11:53:06] {2392} INFO -  at 2149.5s,\testimator rf's best error=0.1342,\tbest estimator lgbm's best error=0.1175\n",
            "[flaml.automl.logger: 07-08 11:53:06] {2219} INFO - iteration 148, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 11:57:52] {2392} INFO -  at 2436.0s,\testimator lgbm's best error=0.1165,\tbest estimator lgbm's best error=0.1165\n",
            "[flaml.automl.logger: 07-08 11:57:52] {2219} INFO - iteration 149, current learner rf\n",
            "[flaml.automl.logger: 07-08 11:57:54] {2392} INFO -  at 2437.8s,\testimator rf's best error=0.1341,\tbest estimator lgbm's best error=0.1165\n",
            "[flaml.automl.logger: 07-08 11:57:54] {2219} INFO - iteration 150, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 12:14:44] {2392} INFO -  at 3447.7s,\testimator lgbm's best error=0.1165,\tbest estimator lgbm's best error=0.1165\n",
            "[flaml.automl.logger: 07-08 12:14:44] {2219} INFO - iteration 151, current learner catboost\n",
            "[flaml.automl.logger: 07-08 12:14:56] {2392} INFO -  at 3460.3s,\testimator catboost's best error=0.1209,\tbest estimator lgbm's best error=0.1165\n",
            "[flaml.automl.logger: 07-08 12:14:56] {2219} INFO - iteration 152, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 12:15:00] {2392} INFO -  at 3463.6s,\testimator extra_tree's best error=0.1320,\tbest estimator lgbm's best error=0.1165\n",
            "[flaml.automl.logger: 07-08 12:15:00] {2219} INFO - iteration 153, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 12:15:03] {2392} INFO -  at 3466.8s,\testimator extra_tree's best error=0.1320,\tbest estimator lgbm's best error=0.1165\n",
            "[flaml.automl.logger: 07-08 12:15:03] {2219} INFO - iteration 154, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 12:15:12] {2392} INFO -  at 3475.9s,\testimator extra_tree's best error=0.1313,\tbest estimator lgbm's best error=0.1165\n",
            "[flaml.automl.logger: 07-08 12:15:12] {2219} INFO - iteration 155, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 12:16:05] {2392} INFO -  at 3528.7s,\testimator lgbm's best error=0.1165,\tbest estimator lgbm's best error=0.1165\n",
            "[flaml.automl.logger: 07-08 12:16:05] {2219} INFO - iteration 156, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 12:20:43] {2392} INFO -  at 3806.6s,\testimator lgbm's best error=0.1165,\tbest estimator lgbm's best error=0.1165\n",
            "[flaml.automl.logger: 07-08 12:20:43] {2219} INFO - iteration 157, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 12:20:50] {2392} INFO -  at 3813.8s,\testimator xgb_limitdepth's best error=0.1299,\tbest estimator lgbm's best error=0.1165\n",
            "[flaml.automl.logger: 07-08 12:20:50] {2219} INFO - iteration 158, current learner lrl1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[flaml.automl.logger: 07-08 12:20:52] {2392} INFO -  at 3816.1s,\testimator lrl1's best error=0.2763,\tbest estimator lgbm's best error=0.1165\n",
            "[flaml.automl.logger: 07-08 12:20:52] {2219} INFO - iteration 159, current learner lrl1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[flaml.automl.logger: 07-08 12:20:54] {2392} INFO -  at 3818.3s,\testimator lrl1's best error=0.2763,\tbest estimator lgbm's best error=0.1165\n",
            "[flaml.automl.logger: 07-08 12:20:54] {2219} INFO - iteration 160, current learner lrl1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[flaml.automl.logger: 07-08 12:20:57] {2392} INFO -  at 3820.5s,\testimator lrl1's best error=0.2763,\tbest estimator lgbm's best error=0.1165\n",
            "[flaml.automl.logger: 07-08 12:20:57] {2219} INFO - iteration 161, current learner lrl1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[flaml.automl.logger: 07-08 12:21:04] {2392} INFO -  at 3827.4s,\testimator lrl1's best error=0.2585,\tbest estimator lgbm's best error=0.1165\n",
            "[flaml.automl.logger: 07-08 12:21:04] {2219} INFO - iteration 162, current learner lrl1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[flaml.automl.logger: 07-08 12:21:10] {2392} INFO -  at 3833.4s,\testimator lrl1's best error=0.2585,\tbest estimator lgbm's best error=0.1165\n",
            "[flaml.automl.logger: 07-08 12:21:10] {2219} INFO - iteration 163, current learner rf\n",
            "[flaml.automl.logger: 07-08 12:21:11] {2392} INFO -  at 3834.4s,\testimator rf's best error=0.1341,\tbest estimator lgbm's best error=0.1165\n",
            "[flaml.automl.logger: 07-08 12:21:11] {2219} INFO - iteration 164, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 12:21:21] {2392} INFO -  at 3845.3s,\testimator extra_tree's best error=0.1305,\tbest estimator lgbm's best error=0.1165\n",
            "[flaml.automl.logger: 07-08 12:21:21] {2219} INFO - iteration 165, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 12:21:48] {2392} INFO -  at 3871.7s,\testimator xgb_limitdepth's best error=0.1299,\tbest estimator lgbm's best error=0.1165\n",
            "[flaml.automl.logger: 07-08 12:21:48] {2219} INFO - iteration 166, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 12:21:54] {2392} INFO -  at 3878.3s,\testimator extra_tree's best error=0.1305,\tbest estimator lgbm's best error=0.1165\n",
            "[flaml.automl.logger: 07-08 12:21:54] {2219} INFO - iteration 167, current learner rf\n",
            "[flaml.automl.logger: 07-08 12:21:57] {2392} INFO -  at 3881.0s,\testimator rf's best error=0.1341,\tbest estimator lgbm's best error=0.1165\n",
            "[flaml.automl.logger: 07-08 12:21:57] {2219} INFO - iteration 168, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 12:22:04] {2392} INFO -  at 3888.3s,\testimator extra_tree's best error=0.1305,\tbest estimator lgbm's best error=0.1165\n",
            "[flaml.automl.logger: 07-08 12:22:04] {2219} INFO - iteration 169, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 12:22:28] {2392} INFO -  at 3911.4s,\testimator extra_tree's best error=0.1304,\tbest estimator lgbm's best error=0.1165\n",
            "[flaml.automl.logger: 07-08 12:22:28] {2219} INFO - iteration 170, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 12:22:41] {2392} INFO -  at 3925.3s,\testimator extra_tree's best error=0.1304,\tbest estimator lgbm's best error=0.1165\n",
            "[flaml.automl.logger: 07-08 12:22:41] {2219} INFO - iteration 171, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 12:48:31] {2392} INFO -  at 5475.2s,\testimator lgbm's best error=0.1147,\tbest estimator lgbm's best error=0.1147\n",
            "[flaml.automl.logger: 07-08 12:48:31] {2219} INFO - iteration 172, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 13:36:28] {2392} INFO -  at 8352.2s,\testimator lgbm's best error=0.1132,\tbest estimator lgbm's best error=0.1132\n",
            "[flaml.automl.logger: 07-08 13:36:28] {2219} INFO - iteration 173, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 13:53:42] {2392} INFO -  at 9386.2s,\testimator lgbm's best error=0.1132,\tbest estimator lgbm's best error=0.1132\n",
            "[flaml.automl.logger: 07-08 13:53:42] {2219} INFO - iteration 174, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 13:53:47] {2392} INFO -  at 9390.8s,\testimator xgboost's best error=0.1293,\tbest estimator lgbm's best error=0.1132\n",
            "[flaml.automl.logger: 07-08 13:53:47] {2219} INFO - iteration 175, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 13:53:48] {2392} INFO -  at 9392.0s,\testimator xgboost's best error=0.1293,\tbest estimator lgbm's best error=0.1132\n",
            "[flaml.automl.logger: 07-08 13:53:48] {2219} INFO - iteration 176, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 13:54:21] {2392} INFO -  at 9424.9s,\testimator xgboost's best error=0.1293,\tbest estimator lgbm's best error=0.1132\n",
            "[flaml.automl.logger: 07-08 13:54:21] {2219} INFO - iteration 177, current learner rf\n",
            "[flaml.automl.logger: 07-08 13:54:23] {2392} INFO -  at 9427.1s,\testimator rf's best error=0.1341,\tbest estimator lgbm's best error=0.1132\n",
            "[flaml.automl.logger: 07-08 13:54:23] {2219} INFO - iteration 178, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 13:54:28] {2392} INFO -  at 9432.2s,\testimator xgb_limitdepth's best error=0.1224,\tbest estimator lgbm's best error=0.1132\n",
            "[flaml.automl.logger: 07-08 13:54:28] {2219} INFO - iteration 179, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 13:54:34] {2392} INFO -  at 9437.5s,\testimator xgb_limitdepth's best error=0.1224,\tbest estimator lgbm's best error=0.1132\n",
            "[flaml.automl.logger: 07-08 13:54:34] {2219} INFO - iteration 180, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 13:54:38] {2392} INFO -  at 9441.7s,\testimator xgb_limitdepth's best error=0.1224,\tbest estimator lgbm's best error=0.1132\n",
            "[flaml.automl.logger: 07-08 13:54:38] {2219} INFO - iteration 181, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 13:54:40] {2392} INFO -  at 9443.8s,\testimator xgb_limitdepth's best error=0.1224,\tbest estimator lgbm's best error=0.1132\n",
            "[flaml.automl.logger: 07-08 13:54:40] {2219} INFO - iteration 182, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 13:54:52] {2392} INFO -  at 9456.2s,\testimator xgb_limitdepth's best error=0.1221,\tbest estimator lgbm's best error=0.1132\n",
            "[flaml.automl.logger: 07-08 13:54:52] {2219} INFO - iteration 183, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 13:55:10] {2392} INFO -  at 9474.0s,\testimator xgb_limitdepth's best error=0.1221,\tbest estimator lgbm's best error=0.1132\n",
            "[flaml.automl.logger: 07-08 13:55:10] {2219} INFO - iteration 184, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 14:22:14] {2392} INFO -  at 11097.9s,\testimator lgbm's best error=0.1124,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 14:22:14] {2219} INFO - iteration 185, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 15:08:18] {2392} INFO -  at 13861.7s,\testimator lgbm's best error=0.1124,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:08:18] {2219} INFO - iteration 186, current learner rf\n",
            "[flaml.automl.logger: 07-08 15:08:19] {2392} INFO -  at 13862.8s,\testimator rf's best error=0.1341,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:08:19] {2219} INFO - iteration 187, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 15:08:27] {2392} INFO -  at 13871.0s,\testimator xgboost's best error=0.1238,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:08:27] {2219} INFO - iteration 188, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 15:08:35] {2392} INFO -  at 13878.9s,\testimator xgboost's best error=0.1238,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:08:35] {2219} INFO - iteration 189, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 15:08:48] {2392} INFO -  at 13892.3s,\testimator xgboost's best error=0.1222,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:08:48] {2219} INFO - iteration 190, current learner lgbm\n",
            "[flaml.automl.logger: 07-08 15:54:35] {2392} INFO -  at 16639.0s,\testimator lgbm's best error=0.1124,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:54:35] {2219} INFO - iteration 191, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 15:54:53] {2392} INFO -  at 16657.2s,\testimator xgboost's best error=0.1222,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:54:53] {2219} INFO - iteration 192, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 15:54:58] {2392} INFO -  at 16662.0s,\testimator xgboost's best error=0.1222,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:54:58] {2219} INFO - iteration 193, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 15:55:09] {2392} INFO -  at 16672.9s,\testimator xgboost's best error=0.1222,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:55:09] {2219} INFO - iteration 194, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 15:55:27] {2392} INFO -  at 16691.0s,\testimator xgboost's best error=0.1222,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:55:27] {2219} INFO - iteration 195, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 15:55:45] {2392} INFO -  at 16708.7s,\testimator xgboost's best error=0.1221,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:55:45] {2219} INFO - iteration 196, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 15:55:58] {2392} INFO -  at 16722.0s,\testimator xgb_limitdepth's best error=0.1216,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:55:58] {2219} INFO - iteration 197, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 15:56:30] {2392} INFO -  at 16754.0s,\testimator extra_tree's best error=0.1303,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:56:30] {2219} INFO - iteration 198, current learner rf\n",
            "[flaml.automl.logger: 07-08 15:56:31] {2392} INFO -  at 16755.3s,\testimator rf's best error=0.1341,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:56:31] {2219} INFO - iteration 199, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 15:56:34] {2392} INFO -  at 16757.7s,\testimator xgb_limitdepth's best error=0.1216,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:56:34] {2219} INFO - iteration 200, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 15:56:50] {2392} INFO -  at 16774.2s,\testimator xgb_limitdepth's best error=0.1216,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:56:50] {2219} INFO - iteration 201, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 15:57:01] {2392} INFO -  at 16784.8s,\testimator xgb_limitdepth's best error=0.1216,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:57:01] {2219} INFO - iteration 202, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 15:57:17] {2392} INFO -  at 16800.5s,\testimator xgb_limitdepth's best error=0.1216,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:57:17] {2219} INFO - iteration 203, current learner rf\n",
            "[flaml.automl.logger: 07-08 15:57:21] {2392} INFO -  at 16804.6s,\testimator rf's best error=0.1322,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:57:21] {2219} INFO - iteration 204, current learner rf\n",
            "[flaml.automl.logger: 07-08 15:57:23] {2392} INFO -  at 16806.8s,\testimator rf's best error=0.1322,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:57:23] {2219} INFO - iteration 205, current learner rf\n",
            "[flaml.automl.logger: 07-08 15:57:32] {2392} INFO -  at 16815.4s,\testimator rf's best error=0.1322,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:57:32] {2219} INFO - iteration 206, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 15:57:47] {2392} INFO -  at 16830.9s,\testimator xgb_limitdepth's best error=0.1212,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:57:47] {2219} INFO - iteration 207, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 15:58:00] {2392} INFO -  at 16843.8s,\testimator xgb_limitdepth's best error=0.1212,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:58:00] {2219} INFO - iteration 208, current learner rf\n",
            "[flaml.automl.logger: 07-08 15:58:03] {2392} INFO -  at 16846.7s,\testimator rf's best error=0.1322,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:58:03] {2219} INFO - iteration 209, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 15:58:18] {2392} INFO -  at 16861.8s,\testimator xgb_limitdepth's best error=0.1212,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:58:18] {2219} INFO - iteration 210, current learner rf\n",
            "[flaml.automl.logger: 07-08 15:58:21] {2392} INFO -  at 16864.6s,\testimator rf's best error=0.1319,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:58:21] {2219} INFO - iteration 211, current learner rf\n",
            "[flaml.automl.logger: 07-08 15:58:32] {2392} INFO -  at 16875.5s,\testimator rf's best error=0.1316,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:58:32] {2219} INFO - iteration 212, current learner rf\n",
            "[flaml.automl.logger: 07-08 15:58:35] {2392} INFO -  at 16878.6s,\testimator rf's best error=0.1316,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:58:35] {2219} INFO - iteration 213, current learner catboost\n",
            "[flaml.automl.logger: 07-08 15:59:29] {2392} INFO -  at 16933.3s,\testimator catboost's best error=0.1209,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:59:29] {2219} INFO - iteration 214, current learner rf\n",
            "[flaml.automl.logger: 07-08 15:59:41] {2392} INFO -  at 16944.5s,\testimator rf's best error=0.1307,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:59:41] {2219} INFO - iteration 215, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 15:59:55] {2392} INFO -  at 16958.4s,\testimator xgb_limitdepth's best error=0.1212,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 15:59:55] {2219} INFO - iteration 216, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 16:00:08] {2392} INFO -  at 16972.2s,\testimator xgb_limitdepth's best error=0.1212,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 16:00:08] {2219} INFO - iteration 217, current learner rf\n",
            "[flaml.automl.logger: 07-08 16:00:18] {2392} INFO -  at 16981.6s,\testimator rf's best error=0.1307,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 16:00:18] {2219} INFO - iteration 218, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 16:00:31] {2392} INFO -  at 16995.1s,\testimator xgb_limitdepth's best error=0.1212,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 16:00:31] {2219} INFO - iteration 219, current learner rf\n",
            "[flaml.automl.logger: 07-08 16:00:47] {2392} INFO -  at 17011.1s,\testimator rf's best error=0.1307,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 16:00:47] {2219} INFO - iteration 220, current learner rf\n",
            "[flaml.automl.logger: 07-08 16:00:54] {2392} INFO -  at 17018.3s,\testimator rf's best error=0.1307,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 16:00:54] {2219} INFO - iteration 221, current learner rf\n",
            "[flaml.automl.logger: 07-08 16:01:11] {2392} INFO -  at 17034.9s,\testimator rf's best error=0.1307,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 16:01:11] {2219} INFO - iteration 222, current learner catboost\n",
            "[flaml.automl.logger: 07-08 16:01:23] {2392} INFO -  at 17046.9s,\testimator catboost's best error=0.1209,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 16:01:23] {2219} INFO - iteration 223, current learner rf\n",
            "[flaml.automl.logger: 07-08 16:02:14] {2392} INFO -  at 17097.7s,\testimator rf's best error=0.1292,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 16:02:14] {2219} INFO - iteration 224, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 16:02:59] {2392} INFO -  at 17142.4s,\testimator xgb_limitdepth's best error=0.1188,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 16:02:59] {2219} INFO - iteration 225, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 16:03:41] {2392} INFO -  at 17184.5s,\testimator xgb_limitdepth's best error=0.1188,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 16:03:41] {2219} INFO - iteration 226, current learner rf\n",
            "[flaml.automl.logger: 07-08 16:04:04] {2392} INFO -  at 17207.4s,\testimator rf's best error=0.1292,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 16:04:04] {2219} INFO - iteration 227, current learner rf\n",
            "[flaml.automl.logger: 07-08 16:05:39] {2392} INFO -  at 17302.8s,\testimator rf's best error=0.1282,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 16:05:39] {2219} INFO - iteration 228, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 16:06:13] {2392} INFO -  at 17337.3s,\testimator xgb_limitdepth's best error=0.1188,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 16:06:13] {2219} INFO - iteration 229, current learner rf\n",
            "[flaml.automl.logger: 07-08 16:07:01] {2392} INFO -  at 17385.2s,\testimator rf's best error=0.1282,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 16:07:01] {2219} INFO - iteration 230, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 16:07:32] {2392} INFO -  at 17415.8s,\testimator xgb_limitdepth's best error=0.1187,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 16:07:32] {2219} INFO - iteration 231, current learner rf\n",
            "[flaml.automl.logger: 07-08 16:10:19] {2392} INFO -  at 17582.5s,\testimator rf's best error=0.1282,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 16:10:19] {2219} INFO - iteration 232, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 16:10:39] {2392} INFO -  at 17603.1s,\testimator xgb_limitdepth's best error=0.1187,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 16:10:39] {2219} INFO - iteration 233, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 16:11:02] {2392} INFO -  at 17626.1s,\testimator extra_tree's best error=0.1303,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 16:11:02] {2219} INFO - iteration 234, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 16:11:21] {2392} INFO -  at 17645.0s,\testimator xgb_limitdepth's best error=0.1187,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 16:11:21] {2219} INFO - iteration 235, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 16:11:39] {2392} INFO -  at 17662.8s,\testimator xgb_limitdepth's best error=0.1187,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 16:11:39] {2219} INFO - iteration 236, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-08 16:11:54] {2392} INFO -  at 17678.3s,\testimator xgb_limitdepth's best error=0.1187,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 16:11:54] {2219} INFO - iteration 237, current learner catboost\n",
            "[flaml.automl.logger: 07-08 16:12:22] {2392} INFO -  at 17706.1s,\testimator catboost's best error=0.1209,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 16:12:22] {2219} INFO - iteration 238, current learner xgboost\n",
            "[flaml.automl.logger: 07-08 16:12:27] {2392} INFO -  at 17710.6s,\testimator xgboost's best error=0.1221,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 16:12:27] {2219} INFO - iteration 239, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 16:12:40] {2392} INFO -  at 17724.0s,\testimator extra_tree's best error=0.1303,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 16:12:40] {2219} INFO - iteration 240, current learner rf\n",
            "[flaml.automl.logger: 07-08 16:13:00] {2392} INFO -  at 17743.6s,\testimator rf's best error=0.1282,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 16:13:00] {2219} INFO - iteration 241, current learner catboost\n",
            "[flaml.automl.logger: 07-08 16:15:48] {2392} INFO -  at 17912.1s,\testimator catboost's best error=0.1209,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 16:15:48] {2219} INFO - iteration 242, current learner extra_tree\n",
            "[flaml.automl.logger: 07-08 16:15:54] {2392} INFO -  at 17918.1s,\testimator extra_tree's best error=0.1303,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 16:15:54] {2219} INFO - iteration 243, current learner catboost\n",
            "[flaml.automl.logger: 07-08 16:17:14] {2392} INFO -  at 17998.1s,\testimator catboost's best error=0.1209,\tbest estimator lgbm's best error=0.1124\n",
            "[flaml.automl.logger: 07-08 16:37:33] {2628} INFO - retrain lgbm for 1218.8s\n",
            "[flaml.automl.logger: 07-08 16:37:33] {2631} INFO - retrained model: LGBMClassifier(colsample_bytree=0.7020907928739494,\n",
            "               learning_rate=0.013082848414054271, max_bin=1023,\n",
            "               min_child_samples=44, n_estimators=1, n_jobs=-1, num_leaves=14,\n",
            "               reg_alpha=2.8809013344332164, reg_lambda=0.501392057176914,\n",
            "               verbose=-1)\n",
            "[flaml.automl.logger: 07-08 16:37:33] {1931} INFO - fit succeeded\n",
            "[flaml.automl.logger: 07-08 16:37:33] {1932} INFO - Time taken to find the best model: 11097.929944038391\n",
            "Best model: lgbm\n",
            "Best hyperparameters: {'n_estimators': 14855, 'num_leaves': 14, 'min_child_samples': 44, 'learning_rate': 0.013082848414054271, 'log_max_bin': 10, 'colsample_bytree': 0.7020907928739494, 'reg_alpha': 2.8809013344332164, 'reg_lambda': 0.501392057176914}\n",
            "Best ROC-AUC on validation data: 0.11237182124293499\n",
            "Train ROC-AUC Score: 0.8892780467716911\n",
            "Test ROC-AUC Score: 0.8879971062169608\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "from flaml import AutoML\n",
        "\n",
        "# Initialize AutoML\n",
        "automl = AutoML()\n",
        "\n",
        "# Define settings for AutoML\n",
        "settings = {\n",
        "    \"time_budget\": 18000,  # total running time in seconds\n",
        "    \"metric\": 'roc_auc',  # primary metric\n",
        "    \"task\": 'classification',  # task type\n",
        "    \"log_file_name\": \"automl.log\",  # log file\n",
        "    \"seed\": 42  # random seed\n",
        "}\n",
        "\n",
        "# Train models with AutoML\n",
        "automl.fit(X_train=X_train, y_train=y_train, **settings)\n",
        "\n",
        "# Print the best model and its parameters\n",
        "print(f\"Best model: {automl.best_estimator}\")\n",
        "print(f\"Best hyperparameters: {automl.best_config}\")\n",
        "print(f\"Best ROC-AUC on validation data: {automl.best_loss}\")\n",
        "\n",
        "# Evaluate the best model on the training set\n",
        "y_train_pred_prob = automl.predict_proba(X_train)[:, 1]\n",
        "train_roc_auc = roc_auc_score(y_train, y_train_pred_prob)\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "y_test_pred_prob = automl.predict_proba(X_test)[:, 1]\n",
        "test_roc_auc = roc_auc_score(y_test, y_test_pred_prob)\n",
        "\n",
        "# Print the train and test ROC-AUC scores\n",
        "print(\"Train ROC-AUC Score:\", train_roc_auc)\n",
        "print(\"Test ROC-AUC Score:\", test_roc_auc)\n",
        "\n",
        "# Plot ROC curve for the best model on the test set\n",
        "fpr, tpr, _ = roc_curve(y_test, y_test_pred_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xHneMr9sNmO"
      },
      "source": [
        "## Test ROC-AUC Score: 0.8781143572697762 base\n",
        "## Test ROC-AUC Score: 0.8765779081614977 all encoding\n",
        "## Test ROC-AUC Score: 0.8770420572344932 no clustering\n",
        "## Test ROC-AUC Score: 0.8771573237963725 borrowed FT engineering"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
