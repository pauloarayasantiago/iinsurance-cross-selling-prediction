{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification of Insurance Cross Selling\n",
    "\n",
    "#### Playground Series - Season 4, Episode 7\n",
    "\n",
    "## Model Blend with CatBoost, LightGBM, and XGBoost. \n",
    "\n",
    "**Author:** Paulo Araya-Santiago\n",
    "\n",
    "Welcome to my comprehensive notebook for the Kaggle Playground Series:Binary Classification of Insurance Cross Selling. This notebook demonstrates my end-to-end workflow, from data exploration and preprocessing to feature engineering and model tuning. The goal is to build a robust model that accurately predicts insurance responses. This particular version of this notebook is meant to be ran locally to be displayed on Github. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Tests and Findings\n",
    "\n",
    "This notebook is the culmination of the creation of at least 50 different notebooks for this competition. As of the creation of this version I still haven't been able to obtain my ideal score, but I decided to share my favorite parts of my work. I started by testing the dataset on different models with only the necessary transformations done to the features. XGBoost and LightGBM stood out from the start. I settled on trying to perfect the LightGBM model by running it through hundreds of iterations across multiple weeks on OPTUNA. When I was satisfied with the validation scores, I submitted it to the competition and the results were lackluster. This led me to take a deep dive into other notebooks scoring high in the competition (all of which are referenced below). After trying all sorts of feature engineering techniques, through testing and research I found that the dataset worked best with the addition of a few interaction features. I later found a notebook along the highest scoring ones that created a blend out of other people's submissions. I found this interesting and decided to concuct my own blend. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Explorations\n",
    "\n",
    "I first started with a little exploratory data analysis (EDA) and basic data processing. The data comes pretty clean, but the dataset is MASSIVE. The largest I had worked with previously had been around 70k rows, but this one had 11 million. Not many columns though. Most columns were fairly easy to handle except for `Region_Code` and `Policy_Sales_Channel`. I treated those by binning them into a rare category due to the heavy imbalance towards some values. Otherwise, everything was treated pretty basically.\n",
    "\n",
    "I made some basic EDA graphs to explore the data, using some base models to understand feature importances. Later, I discovered the magic of KLIB from another notebook: [Optuna XGBoost KLIB Notebook](https://www.kaggle.com/code/suvroo/ps4e7-optuna-xgboost-klib), which taught me a thing or two about cleaning the data easily with KLIB, and how to keep track of hyperparameter studies with Optuna and some of its also amazing graphs.\n",
    "\n",
    "At first, I applied the basic preprocessing steps necessary to run the dataset efficiently in the models I was using. Also incorporating some downcasting to the workflow so that the model would work more efficiently. I tried applying some additional transformations to the data like removing outliers, creating rare categories for feature values with low counts, and creating KMEANS cluster feature. I also tested borrowed feature interactions from other notebooks and created my own. After possibly hundreds of tests, I settled on a combination of my own outlier removal using IQR and a set of feature interactions from [this Kaggle notebook](https://www.kaggle.com/code/rohanrao/automl-grand-prix-1st-place-solution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries Import\n",
    "In this section, we import all necessary libraries required for data manipulation, visualization, model building, and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import gc\n",
    "import klib\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a log filename with the notebook name and current datetime\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_filename = f'kaggle_submission_{current_time}.log'\n",
    "\n",
    "# Configure logging to save to a file and output to the console\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filename),\n",
    "        logging.StreamHandler()  # This ensures logs are also output to the console\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "Here, we load the training dataset. This dataset will be used for all subsequent data processing and model training steps. This dataset was created artificially for the Kaggle Playground Series S4E7, based on [this set](https://www.kaggle.com/datasets/annantkumarsingh/health-insurance-cross-sell-prediction-data). For EDA, I'll use only a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to datasets\n",
    "train_path = r\"C:\\Users\\paulo\\OneDrive\\Documents\\kaggle_competition_2_datasets\\train.csv\"\n",
    "test_path = r\"C:\\Users\\paulo\\OneDrive\\Documents\\kaggle_competition_2_datasets\\test.csv\"\n",
    "\n",
    "eda_df = pd.read_csv(train_path).sample(frac=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying Sampled Data\n",
    "After performing sampling, we display the first few rows of the sampled dataset to understand its structure and verify the sampling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Summary\n",
    "We use the `describe` method to generate summary statistics for the numerical columns in the dataset. This provides insights into the central tendency, dispersion, and shape of the dataset’s distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values Check\n",
    "It is essential to check for missing values in the dataset as they can affect the model performance. Here, we count the number of missing values in each column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Observations and Ideas\n",
    "\n",
    "- **Gender, Driving_License, Regional_Code, Previously_Insured, Vehicle_Age, Vehicle_Damage, Policy_Sales_Channel, and Response** are all categories. I will treat most of them as numerical columns for now, except for Gender, Vehicle_Age, Previously_Insured, and Vehicle_Damage, which I will turn into categories to use in KLIB's streamlined categorical plotting. From previous explorations, I know Driving_License only has 1 negative value, so I will drop it.\n",
    "- I will later remap those four categories into numerical columns after EDA as part of the preprocessing for the model.\n",
    "- I will MinMax scale Age and Vintage when standardizing because they have a reasonable range for this type of transformation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I turn some categories I want to plot into category dtype to be compatible with klib, they will automatically switch back to numeric during preprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert specified columns to categorical\n",
    "categorical_columns = ['Gender', 'Vehicle_Age', 'Previously_Insured']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    eda_df[col] = eda_df[col].astype('category')\n",
    "\n",
    "# Convert 'Previously_Insured' column to a categorical type with specific labels\n",
    "eda_df['Previously_Insured'] = pd.Categorical(eda_df['Previously_Insured'], categories=[0, 1], ordered=True)\n",
    "eda_df['Previously_Insured'] = eda_df['Previously_Insured'].cat.rename_categories([\"Uninsured\", \"Insured\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Data with KLIB\n",
    "Using KLIB, we create categorical plots to visualize the distribution of categorical features in the dataset. This helps in understanding the balance of different categories within the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klib.cat_plot(eda_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KLIB Cat Plot Explanation\n",
    "The KLIB categorical plot is an interesting way of visualizing binary variables within a dataset. However, it doesn't translate too well with categorical variables having more than two possible values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Relationships\n",
    "\n",
    "We create a custom function to plot the relationship between categorical variables and the target in a 2x2 single figure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the relationship between categorical variables and the target in a 2x2 single figure\n",
    "def plot_categorical_vs_target(df, cat_cols, target_col):\n",
    "    num_plots = len(cat_cols)\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20, 10))\n",
    "    palette = [\"#66c2a5\", \"#fc8d62\"]  # Custom palette with exactly two colors\n",
    "\n",
    "    for ax, col in zip(axes.flatten(), cat_cols):\n",
    "        sns.countplot(data=df, x=col, hue=target_col, ax=ax, palette=palette)\n",
    "        ax.set_title(f'Relation between {col} and {target_col}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the relationships\n",
    "categorical_columns = ['Gender', 'Vehicle_Age', 'Previously_Insured', 'Vehicle_Damage']\n",
    "plot_categorical_vs_target(eda_df, categorical_columns, 'Response')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The binary categories were balanced for the most part. Gender's relation to the target doesn't tell us much knowing that there are slightly more Males to begin with. People with newer vehicles are much more likely to insure them. Naturally people that are already insured answered No (who knows if that was a no to switching providers as well). People with no vehicle damage are not very likely to ensure their cars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution Plots with KLIB\n",
    "We use KLIB to create distribution plots for several features, including Annual_Premium, Age, Region_Code, Policy_Sales_Channel, and Vintage. This helps in understanding the distribution and identifying potential outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting categorical features against the target variable\n",
    "klib.dist_plot(eda_df[['Annual_Premium']])\n",
    "klib.dist_plot(eda_df[['Age']])\n",
    "klib.dist_plot(eda_df[['Region_Code']])\n",
    "klib.dist_plot(eda_df[['Policy_Sales_Channel']])\n",
    "klib.dist_plot(eda_df[['Vintage']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution Plot Analysis\n",
    "- **Annual_Premium** is heavily right-skewed with some heavy outliers in larger numbers. It is also bimodally distributed with a large concentration in the lower values and a second concentration near the mean. I might use a standard outlier removal method or a more aggressive quartile method. It might also benefit from log-transformation for its skewness.\n",
    "- **Age** is right-skewed, but given the nature of the feature, I will leave it as is and use only a MinMax Scaler during preprocessing.\n",
    "- **Region_Code** is actually a category but has many different values. It is clear certain regions are much more favored. In a previous notebook, I tried compiling all of the rarer codes into their own category. I might attempt this again but will need to consider that the rare category must be a number in itself for the model.\n",
    "- **Policy_Sales_Channel** is similar to Region_Code and will be treated the same way.\n",
    "- **Vintage** is the most normally distributed feature and I will probably scale it with a MinMax Scaler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Features\n",
    "\n",
    "Here, we encode the 'Previously_Insured' feature. So that it works properly with the klib correlation plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df['Previously_Insured'] = eda_df['Previously_Insured'].cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Plot with KLIB\n",
    "We use KLIB to create a correlation plot to identify relationships between the features and the target variable. This helps in understanding which features might be important for the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klib.corr_plot(eda_df, target='Response')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Plot Analysis\n",
    "The only feature that seems to have a significant relation towards conversion on the target is whether people are uninsured prior to the call. Based on this I will borrow the features that were engineered in another notebook to create categorical features that capture the relationship between other features and 'Previously_Insured'.\n",
    "\n",
    "##### Reference: https://www.kaggle.com/code/rohanrao/automl-grand-prix-1st-place-solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del eda_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Functions\n",
    "\n",
    "In this section, we define custom functions to streamline our data processing and feature engineering tasks. These functions help in optimizing memory usage, handling categorical features, and generating new features from existing ones. Let's walk through each of them.\n",
    "\n",
    "### Memory Optimization Function\n",
    "\n",
    "Efficient memory usage is crucial when dealing with large datasets. The `reduce_mem_usage` function iterates through all columns of a dataframe and modifies their data type to reduce memory consumption. This optimization ensures that we can handle the dataset more effectively without running into memory issues.\n",
    "\n",
    "### Safe Mapping Function\n",
    "\n",
    "Handling categorical features often involves mapping them to numerical values. The `safe_map` function ensures that we map these categories correctly and log any unknown categories that might be encountered during the process.\n",
    "\n",
    "### Feature Engineering Function\n",
    "\n",
    "Feature engineering is a critical step in enhancing model performance. The `feature_engineering` function creates new features by combining existing ones. These new features capture interactions between variables that might be predictive of the target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documenting the purpose and usage of the function\n",
    "def get_column_stats(df):\n",
    "    \"\"\"Get basic statistics for each column in the dataframe.\"\"\"\n",
    "    stats = {}\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            stats[col] = {\n",
    "                'min': df[col].min(),\n",
    "                'max': df[col].max(),\n",
    "                'mean': df[col].mean(),\n",
    "            }\n",
    "        else:\n",
    "            stats[col] = {\n",
    "                'unique': df[col].nunique()\n",
    "            }\n",
    "    return stats\n",
    "\n",
    "# Log comparison of statistics\n",
    "def compare_stats(stats_before, stats_after):\n",
    "    \"\"\"Compare statistics before and after type conversion.\"\"\"\n",
    "    for col in stats_before:\n",
    "        if stats_before[col] != stats_after[col]:\n",
    "            logging.warning(f\"Column {col} has changed: {stats_before[col]} != {stats_after[col]}\")\n",
    "\n",
    "# Log precision loss\n",
    "def calculate_precision_loss(stats_before, stats_after):\n",
    "    \"\"\"Calculate and log precision loss for numeric columns.\"\"\"\n",
    "    for col in stats_before:\n",
    "        if 'mean' in stats_before[col]:\n",
    "            mean_before = stats_before[col]['mean']\n",
    "            mean_after = stats_after[col]['mean']\n",
    "            precision_loss = abs(mean_before - mean_after) / abs(mean_before) * 100\n",
    "            logging.info(f\"Column {col} precision loss: {precision_loss:.6f}%\")\n",
    "\n",
    "# Memory optimization function\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.\"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        logging.info(f'Start memory usage of dataframe: {start_mem:.2f} MB')\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        logging.info(f'End memory usage of dataframe: {end_mem:.2f} MB')\n",
    "        logging.info(f'Decreased by {(100 * (start_mem - end_mem) / start_mem):.1f}%')\n",
    "\n",
    "    return df\n",
    "\n",
    "# Log any unknown categories during mapping\n",
    "def safe_map(df, column, mapping):\n",
    "    \"\"\"Map categorical values to numerical values and log any unknown categories.\"\"\"\n",
    "    unknown_categories = set(df[column]) - set(mapping.keys())\n",
    "    if unknown_categories:\n",
    "        logging.warning(f\"Unknown categories in column {column}: {unknown_categories}\")\n",
    "    df[column] = df[column].map(mapping)\n",
    "    return df\n",
    "\n",
    "# Function to import data with logging\n",
    "def import_data(path, index_col=None):\n",
    "    \"\"\"Import data from a CSV file and optimize memory usage.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(path, index_col=index_col)\n",
    "        \n",
    "        # Get column stats before optimization\n",
    "        stats_before = get_column_stats(df)\n",
    "        \n",
    "        df = reduce_mem_usage(df)\n",
    "        \n",
    "        # Get column stats after optimization\n",
    "        stats_after = get_column_stats(df)\n",
    "        \n",
    "        # Compare statistics and calculate precision loss\n",
    "        compare_stats(stats_before, stats_after)\n",
    "        calculate_precision_loss(stats_before, stats_after)\n",
    "        \n",
    "        logging.info(f'Data loaded and memory optimized from {path}')\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error loading data from {path}: {str(e)}')\n",
    "        return None\n",
    "\n",
    "# Preprocess data with logging\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the dataset.\"\"\"\n",
    "    gender_mapping = {'Male': 1, 'Female': 0}\n",
    "    vehicle_damage_mapping = {'Yes': 1, 'No': 0}\n",
    "    vehicle_age_mapping = {'< 1 Year': 0, '1-2 Year': 1, '> 2 Years': 2}\n",
    "    \n",
    "    df = safe_map(df, 'Gender', gender_mapping)\n",
    "    df = safe_map(df, 'Vehicle_Damage', vehicle_damage_mapping)\n",
    "    df = safe_map(df, 'Vehicle_Age', vehicle_age_mapping)\n",
    "    \n",
    "    df.drop(['Driving_License'], axis=1, inplace=True)\n",
    "    logging.info(\"Data preprocessing completed.\")\n",
    "    return df\n",
    "\n",
    "# Feature engineering function with logging\n",
    "def feature_engineering(df):\n",
    "    \"\"\"Feature engineering on the dataset.\"\"\"\n",
    "    df['Previously_Insured_Annual_Premium'] = pd.factorize((df['Previously_Insured'].astype(str) + df['Annual_Premium'].astype(str)))[0]\n",
    "    df['Previously_Insured_Vehicle_Age'] = pd.factorize((df['Previously_Insured'].astype(str) + df['Vehicle_Age'].astype(str)))[0]\n",
    "    df['Previously_Insured_Vehicle_Damage'] = pd.factorize((df['Previously_Insured'].astype(str) + df['Vehicle_Damage'].astype(str)))[0]\n",
    "    df['Previously_Insured_Vintage'] = pd.factorize((df['Previously_Insured'].astype(str) + df['Vintage'].astype(str)))[0]\n",
    "    logging.info(\"Feature engineering completed.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downcasting\n",
    "To optimize memory usage, we downcast numerical columns to more appropriate data types without losing information. We also check preemptively the loss of precision to ensure the efficiency gains are worth it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and optimize data\n",
    "train_df = import_data(train_path, index_col='id')\n",
    "test_df = import_data(test_path, index_col='id')\n",
    "\n",
    "gc.collect()\n",
    "logging.info(\"Data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Feature Engineering\n",
    "\n",
    "To prepare our dataset for modeling, we need to preprocess it by handling missing values, encoding categorical variables, and engineering new features. This process ensures that our dataset is clean and contains relevant information for our models to learn from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "In this step, we preprocess the data by mapping the categorical features into numerical values. This prepares the dataset for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "train_df = preprocess_data(train_df)\n",
    "test_df = preprocess_data(test_df)\n",
    "logging.info(\"Data preprocessed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "We create new features by capturing the interactions between them and encoding that into categorical combinations. This can provide additional information to the model and improve its performance.\n",
    "##### Reference: https://www.kaggle.com/code/rohanrao/automl-grand-prix-1st-place-solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature engineering\n",
    "train_df = feature_engineering(train_df)\n",
    "test_df = feature_engineering(test_df)\n",
    "\n",
    "gc.collect()\n",
    "logging.info(\"Feature engineering completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling\n",
    "\n",
    "We apply standard scaling to the numerical features to ensure they are on a similar scale. This is important for many machine learning algorithms to perform well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize numeric columns\n",
    "num_cols = ['Age', 'Region_Code', 'Annual_Premium', 'Policy_Sales_Channel', 'Vintage']\n",
    "scaler = StandardScaler()\n",
    "train_df[num_cols] = scaler.fit_transform(train_df[num_cols])\n",
    "test_df[num_cols] = scaler.transform(test_df[num_cols])\n",
    "logging.info(\"Numeric columns normalized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separating Features and Target Variable\n",
    "\n",
    "We separate the features (X) and the target variable (y) from the preprocessed dataset. This is an essential step before model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = train_df.drop('Response', axis=1)\n",
    "y = train_df['Response']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "In this section, we train our model using LightGBM, XGBoost, and CatBoost, and evaluate their performance using cross-validation. The predictions of each fold will be averaged into that model's contribution of the blend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Process\n",
    "\n",
    "For this competition, I selected CatBoost, LightGBM, and XGBoost. Each model has unique strengths, making them ideal for capturing different aspects of the data. Blending their predictions leverages these strengths for a more robust solution. Because of the massive size of the dataset I'm saving each model iteration created by each fold, in case something goes wrong during modeling. \n",
    "\n",
    "- **CatBoost:** Excels with categorical variables.\n",
    "- **LightGBM:** Offers speed and efficiency.\n",
    "- **XGBoost:** Ensures versatility and robustness.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of these values for hyperparameters are based on previous searches using OPTUNA or referencing other notebooks from the competition.\n",
    "\n",
    "Reference: https://www.kaggle.com/code/darkdevil18/0-89698-ps4e7-are-you-insured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Stratified K-Folds\n",
    "n_splits = 5\n",
    "skfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost\n",
    "\n",
    "- **Handles Categorical Data Natively:** Reduces preprocessing needs.\n",
    "- **Ordered Boosting:** Minimizes overfitting and improves generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CatBoost parameters\n",
    "cat_params = {\n",
    "    'loss_function': 'Logloss',\n",
    "    'eval_metric': 'AUC',\n",
    "    'class_names': [0, 1],\n",
    "    'learning_rate': 0.075,\n",
    "    'iterations': 3000,\n",
    "    'depth': 9,\n",
    "    'random_strength': 0,\n",
    "    'l2_leaf_reg': 0.5,\n",
    "    'max_leaves': 512,\n",
    "    'fold_permutation_block': 64,\n",
    "    'task_type': 'GPU',  # Ensure your environment supports GPU\n",
    "    'random_seed': 42,\n",
    "    'allow_writing_files': False,\n",
    "    'verbose': 100,  # Display log every 100 iterations\n",
    "    # 'thread_count': -1\n",
    "}\n",
    "\n",
    "# Initialize lists to store out-of-fold predictions, models, and AUC scores\n",
    "cat_preds = []\n",
    "cat_aucs = []\n",
    "\n",
    "test_pool = Pool(test_df.astype(str), cat_features=X.columns.values)\n",
    "\n",
    "# CatBoost Model\n",
    "logging.info(\"Starting CatBoost training...\")\n",
    "for fold, (train_idx, test_idx) in enumerate(skfold.split(X, y)):\n",
    "    logging.info(f\"---- CatBoost Fold {fold + 1} ----\")\n",
    "    \n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_valid, y_valid = X.iloc[test_idx], y.iloc[test_idx]\n",
    "    \n",
    "    train_pool = Pool(X_train.astype(str), y_train, cat_features=X.columns.values)\n",
    "    valid_pool = Pool(X_valid.astype(str), y_valid, cat_features=X.columns.values)\n",
    "    \n",
    "    model = CatBoostClassifier(**cat_params)\n",
    "    model.fit(train_pool, eval_set=valid_pool, early_stopping_rounds=50, verbose=100)\n",
    "    \n",
    "    valid_preds = model.predict_proba(X_valid.astype(str))[:, 1]\n",
    "    auc_score = roc_auc_score(y_valid, valid_preds)\n",
    "    cat_aucs.append(auc_score)\n",
    "    logging.info(f\"Validation AUC score for fold {fold + 1}: {auc_score:.6f}\")\n",
    "    \n",
    "    test_pred = model.predict_proba(test_pool)[:, 1]\n",
    "    cat_preds.append(test_pred)\n",
    "    \n",
    "    # Save the model for this fold\n",
    "    joblib.dump(model, f'catboost_model_fold_{fold + 1}.pkl')\n",
    "    \n",
    "    # Clear memory\n",
    "    del X_train, y_train, X_valid, y_valid, train_pool, valid_pool, model\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "# Calculate overall AUC score for CatBoost\n",
    "auc_mean_cat = np.mean(cat_aucs)\n",
    "auc_std_cat = np.std(cat_aucs)\n",
    "logging.info(f\"Overall ROC-AUC Score for CatBoost: {auc_mean_cat:.6f} ± {auc_std_cat:.6f}\")\n",
    "\n",
    "# Average the predictions from each fold for CatBoost\n",
    "test_pred_cat = np.mean(cat_preds, axis=0)\n",
    "joblib.dump(test_pred_cat, 'test_pred_cat.pkl')\n",
    "logging.info(\"CatBoost models and predictions saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM\n",
    "\n",
    "- **Histogram-Based Algorithms:** Efficient training and memory usage.\n",
    "- **Leaf-Wise Growth:** Reduces loss more aggressively, enhancing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LightGBM parameters\n",
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'reg_alpha': 0.03432385172267505,\n",
    "    'reg_lambda': 0.2998279059616829,\n",
    "    'colsample_bytree': 0.790292183596673,\n",
    "    'subsample': 0.9046878168822107,\n",
    "    'learning_rate': 0.05035039561309864,\n",
    "    'max_depth': 10,  # Further reduced max depth\n",
    "    'num_leaves': 31,  # Standard number of leaves\n",
    "    'min_child_samples': 100,  # Increased min child samples\n",
    "    'min_child_weight': 1,  # Adjusted min child weight\n",
    "    'min_split_gain': 0.09978597066868167,\n",
    "    'max_bin': 255,\n",
    "    'device': 'gpu',\n",
    "    'early_stopping_rounds': 50,\n",
    "    'verbose': 1  # Enable verbose mode\n",
    "}\n",
    "\n",
    "# Initialize lists to store out-of-fold predictions and AUC scores\n",
    "lgb_preds = []\n",
    "lgb_aucs = []\n",
    "\n",
    "# Train LightGBM model with cross-validation\n",
    "logging.info(\"Starting LightGBM training...\")\n",
    "for fold, (train_idx, test_idx) in enumerate(skfold.split(X, y)):\n",
    "    logging.info(f\"---- Fold {fold + 1} ----\")\n",
    "    \n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_valid, y_valid = X.iloc[test_idx], y.iloc[test_idx]\n",
    "\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        lgb_params,\n",
    "        train_data,\n",
    "        num_boost_round=3000,\n",
    "        valid_sets=[train_data, valid_data],\n",
    "    )\n",
    "    \n",
    "    valid_preds = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    auc_score = roc_auc_score(y_valid, valid_preds)\n",
    "    lgb_aucs.append(auc_score)\n",
    "    logging.info(f\"Validation AUC score for fold {fold + 1}: {auc_score:.6f}\")\n",
    "    \n",
    "    test_pred = model.predict(test_df, num_iteration=model.best_iteration)\n",
    "    lgb_preds.append(test_pred)\n",
    "    \n",
    "    # Save the model for this fold\n",
    "    joblib.dump(model, f'lgb_model_fold_{fold + 1}.pkl')\n",
    "    \n",
    "    # Clear memory\n",
    "    del X_train, y_train, X_valid, y_valid, train_data, valid_data, model\n",
    "    gc.collect()\n",
    "\n",
    "# Calculate overall AUC score for LightGBM\n",
    "auc_mean_lgb = np.mean(lgb_aucs)\n",
    "auc_std_lgb = np.std(lgb_aucs)\n",
    "logging.info(f\"Overall ROC-AUC Score for LightGBM: {auc_mean_lgb:.6f} ± {auc_std_lgb:.6f}\")\n",
    "\n",
    "# Average the predictions from each fold for LightGBM\n",
    "test_pred_lgb = np.mean(lgb_preds, axis=0)\n",
    "joblib.dump(test_pred_lgb, 'test_pred_lgb.pkl')\n",
    "logging.info(\"LightGBM models and predictions saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "- **Regularization (L1 and L2):** Prevents overfitting, improving robustness.\n",
    "- **Tree Pruning:** Effectively manages overfitting.\n",
    "- **Parallel Processing:** Speeds up training on large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define XGBoost parameters\n",
    "xgb_params = {\n",
    "    'eval_metric': 'auc',\n",
    "    'eta': 0.05,\n",
    "    'alpha': 0.2545607592482198,\n",
    "    'subsample': 0.8388163485383147,\n",
    "    'colsample_bytree': 0.2732499701466825,\n",
    "    'max_depth': 16,\n",
    "    'min_child_weight': 5,\n",
    "    'gamma': 0.0017688666476104672,\n",
    "    'max_bin': 262143,\n",
    "    'tree_method': 'gpu_hist',  # Ensure your environment supports GPU\n",
    "    'predictor': 'gpu_predictor',  # Ensure your environment supports GPU\n",
    "    'enable_categorical': True,\n",
    "    'verbose': 100\n",
    "}\n",
    "\n",
    "# Initialize lists to store out-of-fold predictions and AUC scores\n",
    "xgb_preds = []\n",
    "xgb_aucs = []\n",
    "\n",
    "# Train XGBoost model with cross-validation\n",
    "logging.info(\"Starting XGBoost training...\")\n",
    "for fold, (train_idx, test_idx) in enumerate(skfold.split(X, y)):\n",
    "    logging.info(f\"---- Fold {fold + 1} ----\")\n",
    "    \n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_valid, y_valid = X.iloc[test_idx], y.iloc[test_idx]\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)\n",
    "    dvalid = xgb.DMatrix(X_valid, label=y_valid, enable_categorical=True)\n",
    "    \n",
    "    model = xgb.train(\n",
    "        xgb_params,\n",
    "        dtrain,\n",
    "        num_boost_round=3000,\n",
    "        evals=[(dtrain, 'train'), (dvalid, 'valid')],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=100\n",
    "    )\n",
    "    \n",
    "    valid_preds = model.predict(dvalid, iteration_range=(0, model.best_iteration))\n",
    "    auc_score = roc_auc_score(y_valid, valid_preds)\n",
    "    xgb_aucs.append(auc_score)\n",
    "    logging.info(f\"Validation AUC score for fold {fold + 1}: {auc_score:.6f}\")\n",
    "    \n",
    "    dtest = xgb.DMatrix(test_df, enable_categorical=True)\n",
    "    test_pred = model.predict(dtest, iteration_range=(0, model.best_iteration))\n",
    "    xgb_preds.append(test_pred)\n",
    "    \n",
    "    # Save the model for this fold\n",
    "    model.save_model(f'xgb_model_fold_{fold + 1}.json')\n",
    "    \n",
    "    # Clear memory\n",
    "    del X_train, y_train, X_valid, y_valid, dtrain, dvalid, model\n",
    "    gc.collect()\n",
    "\n",
    "# Calculate overall AUC score for XGBoost\n",
    "auc_mean_xgb = np.mean(xgb_aucs)\n",
    "auc_std_xgb = np.std(xgb_aucs)\n",
    "logging.info(f\"Overall ROC-AUC Score for XGBoost: {auc_mean_xgb:.6f} ± {auc_std_xgb:.6f}\")\n",
    "\n",
    "# Average the predictions from each fold for XGBoost\n",
    "test_pred_xgb = np.mean(xgb_preds, axis=0)\n",
    "joblib.dump(test_pred_xgb, 'test_pred_xgb.pkl')\n",
    "logging.info(\"XGBoost models and predictions saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blending Predictions\n",
    "We blend predictions from CatBoost, LightGBM, and XGBoost models based on their AUC scores to create the final submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize AUC scores to sum to 1\n",
    "total_auc = auc_mean_cat + auc_mean_lgb + auc_mean_xgb\n",
    "\n",
    "weight_cat = auc_mean_cat / total_auc\n",
    "weight_lgb = auc_mean_lgb / total_auc\n",
    "weight_xgb = auc_mean_xgb / total_auc\n",
    "\n",
    "# Print weights for verification\n",
    "print(f\"Weights - CatBoost: {weight_cat:.4f}, LightGBM: {weight_lgb:.4f}, XGBoost: {weight_xgb:.4f}\")\n",
    "\n",
    "# Blending predictions with calculated weights\n",
    "blended_preds = (weight_cat * test_pred_cat + weight_lgb * test_pred_lgb + weight_xgb * test_pred_xgb)\n",
    "\n",
    "# Create the submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df.index,\n",
    "    'Response': blended_preds\n",
    "})\n",
    "\n",
    "# Save the submission file\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"Submission file created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What We Did in This Notebook\n",
    "\n",
    "This notebook showcased a detailed and comprehensive end-to-end workflow for tackling the Kaggle Playground Series S4E07 competition. Here’s a recap of our journey:\n",
    "\n",
    "### Exploratory Data Analysis (EDA)\n",
    "- **Initial Explorations:** We kicked off with a subset of the data to get a quick grasp of its structure and nuances. This initial dive helped us spot potential issues and interesting patterns early on.\n",
    "- **KLIB Visualizations:** We utilized KLIB for streamlined visualizations and correlation analysis, making it easier to pinpoint key features and understand their relationships with the target variable.\n",
    "\n",
    "### Data Preprocessing\n",
    "- **Handling Missing Values:** We meticulously checked for missing values to ensure data integrity throughout the modeling process.\n",
    "- **Categorical Encoding:** By converting categorical variables into numerical formats, we prepped the data for machine learning models.\n",
    "- **Memory Optimization:** To efficiently handle the large dataset, we optimized memory usage through downcasting of data types.\n",
    "\n",
    "### Feature Engineering\n",
    "- **Creating New Features:** We got creative with feature engineering, developing new features by combining existing ones. This allowed us to capture interactions between variables that could boost model performance.\n",
    "- **Scaling Numerical Features:** Standard scaling was applied to numerical features to bring them onto a similar scale, which is essential for many machine learning algorithms to perform optimally.\n",
    "\n",
    "### Modeling and Evaluation\n",
    "- **Model Selection:** We chose three powerhouse models – CatBoost, LightGBM, and XGBoost – each known for its unique strengths in handling structured data.\n",
    "- **Cross-Validation:** To get a reliable estimate of model performance, we used stratified k-fold cross-validation, ensuring our models were tested across diverse subsets of the data.\n",
    "- **Hyperparameter Tuning:** Leveraging Optuna, we efficiently tuned the hyperparameters, squeezing out the best performance from our models.\n",
    "\n",
    "### Blending Predictions\n",
    "- **Ensemble Approach:** Instead of relying on a single model, we blended predictions from CatBoost, LightGBM, and XGBoost based on their ROC-AUC scores. This ensemble method harnessed the strengths of each model, resulting in superior overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this notebook, we performed exploratory data analysis, preprocessing, feature engineering, and model training with blending at the end to form our best submission possible.. The final submission was blended using CatBoost, LightGBM and XGBoost with the best hyperparameters found by Optuna(or borrowed from other noteboks) and evaluated on the validation set. The results demonstrate the effectiveness of the selected features and the tuned model. This notebook was designed to showcase a clean and optimized workflow.\n",
    "\n",
    "## Challenges and Solutions\n",
    "\n",
    "- **Handling Large Datasets:** The 11 million rows were daunting. I downsampled the dataset for initial exploration to manage computational resources better.\n",
    "- **Imbalanced Dataset:** SMote was my go-to solution for balancing the target variable classes. SMote resulted in too much overfitting.\n",
    "- **Hyperparameter Tuning:** Given the computational constraints, I leaned heavily on Optuna for efficient hyperparameter tuning. Hyperparameter tuning took almost two weeks without many gains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Walter Reade, & Ashley Chow. (2024). *Binary Classification of Insurance Cross Selling*. Kaggle. Retrieved from [https://kaggle.com/competitions/playground-series-s4e7](https://kaggle.com/competitions/playground-series-s4e7)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
