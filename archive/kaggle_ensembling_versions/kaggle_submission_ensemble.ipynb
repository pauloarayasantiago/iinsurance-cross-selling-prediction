{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from scipy.optimize import minimize\n",
    "import optuna\n",
    "from datetime import datetime\n",
    "import gc\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a log filename with the notebook name and current datetime\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_filename = f'kaggle_submission_{current_time}.log'\n",
    "\n",
    "# Configure logging to save to a file\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filename),\n",
    "        logging.StreamHandler()  # This ensures logs are also output to the console\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\"Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.\"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    logging.info(f'Memory usage of dataframe is {start_mem:.2f} MB')\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    logging.info(f'Memory usage after optimization is: {end_mem:.2f} MB')\n",
    "    logging.info(f'Decreased by {(100 * (start_mem - end_mem) / start_mem):.1f}%')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def import_data(file, **kwargs):\n",
    "    \"\"\"Create a dataframe and optimize its memory usage\"\"\"\n",
    "    df = pd.read_csv(file, parse_dates=True, keep_date_col=True, **kwargs)\n",
    "    df = reduce_mem_usage(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 13:34:43,739 - INFO - Memory usage of dataframe is 1053.30 MB\n",
      "2024-07-23 13:34:45,387 - INFO - Memory usage after optimization is: 274.30 MB\n",
      "2024-07-23 13:34:45,387 - INFO - Decreased by 74.0%\n",
      "2024-07-23 13:34:54,680 - INFO - Memory usage of dataframe is 643.68 MB\n",
      "2024-07-23 13:34:55,761 - INFO - Memory usage after optimization is: 175.55 MB\n",
      "2024-07-23 13:34:55,762 - INFO - Decreased by 72.7%\n",
      "2024-07-23 13:34:55,824 - INFO - Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Paths to datasets\n",
    "train_path = r\"C:\\Users\\paulo\\OneDrive\\Documents\\kaggle_competition_2_datasets\\train.csv\"\n",
    "test_path = r\"C:\\Users\\paulo\\OneDrive\\Documents\\kaggle_competition_2_datasets\\test.csv\"\n",
    "\n",
    "# Load and optimize data\n",
    "train_df = import_data(train_path, index_col='id')\n",
    "test_df = import_data(test_path, index_col='id')\n",
    "\n",
    "gc.collect()\n",
    "logging.info(\"Data loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 13:34:56,174 - INFO - Data preprocessed successfully.\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(df):\n",
    "    df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})\n",
    "    df['Vehicle_Damage'] = df['Vehicle_Damage'].map({'Yes': 1, 'No': 0})\n",
    "    vehicle_age_mapping = {'< 1 Year': 0, '1-2 Year': 1, '> 2 Years': 2}\n",
    "    df['Vehicle_Age'] = df['Vehicle_Age'].map(vehicle_age_mapping)\n",
    "    df.drop(['Driving_License'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Apply preprocessing\n",
    "train_df = preprocess_data(train_df)\n",
    "test_df = preprocess_data(test_df)\n",
    "logging.info(\"Data preprocessed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_outliers_iqr(df, column):\n",
    "#     Q1 = df[column].quantile(0.25)\n",
    "#     Q3 = df[column].quantile(0.75)\n",
    "#     IQR = Q3 - Q1\n",
    "#     lower_bound = Q1 - 1.5 * IQR\n",
    "#     upper_bound = Q3 + 1.5 * IQR\n",
    "#     return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "# # Apply outlier removal\n",
    "# train_df = remove_outliers_iqr(train_df, 'Annual_Premium')\n",
    "# logging.info(\"Outliers removed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 13:35:28,743 - INFO - Feature engineering completed successfully.\n"
     ]
    }
   ],
   "source": [
    "def feature_engineering(df):\n",
    "    df = df.copy()\n",
    "    df['Previously_Insured_Annual_Premium'] = pd.factorize((df['Previously_Insured'].astype(str) + df['Annual_Premium'].astype(str)))[0]\n",
    "    df['Previously_Insured_Vehicle_Age'] = pd.factorize((df['Previously_Insured'].astype(str) + df['Vehicle_Age'].astype(str)))[0]\n",
    "    df['Previously_Insured_Vehicle_Damage'] = pd.factorize((df['Previously_Insured'].astype(str) + df['Vehicle_Damage'].astype(str)))[0]\n",
    "    df['Previously_Insured_Vintage'] = pd.factorize((df['Previously_Insured'].astype(str) + df['Vintage'].astype(str)))[0]\n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "train_df = feature_engineering(train_df)\n",
    "test_df = feature_engineering(test_df)\n",
    "\n",
    "gc.collect()\n",
    "logging.info(\"Feature engineering completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 13:35:31,794 - INFO - Features and target variable separated and scaled.\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target variable\n",
    "X = train_df.drop('Response', axis=1).values\n",
    "y = train_df['Response'].values\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "test_df_scaled = scaler.transform(test_df.values)\n",
    "\n",
    "gc.collect()\n",
    "logging.info(f\"Features and target variable separated and scaled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Stratified K-Folds\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LightGBM model with validation within each fold\n",
    "def train_lgbm_with_validation(X_train, y_train, params, num_boost_round=1000):\n",
    "    X_train_split, X_valid_split, y_train_split, y_valid_split = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train_split, label=y_train_split)\n",
    "    valid_data = lgb.Dataset(X_valid_split, label=y_valid_split, reference=train_data)\n",
    "    \n",
    "    bst = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=num_boost_round,\n",
    "        valid_sets=[train_data, valid_data],\n",
    "    )\n",
    "    \n",
    "    gc.collect()\n",
    "    valid_preds = bst.predict(X_valid_split, num_iteration=bst.best_iteration)\n",
    "    auc_score = roc_auc_score(y_valid_split, valid_preds)\n",
    "    logging.info(f'Validation AUC score: {auc_score}')\n",
    "    return bst, bst.best_iteration\n",
    "\n",
    "# Define LightGBM parameters\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'reg_alpha': 0.03432385172267505,\n",
    "    'reg_lambda': 0.2998279059616829,\n",
    "    'colsample_bytree': 0.790292183596673,\n",
    "    'subsample': 0.9046878168822107,\n",
    "    'learning_rate': 0.05035039561309864,\n",
    "    'max_depth': 29,\n",
    "    'num_leaves': 1474,\n",
    "    'min_child_samples': 75,\n",
    "    'min_child_weight': 7.661448090878849,\n",
    "    'min_split_gain': 0.09978597066868167,\n",
    "    'max_bin': 499,\n",
    "    'n_jobs': 8,\n",
    "    'early_stopping_rounds': 100\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Fold 1 ----\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m X_valid, y_valid \u001b[38;5;241m=\u001b[39m X_scaled[test_idx], y[test_idx]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Train the model with validation to find the best iteration\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m model, best_iteration \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_lgbm_with_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest iteration found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_iteration\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Predict on validation set\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m, in \u001b[0;36mtrain_lgbm_with_validation\u001b[1;34m(X_train, y_train, params, num_boost_round)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_lgbm_with_validation\u001b[39m(X_train, y_train, params, num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     X_train_split, X_valid_split, y_train_split, y_valid_split \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstratify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     train_data \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X_train_split, label\u001b[38;5;241m=\u001b[39my_train_split)\n\u001b[0;32m      7\u001b[0m     valid_data \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X_valid_split, label\u001b[38;5;241m=\u001b[39my_valid_split, reference\u001b[38;5;241m=\u001b[39mtrain_data)\n",
      "File \u001b[1;32mc:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2681\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2677\u001b[0m         CVClass \u001b[38;5;241m=\u001b[39m ShuffleSplit\n\u001b[0;32m   2679\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m-> 2681\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstratify\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2683\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2684\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m   2685\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2686\u001b[0m     )\n\u001b[0;32m   2687\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:1749\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1719\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m   1720\u001b[0m \n\u001b[0;32m   1721\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;124;03mto an integer.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1748\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m-> 1749\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2194\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   2191\u001b[0m     test\u001b[38;5;241m.\u001b[39mextend(perm_indices_class_i[n_i[i] : n_i[i] \u001b[38;5;241m+\u001b[39m t_i[i]])\n\u001b[0;32m   2193\u001b[0m train \u001b[38;5;241m=\u001b[39m rng\u001b[38;5;241m.\u001b[39mpermutation(train)\n\u001b[1;32m-> 2194\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mrng\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermutation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2196\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[1;32mnumpy\\\\random\\\\mtrand.pyx:4727\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.permutation\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize lists to store out-of-fold predictions and AUC scores\n",
    "lgb_preds = []\n",
    "lgb_aucs = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for fold, (train_idx, test_idx) in enumerate(skfold.split(X_scaled, y)):\n",
    "    print(f\"\\n---- Fold {fold + 1} ----\\n\")\n",
    "    \n",
    "    X_train, y_train = X_scaled[train_idx], y[train_idx]\n",
    "    X_valid, y_valid = X_scaled[test_idx], y[test_idx]\n",
    "    \n",
    "    # Train the model with validation to find the best iteration\n",
    "    model, best_iteration = train_lgbm_with_validation(X_train, y_train, params)\n",
    "    logging.info(f\"Best iteration found: {best_iteration}\")\n",
    "\n",
    "    # Predict on validation set\n",
    "    valid_preds = model.predict(X_valid, num_iteration=best_iteration)\n",
    "    auc_score = roc_auc_score(y_valid, valid_preds)\n",
    "    lgb_aucs.append(auc_score)\n",
    "    print(f\"Validation AUC score for fold {fold + 1}: {auc_score:.6f}\")\n",
    "    \n",
    "    # Predict on test set\n",
    "    test_pred = model.predict(test_df_scaled, num_iteration=best_iteration)\n",
    "    lgb_preds.append(test_pred)\n",
    "    \n",
    "    # Clean up to free memory\n",
    "    del X_train, y_train, X_valid, y_valid, model\n",
    "    gc.collect()\n",
    "\n",
    "# Calculate overall AUC score\n",
    "auc_mean = np.mean(lgb_aucs)\n",
    "auc_std = np.std(lgb_aucs)\n",
    "print(f\"\\n---> Overall ROC-AUC Score: {auc_mean:.6f} ± {auc_std:.6f}\\n\")\n",
    "\n",
    "# Average the predictions from each fold\n",
    "test_pred_lgb = np.mean(lgb_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'eval_metric': 'auc',\n",
    "    'n_estimators': 3000,\n",
    "    'eta': 0.05,\n",
    "    'alpha': 0.2545607592482198,\n",
    "    'subsample': 0.8388163485383147,\n",
    "    'colsample_bytree': 0.2732499701466825,\n",
    "    'max_depth': 16,\n",
    "    'min_child_weight': 5,\n",
    "    'gamma': 0.0017688666476104672,\n",
    "    'max_bin': 262143,\n",
    "    'tree_method': 'hist',\n",
    "    'device': 'cuda',\n",
    "    'enable_categorical': True,\n",
    "    'early_stopping_rounds': 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Fold 1 ----\n",
      "\n",
      "[0]\ttrain-auc:0.84812\tvalid-auc:0.84825\n",
      "[1]\ttrain-auc:0.85206\tvalid-auc:0.85184\n",
      "[2]\ttrain-auc:0.85625\tvalid-auc:0.85522\n",
      "[3]\ttrain-auc:0.85848\tvalid-auc:0.85752\n",
      "[4]\ttrain-auc:0.85683\tvalid-auc:0.85599\n",
      "[5]\ttrain-auc:0.85928\tvalid-auc:0.85708\n",
      "[6]\ttrain-auc:0.86420\tvalid-auc:0.86112\n",
      "[7]\ttrain-auc:0.86342\tvalid-auc:0.86003\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m dvalid \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(X_valid, label\u001b[38;5;241m=\u001b[39my_valid)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Train XGBoost model\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxgb_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn_estimators\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdvalid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxgb_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mearly_stopping_rounds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Predict on validation set\u001b[39;00m\n\u001b[0;32m     26\u001b[0m valid_preds \u001b[38;5;241m=\u001b[39m xgb_model\u001b[38;5;241m.\u001b[39mpredict(dvalid, ntree_limit\u001b[38;5;241m=\u001b[39mxgb_model\u001b[38;5;241m.\u001b[39mbest_ntree_limit)\n",
      "File \u001b[1;32mc:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\xgboost\\core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2100\u001b[0m     _check_call(\n\u001b[1;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2104\u001b[0m     )\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize lists to store out-of-fold predictions and AUC scores\n",
    "preds_xgb = []\n",
    "aucs_xgb = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for fold, (train_idx, test_idx) in enumerate(skfold.split(X_scaled, y)):\n",
    "    print(f\"\\n---- Fold {fold + 1} ----\\n\")\n",
    "    \n",
    "    X_train, y_train = X_scaled[train_idx], y[train_idx]\n",
    "    X_valid, y_valid = X_scaled[test_idx], y[test_idx]\n",
    "    \n",
    "    # Prepare data for XGBoost\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "    \n",
    "    # Train XGBoost model\n",
    "    xgb_model = xgb.train(\n",
    "        xgb_params,\n",
    "        dtrain,\n",
    "        num_boost_round=xgb_params['n_estimators'],\n",
    "        evals=[(dtrain, 'train'), (dvalid, 'valid')],\n",
    "        early_stopping_rounds=xgb_params['early_stopping_rounds']\n",
    "    )\n",
    "    \n",
    "    # Predict on validation set\n",
    "    valid_preds = xgb_model.predict(dvalid, ntree_limit=xgb_model.best_ntree_limit)\n",
    "    auc_score = roc_auc_score(y_valid, valid_preds)\n",
    "    aucs_xgb.append(auc_score)\n",
    "    print(f\"Validation AUC score for fold {fold + 1}: {auc_score:.6f}\")\n",
    "    \n",
    "    # Predict on test set\n",
    "    dtest = xgb.DMatrix(test_df_scaled)\n",
    "    test_pred = xgb_model.predict(dtest, ntree_limit=xgb_model.best_ntree_limit)\n",
    "    preds_xgb.append(test_pred)\n",
    "    \n",
    "    # Clean up to free memory\n",
    "    del X_train, y_train, X_valid, y_valid, dtrain, dvalid, xgb_model\n",
    "    gc.collect()\n",
    "\n",
    "# Calculate overall AUC score for XGBoost\n",
    "auc_mean_xgb = np.mean(aucs_xgb)\n",
    "auc_std_xgb = np.std(aucs_xgb)\n",
    "print(f\"\\n---> Overall ROC-AUC Score for XGBoost: {auc_mean_xgb:.6f} ± {auc_std_xgb:.6f}\\n\")\n",
    "\n",
    "# Average the predictions from each fold for XGBoost\n",
    "test_pred_xgb = np.mean(preds_xgb, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_params = {\n",
    "    'loss_function': 'Logloss',\n",
    "    'eval_metric': 'AUC',\n",
    "    'class_names': [0, 1],\n",
    "    'learning_rate': 0.075,\n",
    "    'iterations': 3000,\n",
    "    'depth': 9,\n",
    "    'random_strength': 0,\n",
    "    'l2_leaf_reg': 0.5,\n",
    "    'max_leaves': 512,\n",
    "    'fold_permutation_block': 64,\n",
    "    'task_type': 'GPU',\n",
    "    'random_seed': 42,\n",
    "    'verbose': False,\n",
    "    'allow_writing_files': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store out-of-fold predictions and AUC scores\n",
    "preds_cat = []\n",
    "aucs_cat = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for fold, (train_idx, test_idx) in enumerate(skfold.split(X_scaled, y)):\n",
    "    print(f\"\\n---- Fold {fold + 1} ----\\n\")\n",
    "    \n",
    "    X_train, y_train = X_scaled[train_idx], y[train_idx]\n",
    "    X_valid, y_valid = X_scaled[test_idx], y[test_idx]\n",
    "    \n",
    "    # Prepare data for CatBoost\n",
    "    train_pool = Pool(X_train, y_train)\n",
    "    valid_pool = Pool(X_valid, y_valid)\n",
    "    \n",
    "    # Train CatBoost model\n",
    "    cat_model = CatBoostClassifier(**cat_params)\n",
    "    cat_model.fit(train_pool, eval_set=valid_pool, early_stopping_rounds=50)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    valid_preds = cat_model.predict_proba(X_valid)[:, 1]\n",
    "    auc_score = roc_auc_score(y_valid, valid_preds)\n",
    "    aucs_cat.append(auc_score)\n",
    "    print(f\"Validation AUC score for fold {fold + 1}: {auc_score:.6f}\")\n",
    "    \n",
    "    # Predict on test set\n",
    "    test_pred = cat_model.predict_proba(test_df_scaled)[:, 1]\n",
    "    preds_cat.append(test_pred)\n",
    "    \n",
    "    # Clean up to free memory\n",
    "    del X_train, y_train, X_valid, y_valid, train_pool, valid_pool, cat_model\n",
    "    gc.collect()\n",
    "\n",
    "# Calculate overall AUC score for CatBoost\n",
    "auc_mean_cat = np.mean(aucs_cat)\n",
    "auc_std_cat = np.std(aucs_cat)\n",
    "print(f\"\\n---> Overall ROC-AUC Score for CatBoost: {auc_mean_cat:.6f} ± {auc_std_cat:.6f}\\n\")\n",
    "\n",
    "# Average the predictions from each fold for CatBoost\n",
    "test_pred_cat = np.mean(preds_cat, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the weighted average predictions\n",
    "def weighted_average(weights, preds):\n",
    "    weighted_preds = np.average(preds, axis=0, weights=weights)\n",
    "    return weighted_preds\n",
    "\n",
    "# Define the objective function to minimize (negative AUC)\n",
    "def objective(weights, preds, y_true):\n",
    "    weighted_preds = weighted_average(weights, preds)\n",
    "    auc = roc_auc_score(y_true, weighted_preds)\n",
    "    return -auc\n",
    "\n",
    "# Prepare prediction arrays and true labels\n",
    "preds = np.array([test_pred_lgb, test_pred_xgb, test_pred_cat])\n",
    "y_true = y  # Use your actual target variable for the validation set\n",
    "\n",
    "# Initialize weights\n",
    "initial_weights = [1/3, 1/3, 1/3]\n",
    "\n",
    "# Define constraints and bounds for the weights\n",
    "constraints = ({'type': 'eq', 'fun': lambda w: 1 - sum(w)})\n",
    "bounds = [(0, 1)] * len(initial_weights)\n",
    "\n",
    "# Optimize the weights\n",
    "opt_result = minimize(objective, initial_weights, args=(preds, y_true), method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "\n",
    "# Extract the optimized weights\n",
    "optimized_weights = opt_result.x\n",
    "print(\"Optimized weights:\", optimized_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the weighted average of the predictions using optimized weights\n",
    "final_predictions_optimized = np.average(preds, axis=0, weights=optimized_weights)\n",
    "\n",
    "# Create the submission DataFrame\n",
    "submission_optimized = pd.DataFrame({'id': test_df.index, 'Response': final_predictions_optimized})\n",
    "\n",
    "# Save the submission DataFrame to a CSV file\n",
    "submission_optimized.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Optimized weighted average submission file created successfully.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
