{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from scipy.optimize import minimize\n",
    "from datetime import datetime\n",
    "import gc\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a log filename with the notebook name and current datetime\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_filename = f'kaggle_submission_{current_time}.log'\n",
    "\n",
    "# Configure logging to save to a file\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filename),\n",
    "        logging.StreamHandler()  # This ensures logs are also output to the console\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import gc\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.\"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        logging.info(f'Start memory usage of dataframe: {start_mem:.2f} MB')\n",
    "\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        logging.info(f'End memory usage of dataframe: {end_mem:.2f} MB')\n",
    "        logging.info(f'Decreased by {(100 * (start_mem - end_mem) / start_mem):.1f}%')\n",
    "\n",
    "    return df\n",
    "\n",
    "def safe_map(df, column, mapping):\n",
    "    \"\"\"Map categorical values to numerical values and log any unknown categories.\"\"\"\n",
    "    unknown_categories = set(df[column]) - set(mapping.keys())\n",
    "    if unknown_categories:\n",
    "        logging.warning(f\"Unknown categories in column {column}: {unknown_categories}\")\n",
    "    df[column] = df[column].map(mapping)\n",
    "    return df\n",
    "\n",
    "def import_data(file, **kwargs):\n",
    "    \"\"\"Create a dataframe and optimize its memory usage.\"\"\"\n",
    "    df = pd.read_csv(file, parse_dates=True, keep_date_col=True, **kwargs)\n",
    "    df = reduce_mem_usage(df)\n",
    "    return df\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the dataset.\"\"\"\n",
    "    gender_mapping = {'Male': 1, 'Female': 0}\n",
    "    vehicle_damage_mapping = {'Yes': 1, 'No': 0}\n",
    "    vehicle_age_mapping = {'< 1 Year': 0, '1-2 Year': 1, '> 2 Years': 2}\n",
    "    \n",
    "    df = safe_map(df, 'Gender', gender_mapping)\n",
    "    df = safe_map(df, 'Vehicle_Damage', vehicle_damage_mapping)\n",
    "    df = safe_map(df, 'Vehicle_Age', vehicle_age_mapping)\n",
    "    \n",
    "    df.drop(['Driving_License'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def feature_engineering(df):\n",
    "    \"\"\"Feature engineering on the dataset.\"\"\"\n",
    "    df['Previously_Insured_Annual_Premium'] = pd.factorize((df['Previously_Insured'].astype(str) + df['Annual_Premium'].astype(str)))[0]\n",
    "    df['Previously_Insured_Vehicle_Age'] = pd.factorize((df['Previously_Insured'].astype(str) + df['Vehicle_Age'].astype(str)))[0]\n",
    "    df['Previously_Insured_Vehicle_Damage'] = pd.factorize((df['Previously_Insured'].astype(str) + df['Vehicle_Damage'].astype(str)))[0]\n",
    "    df['Previously_Insured_Vintage'] = pd.factorize((df['Previously_Insured'].astype(str) + df['Vintage'].astype(str)))[0]\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 23:13:56,190 - INFO - Start memory usage of dataframe: 1053.30 MB\n",
      "2024-07-23 23:13:57,831 - INFO - End memory usage of dataframe: 318.18 MB\n",
      "2024-07-23 23:13:57,831 - INFO - Decreased by 69.8%\n",
      "2024-07-23 23:14:07,967 - INFO - Start memory usage of dataframe: 643.68 MB\n",
      "2024-07-23 23:14:09,076 - INFO - End memory usage of dataframe: 204.81 MB\n",
      "2024-07-23 23:14:09,077 - INFO - Decreased by 68.2%\n",
      "2024-07-23 23:14:09,144 - INFO - Data loaded successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after import: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 23:14:11,051 - INFO - Data preprocessed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after preprocessing: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 23:14:45,424 - INFO - Feature engineering completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after feature engineering: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Paths to datasets\n",
    "train_path = r\"C:\\Users\\paulo\\OneDrive\\Documents\\kaggle_competition_2_datasets\\train.csv\"\n",
    "test_path = r\"C:\\Users\\paulo\\OneDrive\\Documents\\kaggle_competition_2_datasets\\test.csv\"\n",
    "\n",
    "# Load and optimize data\n",
    "train_df = import_data(train_path, index_col='id')\n",
    "test_df = import_data(test_path, index_col='id')\n",
    "\n",
    "gc.collect()\n",
    "print(f\"DataFrame after import: {type(train_df)}\")\n",
    "logging.info(\"Data loaded successfully.\")\n",
    "\n",
    "# Apply preprocessing\n",
    "train_df = preprocess_data(train_df)\n",
    "test_df = preprocess_data(test_df)\n",
    "print(f\"DataFrame after preprocessing: {type(train_df)}\")\n",
    "logging.info(\"Data preprocessed successfully.\")\n",
    "\n",
    "# Apply feature engineering\n",
    "train_df = feature_engineering(train_df)\n",
    "test_df = feature_engineering(test_df)\n",
    "\n",
    "gc.collect()\n",
    "print(f\"DataFrame after feature engineering: {type(train_df)}\")\n",
    "logging.info(\"Feature engineering completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = train_df.drop('Response', axis=1)\n",
    "y = train_df['Response']\n",
    "\n",
    "num_cols = ['Age', 'Region_Code', 'Annual_Premium', 'Policy_Sales_Channel', 'Vintage']\n",
    "scaler = StandardScaler()\n",
    "train_df[num_cols] = scaler.fit_transform(train_df[num_cols])\n",
    "test_df[num_cols] = scaler.transform(test_df[num_cols])\n",
    "\n",
    "# Create Stratified K-Folds\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- CatBoost Fold 1 ----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.8757758\tbest: 0.8757758 (0)\ttotal: 1.28s\tremaining: 1h 57m 40s\n",
      "100:\ttest: 0.8919066\tbest: 0.8919066 (100)\ttotal: 2m 21s\tremaining: 2h 6m 22s\n",
      "200:\ttest: 0.8934487\tbest: 0.8934487 (200)\ttotal: 4m 33s\tremaining: 2h 1s\n",
      "300:\ttest: 0.8940179\tbest: 0.8940179 (300)\ttotal: 6m 45s\tremaining: 1h 56m 41s\n",
      "400:\ttest: 0.8943058\tbest: 0.8943058 (400)\ttotal: 9m 2s\tremaining: 1h 55m 1s\n",
      "500:\ttest: 0.8945133\tbest: 0.8945133 (500)\ttotal: 11m 14s\tremaining: 1h 52m 13s\n",
      "600:\ttest: 0.8946729\tbest: 0.8946729 (600)\ttotal: 13m 31s\tremaining: 1h 50m 13s\n",
      "700:\ttest: 0.8947868\tbest: 0.8947868 (700)\ttotal: 15m 47s\tremaining: 1h 48m 3s\n",
      "800:\ttest: 0.8948612\tbest: 0.8948612 (800)\ttotal: 18m 3s\tremaining: 1h 45m 55s\n",
      "900:\ttest: 0.8949273\tbest: 0.8949273 (900)\ttotal: 20m 20s\tremaining: 1h 43m 48s\n",
      "1000:\ttest: 0.8949838\tbest: 0.8949838 (1000)\ttotal: 22m 34s\tremaining: 1h 41m 29s\n",
      "1100:\ttest: 0.8950353\tbest: 0.8950353 (1100)\ttotal: 24m 49s\tremaining: 1h 39m 9s\n",
      "1200:\ttest: 0.8950908\tbest: 0.8950908 (1200)\ttotal: 27m 4s\tremaining: 1h 36m 54s\n",
      "1300:\ttest: 0.8951126\tbest: 0.8951127 (1291)\ttotal: 29m 19s\tremaining: 1h 34m 37s\n",
      "1400:\ttest: 0.8951318\tbest: 0.8951318 (1400)\ttotal: 31m 34s\tremaining: 1h 32m 21s\n",
      "1500:\ttest: 0.8951464\tbest: 0.8951464 (1500)\ttotal: 33m 51s\tremaining: 1h 30m 12s\n",
      "1600:\ttest: 0.8951614\tbest: 0.8951620 (1589)\ttotal: 36m 5s\tremaining: 1h 27m 52s\n",
      "1700:\ttest: 0.8951771\tbest: 0.8951775 (1698)\ttotal: 38m 15s\tremaining: 1h 25m 27s\n",
      "1800:\ttest: 0.8951848\tbest: 0.8951856 (1783)\ttotal: 40m 30s\tremaining: 1h 23m 10s\n",
      "bestTest = 0.8951895833\n",
      "bestIteration = 1846\n",
      "Shrink model to first 1847 iterations.\n",
      "Validation AUC score for fold 1: 0.895190\n",
      "\n",
      "---- CatBoost Fold 2 ----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.8751968\tbest: 0.8751968 (0)\ttotal: 1.26s\tremaining: 1h 55m 46s\n",
      "100:\ttest: 0.8916085\tbest: 0.8916085 (100)\ttotal: 2m 17s\tremaining: 2h 2m 52s\n",
      "200:\ttest: 0.8930614\tbest: 0.8930614 (200)\ttotal: 4m 28s\tremaining: 1h 57m 53s\n",
      "300:\ttest: 0.8936133\tbest: 0.8936133 (300)\ttotal: 6m 41s\tremaining: 1h 55m 27s\n",
      "400:\ttest: 0.8939499\tbest: 0.8939499 (400)\ttotal: 8m 53s\tremaining: 1h 53m 3s\n",
      "500:\ttest: 0.8941349\tbest: 0.8941349 (500)\ttotal: 11m 6s\tremaining: 1h 50m 52s\n",
      "600:\ttest: 0.8942729\tbest: 0.8942729 (600)\ttotal: 13m 18s\tremaining: 1h 48m 28s\n",
      "700:\ttest: 0.8943772\tbest: 0.8943772 (700)\ttotal: 15m 31s\tremaining: 1h 46m 14s\n",
      "800:\ttest: 0.8944550\tbest: 0.8944550 (800)\ttotal: 17m 43s\tremaining: 1h 43m 58s\n",
      "900:\ttest: 0.8945208\tbest: 0.8945208 (900)\ttotal: 19m 54s\tremaining: 1h 41m 35s\n",
      "1000:\ttest: 0.8945849\tbest: 0.8945849 (1000)\ttotal: 22m 3s\tremaining: 1h 39m 10s\n",
      "1100:\ttest: 0.8946387\tbest: 0.8946387 (1100)\ttotal: 24m 14s\tremaining: 1h 36m 52s\n",
      "1200:\ttest: 0.8946714\tbest: 0.8946714 (1200)\ttotal: 26m 24s\tremaining: 1h 34m 33s\n",
      "1300:\ttest: 0.8947037\tbest: 0.8947037 (1300)\ttotal: 28m 37s\tremaining: 1h 32m 22s\n",
      "1400:\ttest: 0.8947293\tbest: 0.8947293 (1400)\ttotal: 30m 49s\tremaining: 1h 30m 9s\n",
      "1500:\ttest: 0.8947455\tbest: 0.8947455 (1500)\ttotal: 32m 59s\tremaining: 1h 27m 53s\n",
      "1600:\ttest: 0.8947678\tbest: 0.8947678 (1600)\ttotal: 35m 13s\tremaining: 1h 25m 46s\n",
      "1700:\ttest: 0.8947884\tbest: 0.8947884 (1700)\ttotal: 37m 24s\tremaining: 1h 23m 33s\n",
      "1800:\ttest: 0.8947996\tbest: 0.8948000 (1799)\ttotal: 39m 38s\tremaining: 1h 21m 24s\n",
      "1900:\ttest: 0.8948066\tbest: 0.8948067 (1893)\ttotal: 41m 52s\tremaining: 1h 19m 16s\n",
      "2000:\ttest: 0.8948146\tbest: 0.8948161 (1995)\ttotal: 44m 3s\tremaining: 1h 17m 2s\n",
      "2100:\ttest: 0.8948230\tbest: 0.8948236 (2098)\ttotal: 46m 16s\tremaining: 1h 14m 52s\n",
      "2200:\ttest: 0.8948347\tbest: 0.8948354 (2197)\ttotal: 48m 31s\tremaining: 1h 12m 43s\n",
      "2300:\ttest: 0.8948425\tbest: 0.8948439 (2277)\ttotal: 50m 44s\tremaining: 1h 10m 32s\n",
      "bestTest = 0.8948438764\n",
      "bestIteration = 2277\n",
      "Shrink model to first 2278 iterations.\n",
      "Validation AUC score for fold 2: 0.894844\n",
      "\n",
      "---- CatBoost Fold 3 ----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.8754984\tbest: 0.8754984 (0)\ttotal: 1.18s\tremaining: 1h 48m 1s\n",
      "100:\ttest: 0.8919761\tbest: 0.8919761 (100)\ttotal: 2m 16s\tremaining: 2h 1m 51s\n",
      "200:\ttest: 0.8934428\tbest: 0.8934428 (200)\ttotal: 4m 28s\tremaining: 1h 58m 2s\n",
      "300:\ttest: 0.8939869\tbest: 0.8939869 (300)\ttotal: 6m 39s\tremaining: 1h 55m 3s\n",
      "400:\ttest: 0.8942636\tbest: 0.8942636 (400)\ttotal: 8m 52s\tremaining: 1h 52m 51s\n",
      "500:\ttest: 0.8944498\tbest: 0.8944498 (500)\ttotal: 11m 5s\tremaining: 1h 50m 35s\n",
      "600:\ttest: 0.8945998\tbest: 0.8945998 (600)\ttotal: 13m 16s\tremaining: 1h 48m 13s\n",
      "700:\ttest: 0.8946897\tbest: 0.8946897 (700)\ttotal: 15m 31s\tremaining: 1h 46m 19s\n",
      "800:\ttest: 0.8947679\tbest: 0.8947679 (800)\ttotal: 17m 45s\tremaining: 1h 44m 8s\n",
      "900:\ttest: 0.8948267\tbest: 0.8948271 (899)\ttotal: 19m 56s\tremaining: 1h 41m 49s\n",
      "1000:\ttest: 0.8948674\tbest: 0.8948674 (1000)\ttotal: 22m 7s\tremaining: 1h 39m 25s\n",
      "1100:\ttest: 0.8949169\tbest: 0.8949169 (1100)\ttotal: 24m 19s\tremaining: 1h 37m 11s\n",
      "1200:\ttest: 0.8949580\tbest: 0.8949580 (1200)\ttotal: 26m 34s\tremaining: 1h 35m 9s\n",
      "1300:\ttest: 0.8949839\tbest: 0.8949840 (1298)\ttotal: 28m 47s\tremaining: 1h 32m 55s\n",
      "1400:\ttest: 0.8949967\tbest: 0.8949968 (1394)\ttotal: 31m\tremaining: 1h 30m 42s\n",
      "1500:\ttest: 0.8950201\tbest: 0.8950201 (1500)\ttotal: 33m 15s\tremaining: 1h 28m 35s\n",
      "1600:\ttest: 0.8950307\tbest: 0.8950316 (1564)\ttotal: 35m 27s\tremaining: 1h 26m 20s\n",
      "1700:\ttest: 0.8950477\tbest: 0.8950480 (1697)\ttotal: 37m 41s\tremaining: 1h 24m 10s\n",
      "1800:\ttest: 0.8950568\tbest: 0.8950578 (1776)\ttotal: 39m 51s\tremaining: 1h 21m 51s\n",
      "1900:\ttest: 0.8950675\tbest: 0.8950676 (1897)\ttotal: 42m 6s\tremaining: 1h 19m 43s\n",
      "2000:\ttest: 0.8950804\tbest: 0.8950806 (1993)\ttotal: 44m 19s\tremaining: 1h 17m 31s\n",
      "2100:\ttest: 0.8950900\tbest: 0.8950903 (2099)\ttotal: 46m 34s\tremaining: 1h 15m 21s\n",
      "2200:\ttest: 0.8950973\tbest: 0.8950995 (2170)\ttotal: 48m 51s\tremaining: 1h 13m 13s\n",
      "bestTest = 0.8950995207\n",
      "bestIteration = 2170\n",
      "Shrink model to first 2171 iterations.\n",
      "Validation AUC score for fold 3: 0.895100\n",
      "\n",
      "---- CatBoost Fold 4 ----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.8751477\tbest: 0.8751477 (0)\ttotal: 1.45s\tremaining: 2h 13m\n",
      "100:\ttest: 0.8917821\tbest: 0.8917821 (100)\ttotal: 2m 19s\tremaining: 2h 4m 10s\n",
      "200:\ttest: 0.8931704\tbest: 0.8931704 (200)\ttotal: 4m 28s\tremaining: 1h 57m 49s\n",
      "300:\ttest: 0.8937134\tbest: 0.8937134 (300)\ttotal: 6m 41s\tremaining: 1h 55m 40s\n",
      "400:\ttest: 0.8940150\tbest: 0.8940150 (400)\ttotal: 8m 54s\tremaining: 1h 53m 20s\n",
      "500:\ttest: 0.8942310\tbest: 0.8942310 (500)\ttotal: 11m 8s\tremaining: 1h 51m 11s\n",
      "600:\ttest: 0.8943666\tbest: 0.8943666 (600)\ttotal: 13m 20s\tremaining: 1h 48m 48s\n",
      "700:\ttest: 0.8944755\tbest: 0.8944755 (700)\ttotal: 15m 30s\tremaining: 1h 46m 12s\n",
      "800:\ttest: 0.8945644\tbest: 0.8945644 (800)\ttotal: 17m 46s\tremaining: 1h 44m 13s\n",
      "900:\ttest: 0.8946195\tbest: 0.8946195 (900)\ttotal: 20m\tremaining: 1h 42m 6s\n",
      "1000:\ttest: 0.8946787\tbest: 0.8946787 (1000)\ttotal: 22m 11s\tremaining: 1h 39m 43s\n",
      "1100:\ttest: 0.8947118\tbest: 0.8947120 (1098)\ttotal: 24m 25s\tremaining: 1h 37m 34s\n",
      "1200:\ttest: 0.8947526\tbest: 0.8947528 (1199)\ttotal: 26m 37s\tremaining: 1h 35m 19s\n",
      "1300:\ttest: 0.8947913\tbest: 0.8947914 (1284)\ttotal: 28m 55s\tremaining: 1h 33m 20s\n",
      "1400:\ttest: 0.8948224\tbest: 0.8948227 (1399)\ttotal: 31m 6s\tremaining: 1h 31m 1s\n",
      "1500:\ttest: 0.8948481\tbest: 0.8948481 (1500)\ttotal: 33m 18s\tremaining: 1h 28m 43s\n",
      "1600:\ttest: 0.8948641\tbest: 0.8948641 (1598)\ttotal: 35m 32s\tremaining: 1h 26m 32s\n",
      "1700:\ttest: 0.8948781\tbest: 0.8948781 (1700)\ttotal: 37m 48s\tremaining: 1h 24m 26s\n",
      "1800:\ttest: 0.8948917\tbest: 0.8948929 (1793)\ttotal: 40m 4s\tremaining: 1h 22m 17s\n",
      "1900:\ttest: 0.8949040\tbest: 0.8949040 (1900)\ttotal: 42m 18s\tremaining: 1h 20m 5s\n",
      "2000:\ttest: 0.8949171\tbest: 0.8949189 (1988)\ttotal: 44m 35s\tremaining: 1h 17m 58s\n",
      "2100:\ttest: 0.8949257\tbest: 0.8949262 (2099)\ttotal: 46m 49s\tremaining: 1h 15m 45s\n",
      "2200:\ttest: 0.8949311\tbest: 0.8949326 (2186)\ttotal: 49m 10s\tremaining: 1h 13m 41s\n",
      "2300:\ttest: 0.8949392\tbest: 0.8949405 (2291)\ttotal: 51m 25s\tremaining: 1h 11m 29s\n",
      "bestTest = 0.8949404955\n",
      "bestIteration = 2291\n",
      "Shrink model to first 2292 iterations.\n",
      "Validation AUC score for fold 4: 0.894940\n",
      "\n",
      "---- CatBoost Fold 5 ----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.8762399\tbest: 0.8762399 (0)\ttotal: 1.2s\tremaining: 1h 50m 7s\n",
      "100:\ttest: 0.8922962\tbest: 0.8922962 (100)\ttotal: 2m 20s\tremaining: 2h 5m 12s\n",
      "200:\ttest: 0.8938102\tbest: 0.8938102 (200)\ttotal: 4m 32s\tremaining: 1h 59m 35s\n",
      "300:\ttest: 0.8943968\tbest: 0.8943968 (300)\ttotal: 6m 46s\tremaining: 1h 57m 8s\n",
      "400:\ttest: 0.8947190\tbest: 0.8947190 (400)\ttotal: 9m\tremaining: 1h 54m 28s\n",
      "500:\ttest: 0.8948994\tbest: 0.8948994 (500)\ttotal: 11m 13s\tremaining: 1h 52m 4s\n",
      "600:\ttest: 0.8950514\tbest: 0.8950514 (600)\ttotal: 13m 27s\tremaining: 1h 49m 43s\n",
      "700:\ttest: 0.8951722\tbest: 0.8951722 (700)\ttotal: 15m 42s\tremaining: 1h 47m 31s\n",
      "800:\ttest: 0.8952501\tbest: 0.8952501 (800)\ttotal: 17m 58s\tremaining: 1h 45m 25s\n",
      "900:\ttest: 0.8953233\tbest: 0.8953233 (900)\ttotal: 20m 14s\tremaining: 1h 43m 21s\n",
      "1000:\ttest: 0.8953665\tbest: 0.8953665 (1000)\ttotal: 22m 30s\tremaining: 1h 41m 9s\n",
      "1100:\ttest: 0.8954027\tbest: 0.8954027 (1100)\ttotal: 24m 45s\tremaining: 1h 38m 56s\n",
      "1200:\ttest: 0.8954355\tbest: 0.8954355 (1200)\ttotal: 27m 3s\tremaining: 1h 36m 50s\n",
      "1300:\ttest: 0.8954639\tbest: 0.8954647 (1296)\ttotal: 29m 19s\tremaining: 1h 34m 38s\n",
      "1400:\ttest: 0.8954886\tbest: 0.8954886 (1400)\ttotal: 31m 36s\tremaining: 1h 32m 27s\n",
      "1500:\ttest: 0.8955092\tbest: 0.8955097 (1499)\ttotal: 33m 52s\tremaining: 1h 30m 15s\n",
      "1600:\ttest: 0.8955246\tbest: 0.8955248 (1595)\ttotal: 36m 8s\tremaining: 1h 28m\n",
      "1700:\ttest: 0.8955360\tbest: 0.8955368 (1681)\ttotal: 38m 23s\tremaining: 1h 25m 44s\n",
      "1800:\ttest: 0.8955449\tbest: 0.8955452 (1795)\ttotal: 40m 37s\tremaining: 1h 23m 26s\n",
      "1900:\ttest: 0.8955512\tbest: 0.8955522 (1880)\ttotal: 42m 52s\tremaining: 1h 21m 10s\n",
      "2000:\ttest: 0.8955588\tbest: 0.8955594 (1998)\ttotal: 45m 12s\tremaining: 1h 19m 2s\n",
      "2100:\ttest: 0.8955650\tbest: 0.8955656 (2075)\ttotal: 47m 30s\tremaining: 1h 16m 51s\n",
      "bestTest = 0.895565629\n",
      "bestIteration = 2075\n",
      "Shrink model to first 2076 iterations.\n",
      "Validation AUC score for fold 5: 0.895566\n",
      "\n",
      "---> Overall ROC-AUC Score for CatBoost: 0.895128 ± 0.000250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define CatBoost parameters\n",
    "cat_params = {\n",
    "    'loss_function': 'Logloss',\n",
    "    'eval_metric': 'AUC',\n",
    "    'class_names': [0, 1],\n",
    "    'learning_rate': 0.075,\n",
    "    'iterations': 5500,\n",
    "    'depth': 9,\n",
    "    'random_strength': 0,\n",
    "    'l2_leaf_reg': 0.5,\n",
    "    'max_leaves': 512,\n",
    "    'fold_permutation_block': 64,\n",
    "    'task_type': 'GPU',  # Ensure your environment supports GPU\n",
    "    'random_seed': 42,\n",
    "    'allow_writing_files': False,\n",
    "    'verbose': 100,  # Display log every 100 iterations\n",
    "    # 'thread_count': -1\n",
    "}\n",
    "\n",
    "# Initialize lists to store out-of-fold predictions and AUC scores\n",
    "cat_preds = []\n",
    "cat_aucs = []\n",
    "\n",
    "test_pool = Pool(test_df.astype(str), cat_features=X.columns.values)\n",
    "\n",
    "# CatBoost Model\n",
    "for fold, (train_idx, test_idx) in enumerate(skfold.split(X, y)):\n",
    "    print(f\"\\n---- CatBoost Fold {fold + 1} ----\\n\")\n",
    "    \n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_valid, y_valid = X.iloc[test_idx], y.iloc[test_idx]\n",
    "    \n",
    "    train_pool = Pool(X_train.astype(str), y_train, cat_features=X.columns.values)\n",
    "    valid_pool = Pool(X_valid.astype(str), y_valid, cat_features=X.columns.values)\n",
    "    \n",
    "    model = CatBoostClassifier(**cat_params)\n",
    "    model.fit(train_pool, eval_set=valid_pool, early_stopping_rounds=50, verbose=100)\n",
    "    \n",
    "    valid_preds = model.predict_proba(X_valid.astype(str))[:, 1]\n",
    "    auc_score = roc_auc_score(y_valid, valid_preds)\n",
    "    cat_aucs.append(auc_score)\n",
    "    print(f\"Validation AUC score for fold {fold + 1}: {auc_score:.6f}\")\n",
    "    \n",
    "    test_pred = model.predict_proba(test_pool)[:, 1]\n",
    "    cat_preds.append(test_pred)\n",
    "    \n",
    "    # Clear memory\n",
    "    del X_train, y_train, X_valid, y_valid, train_pool, valid_pool, model\n",
    "    gc.collect()\n",
    "\n",
    "# Calculate overall AUC score for CatBoost\n",
    "auc_mean_cat = np.mean(cat_aucs)\n",
    "auc_std_cat = np.std(cat_aucs)\n",
    "print(f\"\\n---> Overall ROC-AUC Score for CatBoost: {auc_mean_cat:.6f} ± {auc_std_cat:.6f}\\n\")\n",
    "\n",
    "# Average the predictions from each fold for CatBoost\n",
    "test_pred_cat = np.mean(cat_preds, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Fold 1 ----\n",
      "\n",
      "Fold 1 class distribution in training set: [8071791 1132047]\n",
      "Fold 1 class distribution in validation set: [2017948  283012]\n",
      "[LightGBM] [Info] Number of positive: 1132047, number of negative: 8071791\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1254\n",
      "[LightGBM] [Info] Number of data points in the train set: 9203838, number of used features: 13\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2070 SUPER, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (140.44 MB) transferred to GPU in 0.137421 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Initialize model as None\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 43\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlgb_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     valid_preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_valid, num_iteration\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mbest_iteration)\n\u001b[0;32m     51\u001b[0m     auc_score \u001b[38;5;241m=\u001b[39m roc_auc_score(y_valid, valid_preds)\n",
      "File \u001b[1;32mc:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\lightgbm\\engine.py:307\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[0;32m    296\u001b[0m     cb(\n\u001b[0;32m    297\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[0;32m    298\u001b[0m             model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    304\u001b[0m         )\n\u001b[0;32m    305\u001b[0m     )\n\u001b[1;32m--> 307\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    309\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    310\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\lightgbm\\basic.py:4126\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   4123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[0;32m   4124\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4125\u001b[0m _safe_call(\n\u001b[1;32m-> 4126\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4129\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4130\u001b[0m )\n\u001b[0;32m   4131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[0;32m   4132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define LightGBM parameters\n",
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'reg_alpha': 0.03432385172267505,\n",
    "    'reg_lambda': 0.2998279059616829,\n",
    "    'colsample_bytree': 0.790292183596673,\n",
    "    'subsample': 0.9046878168822107,\n",
    "    'learning_rate': 0.05035039561309864,\n",
    "    'max_depth': 10,  # Further reduced max depth\n",
    "    'num_leaves': 31,  # Standard number of leaves\n",
    "    'min_child_samples': 100,  # Increased min child samples\n",
    "    'min_child_weight': 1,  # Adjusted min child weight\n",
    "    'min_split_gain': 0.09978597066868167,\n",
    "    'max_bin': 255,\n",
    "    'device': 'gpu',\n",
    "    'early_stopping_rounds': 50,\n",
    "    'verbose': 1  # Enable verbose mode\n",
    "}\n",
    "\n",
    "# Initialize lists to store out-of-fold predictions and AUC scores\n",
    "lgb_preds = []\n",
    "lgb_aucs = []\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Train LightGBM model with cross-validation\n",
    "for fold, (train_idx, test_idx) in enumerate(skfold.split(X, y)):\n",
    "    print(f\"\\n---- Fold {fold + 1} ----\\n\")\n",
    "    \n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_valid, y_valid = X.iloc[test_idx], y.iloc[test_idx]\n",
    "\n",
    "    print(f\"Fold {fold + 1} class distribution in training set: {np.bincount(y_train)}\")\n",
    "    print(f\"Fold {fold + 1} class distribution in validation set: {np.bincount(y_valid)}\")\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
    "    \n",
    "    model = None  # Initialize model as None\n",
    "    try:\n",
    "        model = lgb.train(\n",
    "            lgb_params,\n",
    "            train_data,\n",
    "            num_boost_round=3000,\n",
    "            valid_sets=[train_data, valid_data],\n",
    "        )\n",
    "        \n",
    "        valid_preds = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "        auc_score = roc_auc_score(y_valid, valid_preds)\n",
    "        lgb_aucs.append(auc_score)\n",
    "        print(f\"Validation AUC score for fold {fold + 1}: {auc_score:.6f}\")\n",
    "        \n",
    "        test_pred = model.predict(test_df, num_iteration=model.best_iteration)  # Use test_df for the test set\n",
    "        lgb_preds.append(test_pred)\n",
    "        \n",
    "    except lgb.basic.LightGBMError as e:\n",
    "        print(f\"LightGBMError in fold {fold + 1}: {str(e)}\")\n",
    "    \n",
    "    # Clear memory\n",
    "    del X_train, y_train, X_valid, y_valid, train_data, valid_data\n",
    "    if model is not None:\n",
    "        del model\n",
    "    gc.collect()\n",
    "\n",
    "# Calculate overall AUC score\n",
    "auc_mean_lgb = np.mean(lgb_aucs)\n",
    "auc_std_lgb = np.std(lgb_aucs)\n",
    "print(f\"\\n---> Overall ROC-AUC Score: {auc_mean_lgb:.6f} ± {auc_std_lgb:.6f}\\n\")\n",
    "\n",
    "# Average the predictions from each fold\n",
    "test_pred_lgb = np.mean(lgb_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Fold 1 ----\n",
      "\n",
      "[0]\ttrain-auc:0.84812\tvalid-auc:0.84825\n",
      "[100]\ttrain-auc:0.88909\tvalid-auc:0.88171\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m dtrain \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(X_train, label\u001b[38;5;241m=\u001b[39my_train, enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     33\u001b[0m dvalid \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(X_valid, label\u001b[38;5;241m=\u001b[39my_valid, enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 35\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdvalid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Display log every 100 rounds\u001b[39;49;00m\n\u001b[0;32m     42\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Use best_iteration instead of best_ntree_limit\u001b[39;00m\n\u001b[0;32m     45\u001b[0m valid_preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(dvalid, iteration_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, model\u001b[38;5;241m.\u001b[39mbest_iteration))\n",
      "File \u001b[1;32mc:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\xgboost\\core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2100\u001b[0m     _check_call(\n\u001b[1;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2104\u001b[0m     )\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define XGBoost parameters\n",
    "xgb_params = {\n",
    "    'eval_metric': 'auc',\n",
    "    'eta': 0.05,\n",
    "    'alpha': 0.2545607592482198,\n",
    "    'subsample': 0.8388163485383147,\n",
    "    'colsample_bytree': 0.2732499701466825,\n",
    "    'max_depth': 16,\n",
    "    'min_child_weight': 5,\n",
    "    'gamma': 0.0017688666476104672,\n",
    "    'max_bin': 262143,\n",
    "    'tree_method': 'gpu_hist',  # Ensure your environment supports GPU\n",
    "    'predictor': 'gpu_predictor',  # Ensure your environment supports GPU\n",
    "    'enable_categorical': True,\n",
    "    'verbose': 100\n",
    "}\n",
    "\n",
    "# Initialize lists to store out-of-fold predictions and AUC scores\n",
    "xgb_preds = []\n",
    "xgb_aucs = []\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Train XGBoost model with cross-validation\n",
    "for fold, (train_idx, test_idx) in enumerate(skfold.split(X, y)):\n",
    "    print(f\"\\n---- Fold {fold + 1} ----\\n\")\n",
    "    \n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_valid, y_valid = X.iloc[test_idx], y.iloc[test_idx]\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)\n",
    "    dvalid = xgb.DMatrix(X_valid, label=y_valid, enable_categorical=True)\n",
    "    \n",
    "    model = xgb.train(\n",
    "        xgb_params,\n",
    "        dtrain,\n",
    "        num_boost_round=3000,\n",
    "        evals=[(dtrain, 'train'), (dvalid, 'valid')],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=100  # Display log every 100 rounds\n",
    "    )\n",
    "    \n",
    "    # Use best_iteration instead of best_ntree_limit\n",
    "    valid_preds = model.predict(dvalid, iteration_range=(0, model.best_iteration))\n",
    "    auc_score = roc_auc_score(y_valid, valid_preds)\n",
    "    xgb_aucs.append(auc_score)\n",
    "    print(f\"Validation AUC score for fold {fold + 1}: {auc_score:.6f}\")\n",
    "    \n",
    "    dtest = xgb.DMatrix(test_df, enable_categorical=True)  # Use test_df for the test set\n",
    "    test_pred = model.predict(dtest, iteration_range=(0, model.best_iteration))\n",
    "    xgb_preds.append(test_pred)\n",
    "    \n",
    "    # Clear memory\n",
    "    del X_train, y_train, X_valid, y_valid, dtrain, dvalid, model\n",
    "    gc.collect()\n",
    "\n",
    "# Calculate overall AUC score for XGBoost\n",
    "auc_mean_xgb = np.mean(xgb_aucs)\n",
    "auc_std_xgb = np.std(xgb_aucs)\n",
    "print(f\"\\n---> Overall ROC-AUC Score for XGBoost: {auc_mean_xgb:.6f} ± {auc_std_xgb:.6f}\\n\")\n",
    "\n",
    "# Average the predictions from each fold for XGBoost\n",
    "test_pred_xgb = np.mean(xgb_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 18:59:07,501 - INFO - Memory usage of dataframe is 643.68 MB\n",
      "2024-07-23 18:59:08,626 - INFO - Memory usage after optimization is: 175.55 MB\n",
      "2024-07-23 18:59:08,627 - INFO - Decreased by 72.7%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights - CatBoost: 0.3334, LightGBM: 0.3328, XGBoost: 0.3338\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m blended_preds \u001b[38;5;241m=\u001b[39m (weight_cat \u001b[38;5;241m*\u001b[39m test_pred_cat \u001b[38;5;241m+\u001b[39m weight_lgb \u001b[38;5;241m*\u001b[39m test_pred_lgb \u001b[38;5;241m+\u001b[39m weight_xgb \u001b[38;5;241m*\u001b[39m test_pred_xgb)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Create the submission DataFrame\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m submission \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mResponse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mblended_preds\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Save the submission file\u001b[39;00m\n\u001b[0;32m     23\u001b[0m submission\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubmission.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    682\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "test_df = import_data(test_path, index_col='id')\n",
    "\n",
    "# Normalize AUC scores to sum to 1\n",
    "total_auc = auc_mean_cat + auc_mean_lgb + auc_mean_xgb\n",
    "\n",
    "weight_cat = auc_mean_cat / total_auc\n",
    "weight_lgb = auc_mean_lgb / total_auc\n",
    "weight_xgb = auc_mean_xgb / total_auc\n",
    "\n",
    "# Print weights for verification\n",
    "print(f\"Weights - CatBoost: {weight_cat:.4f}, LightGBM: {weight_lgb:.4f}, XGBoost: {weight_xgb:.4f}\")\n",
    "\n",
    "# Blending predictions with calculated weights\n",
    "blended_preds = (weight_cat * test_pred_cat + weight_lgb * test_pred_lgb + weight_xgb * test_pred_xgb)\n",
    "\n",
    "# Create the submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df.index,\n",
    "    'Response': blended_preds\n",
    "})\n",
    "\n",
    "# Save the submission file\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"Submission file created successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
