{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 21:16:21,727 - INFO - Sample data loaded from C:\\Users\\paulo\\OneDrive\\Documents\\kaggle_competition_2_datasets\\train.csv\n",
      "2024-07-23 21:16:21,729 - INFO - Start memory usage of dataframe: 0.92 MB\n",
      "2024-07-23 21:16:21,742 - WARNING - Column Region_Code has changed: {'min': 0.0, 'max': 51.0, 'mean': 26.2959, 'unique': 52} != {'min': 0.0, 'max': 51.0, 'mean': 26.2959, 'unique': 52}\n",
      "2024-07-23 21:16:21,743 - WARNING - Column Annual_Premium has changed: {'min': 2630.0, 'max': 289606.0, 'mean': 30482.4002, 'unique': 6316} != {'min': 2630.0, 'max': 289606.0, 'mean': 30482.4, 'unique': 6316}\n",
      "2024-07-23 21:16:21,743 - WARNING - Column Policy_Sales_Channel has changed: {'min': 1.0, 'max': 163.0, 'mean': 112.7599, 'unique': 82} != {'min': 1.0, 'max': 163.0, 'mean': 112.7599, 'unique': 82}\n",
      "2024-07-23 21:16:21,744 - INFO - Column id precision loss: 0.000000%\n",
      "2024-07-23 21:16:21,744 - INFO - Column Age precision loss: 0.000000%\n",
      "2024-07-23 21:16:21,744 - INFO - Column Driving_License precision loss: 0.000000%\n",
      "2024-07-23 21:16:21,745 - INFO - Column Region_Code precision loss: 0.000001%\n",
      "2024-07-23 21:16:21,745 - INFO - Column Previously_Insured precision loss: 0.000000%\n",
      "2024-07-23 21:16:21,745 - INFO - Column Annual_Premium precision loss: 0.000001%\n",
      "2024-07-23 21:16:21,747 - INFO - Column Policy_Sales_Channel precision loss: 0.000003%\n",
      "2024-07-23 21:16:21,747 - INFO - Column Vintage precision loss: 0.000000%\n",
      "2024-07-23 21:16:21,748 - INFO - Column Response precision loss: 0.000000%\n",
      "2024-07-23 21:16:21,749 - INFO - End memory usage of dataframe: 0.22 MB\n",
      "2024-07-23 21:16:21,749 - INFO - Decreased by 76.0%\n",
      "2024-07-23 21:16:21,792 - INFO - Sample data processed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id Gender  Age  Region_Code  Previously_Insured Vehicle_Age Vehicle_Damage  \\\n",
      "0   0      1   21         35.0                   0           1              1   \n",
      "1   1      1   43         28.0                   0           2              1   \n",
      "2   2      0   25         14.0                   1           0              0   \n",
      "3   3      0   35          1.0                   0           1              1   \n",
      "4   4      0   36         15.0                   1           1              0   \n",
      "\n",
      "   Annual_Premium  Policy_Sales_Channel  Vintage  Response  \\\n",
      "0         65101.0                 124.0      187         0   \n",
      "1         58911.0                  26.0      288         1   \n",
      "2         38043.0                 152.0      254         0   \n",
      "3          2630.0                 156.0       76         0   \n",
      "4         31951.0                 152.0      294         0   \n",
      "\n",
      "   Previously_Insured_Annual_Premium  Previously_Insured_Vehicle_Age  \\\n",
      "0                                  0                               0   \n",
      "1                                  1                               1   \n",
      "2                                  2                               2   \n",
      "3                                  3                               0   \n",
      "4                                  4                               3   \n",
      "\n",
      "   Previously_Insured_Vehicle_Damage  Previously_Insured_Vintage  \n",
      "0                                  0                           0  \n",
      "1                                  0                           1  \n",
      "2                                  1                           2  \n",
      "3                                  0                           3  \n",
      "4                                  1                           4  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "def get_column_stats(df):\n",
    "    \"\"\"Get basic statistics for each column in the dataframe.\"\"\"\n",
    "    stats = {}\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            stats[col] = {\n",
    "                'min': df[col].min(),\n",
    "                'max': df[col].max(),\n",
    "                'mean': df[col].mean(),\n",
    "            }\n",
    "        else:\n",
    "            stats[col] = {\n",
    "                'unique': df[col].nunique()\n",
    "            }\n",
    "    return stats\n",
    "\n",
    "def compare_stats(stats_before, stats_after):\n",
    "    \"\"\"Compare statistics before and after type conversion.\"\"\"\n",
    "    for col in stats_before:\n",
    "        if stats_before[col] != stats_after[col]:\n",
    "            logging.warning(f\"Column {col} has changed: {stats_before[col]} != {stats_after[col]}\")\n",
    "\n",
    "def calculate_precision_loss(stats_before, stats_after):\n",
    "    \"\"\"Calculate and log precision loss for numeric columns.\"\"\"\n",
    "    for col in stats_before:\n",
    "        if 'mean' in stats_before[col]:\n",
    "            mean_before = stats_before[col]['mean']\n",
    "            mean_after = stats_after[col]['mean']\n",
    "            precision_loss = abs(mean_before - mean_after) / abs(mean_before) * 100\n",
    "            logging.info(f\"Column {col} precision loss: {precision_loss:.6f}%\")\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.\"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        logging.info(f'Start memory usage of dataframe: {start_mem:.2f} MB')\n",
    "\n",
    "    stats_before = get_column_stats(df)\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    stats_after = get_column_stats(df)\n",
    "    compare_stats(stats_before, stats_after)\n",
    "    calculate_precision_loss(stats_before, stats_after)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        logging.info(f'End memory usage of dataframe: {end_mem:.2f} MB')\n",
    "        logging.info(f'Decreased by {(100 * (start_mem - end_mem) / start_mem):.1f}%')\n",
    "\n",
    "    return df\n",
    "\n",
    "def safe_map(df, column, mapping):\n",
    "    \"\"\"Map categorical values to numerical values and log any unknown categories.\"\"\"\n",
    "    unknown_categories = set(df[column]) - set(mapping.keys())\n",
    "    if unknown_categories:\n",
    "        logging.warning(f\"Unknown categories in column {column}: {unknown_categories}\")\n",
    "    df[column] = df[column].map(mapping)\n",
    "    return df\n",
    "\n",
    "# Load a sample of the dataset\n",
    "def load_sample_data(file, sample_size=10000):\n",
    "    \"\"\"Load a sample of the dataset for testing.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file, nrows=sample_size)\n",
    "        logging.info(f'Sample data loaded from {file}')\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading sample data from {file}: {e}\")\n",
    "        raise\n",
    "    return df\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the dataset.\"\"\"\n",
    "    gender_mapping = {'Male': 1, 'Female': 0}\n",
    "    vehicle_damage_mapping = {'Yes': 1, 'No': 0}\n",
    "    vehicle_age_mapping = {'< 1 Year': 0, '1-2 Year': 1, '> 2 Years': 2}\n",
    "    \n",
    "    df = safe_map(df, 'Gender', gender_mapping)\n",
    "    df = safe_map(df, 'Vehicle_Damage', vehicle_damage_mapping)\n",
    "    df = safe_map(df, 'Vehicle_Age', vehicle_age_mapping)\n",
    "    \n",
    "    df.drop(['Driving_License'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def feature_engineering(df):\n",
    "    \"\"\"Feature engineering on the dataset.\"\"\"\n",
    "    df['Previously_Insured_Annual_Premium'] = pd.factorize((df['Previously_Insured'].astype(str) + df['Annual_Premium'].astype(str)))[0]\n",
    "    df['Previously_Insured_Vehicle_Age'] = pd.factorize((df['Previously_Insured'].astype(str) + df['Vehicle_Age'].astype(str)))[0]\n",
    "    df['Previously_Insured_Vehicle_Damage'] = pd.factorize((df['Previously_Insured'].astype(str) + df['Vehicle_Damage'].astype(str)))[0]\n",
    "    df['Previously_Insured_Vintage'] = pd.factorize((df['Previously_Insured'].astype(str) + df['Vintage'].astype(str)))[0]\n",
    "    return df\n",
    "\n",
    "# Path to the dataset\n",
    "file_path = r\"C:\\Users\\paulo\\OneDrive\\Documents\\kaggle_competition_2_datasets\\train.csv\"\n",
    "\n",
    "# Load a sample of the data\n",
    "sample_df = load_sample_data(file_path)\n",
    "\n",
    "# Save a copy of the original sample for comparison\n",
    "original_sample_df = sample_df.copy()\n",
    "\n",
    "# Reduce memory usage\n",
    "sample_df = reduce_mem_usage(sample_df)\n",
    "\n",
    "# Compare specific rows and columns\n",
    "comparison = original_sample_df.compare(sample_df)\n",
    "if not comparison.empty:\n",
    "    logging.warning(\"Differences found between original and optimized data:\")\n",
    "    print(comparison)\n",
    "\n",
    "# Apply preprocessing\n",
    "sample_df = preprocess_data(sample_df)\n",
    "\n",
    "# Apply feature engineering\n",
    "sample_df = feature_engineering(sample_df)\n",
    "\n",
    "logging.info(\"Sample data processed successfully.\")\n",
    "\n",
    "# Display the processed sample data\n",
    "print(sample_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
