{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-6.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-6 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-6 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-6 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table th,\n",
       "#h2o-table-6 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-6 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-6\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>16 mins 34 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/Costa_Rica</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>7 days, 23 hours and 59 minutes</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_paulo_o0nbvb</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>5.963 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.8.19 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -------------------------------\n",
       "H2O_cluster_uptime:         16 mins 34 secs\n",
       "H2O_cluster_timezone:       America/Costa_Rica\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.4\n",
       "H2O_cluster_version_age:    7 days, 23 hours and 59 minutes\n",
       "H2O_cluster_name:           H2O_from_python_paulo_o0nbvb\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    5.963 Gb\n",
       "H2O_cluster_total_cores:    16\n",
       "H2O_cluster_allowed_cores:  16\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.8.19 final\n",
       "--------------------------  -------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |█\n",
      "20:11:12.543: AutoML: XGBoost is not available; skipping it.\n",
      "20:11:12.547: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n",
      "\n",
      "████ (cancelled)\n"
     ]
    },
    {
     "ename": "H2OJobCancelled",
     "evalue": "Job<$03017f00000132d4ffffffff$_b91f0cbc1cf7b90c75dee7a0bf544842> was cancelled by the user.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mH2OJobCancelled\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 29\u001b[0m\n\u001b[0;32m     21\u001b[0m aml \u001b[38;5;241m=\u001b[39m H2OAutoML(max_runtime_secs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3600\u001b[39m,  \u001b[38;5;66;03m# Set the maximum runtime for the AutoML process\u001b[39;00m\n\u001b[0;32m     22\u001b[0m                 seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,  \u001b[38;5;66;03m# For reproducibility\u001b[39;00m\n\u001b[0;32m     23\u001b[0m                 nfolds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,  \u001b[38;5;66;03m# Number of folds for cross-validation\u001b[39;00m\n\u001b[0;32m     24\u001b[0m                 balance_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# Balance classes for binary classification\u001b[39;00m\n\u001b[0;32m     25\u001b[0m                 sort_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUC\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Ensure the leaderboard is sorted by AUC  # Specify to use GBM which can leverage GPU  # Exclude deep learning to avoid conflicts\u001b[39;00m\n\u001b[0;32m     26\u001b[0m                 )\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[43maml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Get the leaderboard of models sorted by AUC\u001b[39;00m\n\u001b[0;32m     32\u001b[0m lb \u001b[38;5;241m=\u001b[39m aml\u001b[38;5;241m.\u001b[39mleaderboard\n",
      "File \u001b[1;32mc:\\Users\\paulo\\anaconda3\\envs\\h2o_env\\lib\\site-packages\\h2o\\automl\\_estimator.py:682\u001b[0m, in \u001b[0;36mH2OAutoML.train\u001b[1;34m(self, x, y, training_frame, fold_column, weights_column, validation_frame, leaderboard_frame, blending_frame)\u001b[0m\n\u001b[0;32m    680\u001b[0m poll_updates \u001b[38;5;241m=\u001b[39m ft\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll_training_updates, verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verbosity, state\u001b[38;5;241m=\u001b[39m{})\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 682\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoll_updates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoll_updates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    684\u001b[0m     poll_updates(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_job, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\paulo\\anaconda3\\envs\\h2o_env\\lib\\site-packages\\h2o\\job.py:85\u001b[0m, in \u001b[0;36mH2OJob.poll\u001b[1;34m(self, poll_updates)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# check if failed... and politely print relevant message\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCANCELLED\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m H2OJobCancelled(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob<\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m> was cancelled by the user.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_key)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFAILED\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob, \u001b[38;5;28mdict\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstacktrace\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob)):\n",
      "\u001b[1;31mH2OJobCancelled\u001b[0m: Job<$03017f00000132d4ffffffff$_b91f0cbc1cf7b90c75dee7a0bf544842> was cancelled by the user."
     ]
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the H2O cluster with GPU support\n",
    "h2o.init(nthreads=4)\n",
    "\n",
    "# Import the dataset\n",
    "data_path = r\"C:\\Users\\paulo\\OneDrive\\Documents\\kaggle_competition_2_datasets\\train.csv\"\n",
    "data = h2o.import_file(data_path)\n",
    "\n",
    "# Specify the target and features\n",
    "target = 'Response'\n",
    "features = data.columns\n",
    "features.remove(target)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train, test = data.split_frame(ratios=[0.8], seed=42)\n",
    "\n",
    "# Initialize the H2O AutoML class with GPU support\n",
    "aml = H2OAutoML(max_runtime_secs=3600,  # Set the maximum runtime for the AutoML process\n",
    "                seed=42,  # For reproducibility\n",
    "                nfolds=5,  # Number of folds for cross-validation\n",
    "                balance_classes=True,  # Balance classes for binary classification\n",
    "                sort_metric='AUC',  # Ensure the leaderboard is sorted by AUC  # Specify to use GBM which can leverage GPU  # Exclude deep learning to avoid conflicts\n",
    "                )\n",
    "\n",
    "# Train the model\n",
    "aml.train(x=features, y=target, training_frame=train)\n",
    "\n",
    "# Get the leaderboard of models sorted by AUC\n",
    "lb = aml.leaderboard\n",
    "print(lb)\n",
    "\n",
    "# Get the best model based on AUC\n",
    "best_model = h2o.get_model(lb[0, 'model_id'])\n",
    "print(best_model)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = best_model.predict(test)\n",
    "print(predictions)\n",
    "\n",
    "# Shutdown the H2O cluster\n",
    "h2o.shutdown(prompt=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
