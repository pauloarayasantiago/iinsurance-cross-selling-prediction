{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 00:59:38,780] A new study created in memory with name: no-name-d0b6a3f3-50d3-4e78-b2c2-e4ccb18feb91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7656322273497828, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7656322273497828\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09791751210195702, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09791751210195702\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1916031521921471, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1916031521921471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7310339612565164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7310339612565164\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7656322273497828, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7656322273497828\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09791751210195702, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09791751210195702\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1916031521921471, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1916031521921471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7310339612565164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7310339612565164\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7656322273497828, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7656322273497828\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09791751210195702, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09791751210195702\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1916031521921471, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1916031521921471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7310339612565164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7310339612565164\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7656322273497828, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7656322273497828\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09791751210195702, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09791751210195702\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1916031521921471, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1916031521921471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7310339612565164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7310339612565164\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7656322273497828, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7656322273497828\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09791751210195702, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09791751210195702\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1916031521921471, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1916031521921471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7310339612565164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7310339612565164\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7656322273497828, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7656322273497828\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09791751210195702, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09791751210195702\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1916031521921471, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1916031521921471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7310339612565164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7310339612565164\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7656322273497828, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7656322273497828\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09791751210195702, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09791751210195702\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1916031521921471, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1916031521921471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7310339612565164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7310339612565164\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7656322273497828, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7656322273497828\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09791751210195702, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09791751210195702\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1916031521921471, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1916031521921471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7310339612565164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7310339612565164\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7656322273497828, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7656322273497828\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09791751210195702, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09791751210195702\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1916031521921471, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1916031521921471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7310339612565164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7310339612565164\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7656322273497828, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7656322273497828\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09791751210195702, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09791751210195702\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1916031521921471, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1916031521921471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7310339612565164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7310339612565164\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7656322273497828, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7656322273497828\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09791751210195702, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09791751210195702\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1916031521921471, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1916031521921471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7310339612565164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7310339612565164\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7656322273497828, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7656322273497828\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09791751210195702, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09791751210195702\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1916031521921471, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1916031521921471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7310339612565164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7310339612565164\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:01:32,157] Trial 0 finished with value: 0.8777718365690105 and parameters: {'learning_rate': 0.19037369000716725, 'num_leaves': 34, 'max_depth': 11, 'min_data_in_leaf': 23, 'lambda_l1': 0.09791751210195702, 'lambda_l2': 0.1916031521921471, 'feature_fraction': 0.7656322273497828, 'bagging_fraction': 0.7310339612565164, 'bagging_freq': 4}. Best is trial 0 with value: 0.8777718365690105.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8639695051298668, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8639695051298668\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11717130413439153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11717130413439153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16596141298551167, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16596141298551167\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7400040004004849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7400040004004849\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8639695051298668, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8639695051298668\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11717130413439153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11717130413439153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16596141298551167, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16596141298551167\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7400040004004849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7400040004004849\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8639695051298668, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8639695051298668\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11717130413439153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11717130413439153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16596141298551167, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16596141298551167\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7400040004004849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7400040004004849\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8639695051298668, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8639695051298668\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11717130413439153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11717130413439153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16596141298551167, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16596141298551167\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7400040004004849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7400040004004849\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8639695051298668, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8639695051298668\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11717130413439153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11717130413439153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16596141298551167, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16596141298551167\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7400040004004849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7400040004004849\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8639695051298668, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8639695051298668\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11717130413439153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11717130413439153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16596141298551167, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16596141298551167\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7400040004004849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7400040004004849\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041299 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8639695051298668, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8639695051298668\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11717130413439153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11717130413439153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16596141298551167, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16596141298551167\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7400040004004849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7400040004004849\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8639695051298668, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8639695051298668\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11717130413439153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11717130413439153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16596141298551167, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16596141298551167\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7400040004004849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7400040004004849\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8639695051298668, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8639695051298668\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11717130413439153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11717130413439153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16596141298551167, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16596141298551167\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7400040004004849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7400040004004849\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8639695051298668, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8639695051298668\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11717130413439153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11717130413439153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16596141298551167, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16596141298551167\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7400040004004849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7400040004004849\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8639695051298668, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8639695051298668\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11717130413439153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11717130413439153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16596141298551167, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16596141298551167\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7400040004004849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7400040004004849\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8639695051298668, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8639695051298668\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11717130413439153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11717130413439153\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16596141298551167, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16596141298551167\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7400040004004849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7400040004004849\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:03:22,066] Trial 1 finished with value: 0.8776594053091861 and parameters: {'learning_rate': 0.20148767668751832, 'num_leaves': 32, 'max_depth': 10, 'min_data_in_leaf': 16, 'lambda_l1': 0.11717130413439153, 'lambda_l2': 0.16596141298551167, 'feature_fraction': 0.8639695051298668, 'bagging_fraction': 0.7400040004004849, 'bagging_freq': 5}. Best is trial 0 with value: 0.8777718365690105.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7685953918237244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7685953918237244\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10922822154098472, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10922822154098472\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2385388214838187, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2385388214838187\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7408610823096882, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7408610823096882\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7685953918237244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7685953918237244\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10922822154098472, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10922822154098472\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2385388214838187, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2385388214838187\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7408610823096882, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7408610823096882\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7685953918237244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7685953918237244\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10922822154098472, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10922822154098472\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2385388214838187, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2385388214838187\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7408610823096882, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7408610823096882\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7685953918237244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7685953918237244\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10922822154098472, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10922822154098472\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2385388214838187, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2385388214838187\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7408610823096882, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7408610823096882\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7685953918237244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7685953918237244\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10922822154098472, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10922822154098472\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2385388214838187, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2385388214838187\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7408610823096882, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7408610823096882\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7685953918237244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7685953918237244\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10922822154098472, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10922822154098472\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2385388214838187, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2385388214838187\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7408610823096882, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7408610823096882\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7685953918237244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7685953918237244\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10922822154098472, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10922822154098472\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2385388214838187, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2385388214838187\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7408610823096882, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7408610823096882\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7685953918237244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7685953918237244\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10922822154098472, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10922822154098472\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2385388214838187, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2385388214838187\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7408610823096882, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7408610823096882\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7685953918237244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7685953918237244\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10922822154098472, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10922822154098472\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2385388214838187, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2385388214838187\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7408610823096882, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7408610823096882\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7685953918237244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7685953918237244\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10922822154098472, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10922822154098472\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2385388214838187, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2385388214838187\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7408610823096882, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7408610823096882\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7685953918237244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7685953918237244\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10922822154098472, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10922822154098472\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2385388214838187, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2385388214838187\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7408610823096882, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7408610823096882\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7685953918237244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7685953918237244\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10922822154098472, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10922822154098472\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2385388214838187, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2385388214838187\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7408610823096882, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7408610823096882\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:05:14,473] Trial 2 finished with value: 0.8782478627641334 and parameters: {'learning_rate': 0.23318311750377654, 'num_leaves': 35, 'max_depth': 12, 'min_data_in_leaf': 18, 'lambda_l1': 0.10922822154098472, 'lambda_l2': 0.2385388214838187, 'feature_fraction': 0.7685953918237244, 'bagging_fraction': 0.7408610823096882, 'bagging_freq': 4}. Best is trial 2 with value: 0.8782478627641334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7300191256149601, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7300191256149601\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11844514073809911, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11844514073809911\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17315331715590176, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17315331715590176\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777245586164885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777245586164885\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7300191256149601, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7300191256149601\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11844514073809911, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11844514073809911\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17315331715590176, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17315331715590176\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777245586164885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777245586164885\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7300191256149601, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7300191256149601\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11844514073809911, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11844514073809911\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17315331715590176, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17315331715590176\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777245586164885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777245586164885\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7300191256149601, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7300191256149601\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11844514073809911, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11844514073809911\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17315331715590176, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17315331715590176\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777245586164885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777245586164885\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7300191256149601, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7300191256149601\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11844514073809911, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11844514073809911\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17315331715590176, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17315331715590176\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777245586164885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777245586164885\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7300191256149601, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7300191256149601\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11844514073809911, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11844514073809911\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17315331715590176, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17315331715590176\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777245586164885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777245586164885\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7300191256149601, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7300191256149601\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11844514073809911, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11844514073809911\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17315331715590176, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17315331715590176\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777245586164885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777245586164885\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7300191256149601, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7300191256149601\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11844514073809911, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11844514073809911\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17315331715590176, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17315331715590176\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777245586164885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777245586164885\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7300191256149601, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7300191256149601\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11844514073809911, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11844514073809911\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17315331715590176, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17315331715590176\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777245586164885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777245586164885\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7300191256149601, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7300191256149601\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11844514073809911, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11844514073809911\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17315331715590176, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17315331715590176\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777245586164885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777245586164885\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7300191256149601, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7300191256149601\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11844514073809911, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11844514073809911\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17315331715590176, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17315331715590176\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777245586164885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777245586164885\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7300191256149601, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7300191256149601\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11844514073809911, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11844514073809911\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17315331715590176, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17315331715590176\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777245586164885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777245586164885\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:07:07,207] Trial 3 finished with value: 0.8775180115992698 and parameters: {'learning_rate': 0.2261499512675778, 'num_leaves': 25, 'max_depth': 9, 'min_data_in_leaf': 22, 'lambda_l1': 0.11844514073809911, 'lambda_l2': 0.17315331715590176, 'feature_fraction': 0.7300191256149601, 'bagging_fraction': 0.777245586164885, 'bagging_freq': 4}. Best is trial 2 with value: 0.8782478627641334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] feature_fraction is set=0.785790677132777, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.785790677132777\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10800842115705882, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10800842115705882\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20847702829967016, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20847702829967016\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9551736319950537, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9551736319950537\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] feature_fraction is set=0.785790677132777, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.785790677132777\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10800842115705882, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10800842115705882\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20847702829967016, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20847702829967016\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9551736319950537, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9551736319950537\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] feature_fraction is set=0.785790677132777, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.785790677132777\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10800842115705882, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10800842115705882\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20847702829967016, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20847702829967016\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9551736319950537, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9551736319950537\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] feature_fraction is set=0.785790677132777, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.785790677132777\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10800842115705882, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10800842115705882\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20847702829967016, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20847702829967016\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9551736319950537, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9551736319950537\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] feature_fraction is set=0.785790677132777, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.785790677132777\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10800842115705882, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10800842115705882\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20847702829967016, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20847702829967016\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9551736319950537, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9551736319950537\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] feature_fraction is set=0.785790677132777, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.785790677132777\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10800842115705882, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10800842115705882\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20847702829967016, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20847702829967016\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9551736319950537, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9551736319950537\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] feature_fraction is set=0.785790677132777, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.785790677132777\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10800842115705882, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10800842115705882\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20847702829967016, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20847702829967016\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9551736319950537, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9551736319950537\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] feature_fraction is set=0.785790677132777, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.785790677132777\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10800842115705882, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10800842115705882\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20847702829967016, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20847702829967016\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9551736319950537, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9551736319950537\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] feature_fraction is set=0.785790677132777, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.785790677132777\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10800842115705882, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10800842115705882\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20847702829967016, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20847702829967016\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9551736319950537, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9551736319950537\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] feature_fraction is set=0.785790677132777, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.785790677132777\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10800842115705882, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10800842115705882\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20847702829967016, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20847702829967016\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9551736319950537, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9551736319950537\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] feature_fraction is set=0.785790677132777, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.785790677132777\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10800842115705882, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10800842115705882\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20847702829967016, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20847702829967016\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9551736319950537, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9551736319950537\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] feature_fraction is set=0.785790677132777, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.785790677132777\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10800842115705882, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10800842115705882\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20847702829967016, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20847702829967016\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9551736319950537, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9551736319950537\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:09:03,944] Trial 4 finished with value: 0.8776086562037705 and parameters: {'learning_rate': 0.22074904991171196, 'num_leaves': 26, 'max_depth': 11, 'min_data_in_leaf': 24, 'lambda_l1': 0.10800842115705882, 'lambda_l2': 0.20847702829967016, 'feature_fraction': 0.785790677132777, 'bagging_fraction': 0.9551736319950537, 'bagging_freq': 4}. Best is trial 2 with value: 0.8782478627641334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9774578900238102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9774578900238102\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08963363270778607, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08963363270778607\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17361217528691048, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17361217528691048\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8313095549087433, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8313095549087433\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9774578900238102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9774578900238102\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08963363270778607, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08963363270778607\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17361217528691048, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17361217528691048\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8313095549087433, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8313095549087433\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041795 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9774578900238102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9774578900238102\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08963363270778607, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08963363270778607\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17361217528691048, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17361217528691048\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8313095549087433, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8313095549087433\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9774578900238102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9774578900238102\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08963363270778607, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08963363270778607\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17361217528691048, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17361217528691048\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8313095549087433, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8313095549087433\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9774578900238102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9774578900238102\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08963363270778607, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08963363270778607\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17361217528691048, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17361217528691048\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8313095549087433, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8313095549087433\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9774578900238102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9774578900238102\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08963363270778607, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08963363270778607\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17361217528691048, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17361217528691048\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8313095549087433, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8313095549087433\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9774578900238102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9774578900238102\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08963363270778607, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08963363270778607\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17361217528691048, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17361217528691048\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8313095549087433, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8313095549087433\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9774578900238102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9774578900238102\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08963363270778607, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08963363270778607\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17361217528691048, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17361217528691048\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8313095549087433, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8313095549087433\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9774578900238102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9774578900238102\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08963363270778607, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08963363270778607\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17361217528691048, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17361217528691048\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8313095549087433, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8313095549087433\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9774578900238102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9774578900238102\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08963363270778607, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08963363270778607\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17361217528691048, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17361217528691048\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8313095549087433, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8313095549087433\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9774578900238102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9774578900238102\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08963363270778607, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08963363270778607\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17361217528691048, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17361217528691048\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8313095549087433, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8313095549087433\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9774578900238102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9774578900238102\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08963363270778607, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08963363270778607\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17361217528691048, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17361217528691048\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8313095549087433, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8313095549087433\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:10:56,331] Trial 5 finished with value: 0.877610455571582 and parameters: {'learning_rate': 0.2372129568861148, 'num_leaves': 25, 'max_depth': 11, 'min_data_in_leaf': 23, 'lambda_l1': 0.08963363270778607, 'lambda_l2': 0.17361217528691048, 'feature_fraction': 0.9774578900238102, 'bagging_fraction': 0.8313095549087433, 'bagging_freq': 5}. Best is trial 2 with value: 0.8782478627641334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9330792268441346, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9330792268441346\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11238994677342737, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11238994677342737\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23688213109969156, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23688213109969156\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8003554075566943, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8003554075566943\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9330792268441346, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9330792268441346\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11238994677342737, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11238994677342737\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23688213109969156, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23688213109969156\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8003554075566943, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8003554075566943\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9330792268441346, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9330792268441346\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11238994677342737, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11238994677342737\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23688213109969156, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23688213109969156\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8003554075566943, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8003554075566943\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9330792268441346, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9330792268441346\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11238994677342737, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11238994677342737\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23688213109969156, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23688213109969156\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8003554075566943, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8003554075566943\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9330792268441346, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9330792268441346\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11238994677342737, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11238994677342737\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23688213109969156, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23688213109969156\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8003554075566943, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8003554075566943\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9330792268441346, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9330792268441346\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11238994677342737, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11238994677342737\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23688213109969156, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23688213109969156\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8003554075566943, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8003554075566943\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9330792268441346, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9330792268441346\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11238994677342737, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11238994677342737\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23688213109969156, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23688213109969156\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8003554075566943, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8003554075566943\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9330792268441346, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9330792268441346\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11238994677342737, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11238994677342737\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23688213109969156, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23688213109969156\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8003554075566943, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8003554075566943\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9330792268441346, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9330792268441346\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11238994677342737, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11238994677342737\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23688213109969156, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23688213109969156\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8003554075566943, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8003554075566943\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9330792268441346, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9330792268441346\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11238994677342737, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11238994677342737\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23688213109969156, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23688213109969156\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8003554075566943, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8003554075566943\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9330792268441346, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9330792268441346\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11238994677342737, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11238994677342737\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23688213109969156, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23688213109969156\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8003554075566943, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8003554075566943\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9330792268441346, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9330792268441346\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11238994677342737, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11238994677342737\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23688213109969156, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23688213109969156\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8003554075566943, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8003554075566943\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:12:49,626] Trial 6 finished with value: 0.8776980621335048 and parameters: {'learning_rate': 0.22593206658038406, 'num_leaves': 27, 'max_depth': 10, 'min_data_in_leaf': 22, 'lambda_l1': 0.11238994677342737, 'lambda_l2': 0.23688213109969156, 'feature_fraction': 0.9330792268441346, 'bagging_fraction': 0.8003554075566943, 'bagging_freq': 6}. Best is trial 2 with value: 0.8782478627641334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7717133644809554, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7717133644809554\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09643711138128533, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09643711138128533\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17976256048385245, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17976256048385245\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7901063191414396, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901063191414396\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7717133644809554, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7717133644809554\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09643711138128533, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09643711138128533\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17976256048385245, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17976256048385245\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7901063191414396, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901063191414396\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7717133644809554, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7717133644809554\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09643711138128533, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09643711138128533\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17976256048385245, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17976256048385245\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7901063191414396, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901063191414396\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7717133644809554, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7717133644809554\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09643711138128533, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09643711138128533\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17976256048385245, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17976256048385245\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7901063191414396, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901063191414396\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7717133644809554, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7717133644809554\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09643711138128533, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09643711138128533\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17976256048385245, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17976256048385245\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7901063191414396, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901063191414396\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7717133644809554, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7717133644809554\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09643711138128533, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09643711138128533\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17976256048385245, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17976256048385245\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7901063191414396, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901063191414396\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7717133644809554, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7717133644809554\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09643711138128533, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09643711138128533\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17976256048385245, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17976256048385245\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7901063191414396, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901063191414396\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7717133644809554, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7717133644809554\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09643711138128533, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09643711138128533\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17976256048385245, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17976256048385245\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7901063191414396, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901063191414396\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7717133644809554, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7717133644809554\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09643711138128533, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09643711138128533\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17976256048385245, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17976256048385245\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7901063191414396, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901063191414396\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7717133644809554, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7717133644809554\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09643711138128533, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09643711138128533\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17976256048385245, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17976256048385245\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7901063191414396, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901063191414396\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7717133644809554, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7717133644809554\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09643711138128533, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09643711138128533\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17976256048385245, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17976256048385245\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7901063191414396, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901063191414396\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7717133644809554, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7717133644809554\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09643711138128533, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09643711138128533\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17976256048385245, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17976256048385245\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7901063191414396, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901063191414396\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:14:42,787] Trial 7 finished with value: 0.8775265279394525 and parameters: {'learning_rate': 0.2059578888023098, 'num_leaves': 28, 'max_depth': 9, 'min_data_in_leaf': 16, 'lambda_l1': 0.09643711138128533, 'lambda_l2': 0.17976256048385245, 'feature_fraction': 0.7717133644809554, 'bagging_fraction': 0.7901063191414396, 'bagging_freq': 5}. Best is trial 2 with value: 0.8782478627641334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7853467005077279, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7853467005077279\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10109786553533043, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10109786553533043\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21364971223612833, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21364971223612833\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8084186818418122, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8084186818418122\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7853467005077279, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7853467005077279\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10109786553533043, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10109786553533043\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21364971223612833, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21364971223612833\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8084186818418122, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8084186818418122\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7853467005077279, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7853467005077279\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10109786553533043, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10109786553533043\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21364971223612833, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21364971223612833\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8084186818418122, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8084186818418122\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7853467005077279, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7853467005077279\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10109786553533043, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10109786553533043\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21364971223612833, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21364971223612833\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8084186818418122, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8084186818418122\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7853467005077279, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7853467005077279\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10109786553533043, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10109786553533043\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21364971223612833, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21364971223612833\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8084186818418122, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8084186818418122\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7853467005077279, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7853467005077279\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10109786553533043, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10109786553533043\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21364971223612833, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21364971223612833\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8084186818418122, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8084186818418122\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7853467005077279, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7853467005077279\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10109786553533043, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10109786553533043\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21364971223612833, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21364971223612833\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8084186818418122, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8084186818418122\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7853467005077279, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7853467005077279\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10109786553533043, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10109786553533043\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21364971223612833, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21364971223612833\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8084186818418122, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8084186818418122\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7853467005077279, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7853467005077279\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10109786553533043, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10109786553533043\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21364971223612833, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21364971223612833\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8084186818418122, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8084186818418122\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7853467005077279, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7853467005077279\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10109786553533043, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10109786553533043\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21364971223612833, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21364971223612833\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8084186818418122, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8084186818418122\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7853467005077279, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7853467005077279\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10109786553533043, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10109786553533043\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21364971223612833, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21364971223612833\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8084186818418122, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8084186818418122\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7853467005077279, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7853467005077279\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10109786553533043, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10109786553533043\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21364971223612833, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21364971223612833\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8084186818418122, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8084186818418122\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:16:32,905] Trial 8 finished with value: 0.8777616734181278 and parameters: {'learning_rate': 0.25703462952794376, 'num_leaves': 24, 'max_depth': 9, 'min_data_in_leaf': 20, 'lambda_l1': 0.10109786553533043, 'lambda_l2': 0.21364971223612833, 'feature_fraction': 0.7853467005077279, 'bagging_fraction': 0.8084186818418122, 'bagging_freq': 6}. Best is trial 2 with value: 0.8782478627641334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7772184642221492, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7772184642221492\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08375668468639909, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08375668468639909\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21206863566073966, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21206863566073966\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6704257634987619, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6704257634987619\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7772184642221492, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7772184642221492\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08375668468639909, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08375668468639909\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21206863566073966, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21206863566073966\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6704257634987619, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6704257634987619\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034820 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7772184642221492, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7772184642221492\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08375668468639909, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08375668468639909\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21206863566073966, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21206863566073966\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6704257634987619, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6704257634987619\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7772184642221492, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7772184642221492\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08375668468639909, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08375668468639909\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21206863566073966, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21206863566073966\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6704257634987619, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6704257634987619\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7772184642221492, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7772184642221492\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08375668468639909, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08375668468639909\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21206863566073966, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21206863566073966\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6704257634987619, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6704257634987619\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7772184642221492, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7772184642221492\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08375668468639909, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08375668468639909\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21206863566073966, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21206863566073966\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6704257634987619, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6704257634987619\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7772184642221492, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7772184642221492\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08375668468639909, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08375668468639909\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21206863566073966, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21206863566073966\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6704257634987619, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6704257634987619\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7772184642221492, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7772184642221492\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08375668468639909, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08375668468639909\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21206863566073966, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21206863566073966\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6704257634987619, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6704257634987619\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7772184642221492, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7772184642221492\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08375668468639909, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08375668468639909\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21206863566073966, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21206863566073966\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6704257634987619, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6704257634987619\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7772184642221492, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7772184642221492\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08375668468639909, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08375668468639909\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21206863566073966, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21206863566073966\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6704257634987619, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6704257634987619\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033015 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7772184642221492, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7772184642221492\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08375668468639909, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08375668468639909\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21206863566073966, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21206863566073966\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6704257634987619, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6704257634987619\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7772184642221492, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7772184642221492\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08375668468639909, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08375668468639909\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21206863566073966, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21206863566073966\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6704257634987619, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6704257634987619\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:18:24,029] Trial 9 finished with value: 0.8781570402780029 and parameters: {'learning_rate': 0.2180742689052647, 'num_leaves': 37, 'max_depth': 10, 'min_data_in_leaf': 21, 'lambda_l1': 0.08375668468639909, 'lambda_l2': 0.21206863566073966, 'feature_fraction': 0.7772184642221492, 'bagging_fraction': 0.6704257634987619, 'bagging_freq': 6}. Best is trial 2 with value: 0.8782478627641334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7685953918237244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7685953918237244\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10922822154098472, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10922822154098472\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2385388214838187, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2385388214838187\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7408610823096882, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7408610823096882\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7685953918237244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7685953918237244\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10922822154098472, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10922822154098472\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2385388214838187, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2385388214838187\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7408610823096882, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7408610823096882\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 1132047, number of negative: 8071791\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 9203838, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7685953918237244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7685953918237244\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10922822154098472, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10922822154098472\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2385388214838187, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2385388214838187\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7408610823096882, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7408610823096882\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.878472\tvalid_0's binary_logloss: 0.25264\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7685953918237244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7685953918237244\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10922822154098472, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10922822154098472\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2385388214838187, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2385388214838187\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7408610823096882, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7408610823096882\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 1: Initial Search\n",
    "\n",
    "# Import Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import logging\n",
    "import optuna\n",
    "\n",
    "# Setting up the logger\n",
    "logging.basicConfig(level=logging.INFO, filename='lgb_initial_tuning.log', filemode='w',\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Create directories for storing graphs\n",
    "os.makedirs('graphs_lgb_incremental', exist_ok=True)\n",
    "\n",
    "# Load Data\n",
    "train_path = \"train_lgb_processed.csv\"\n",
    "test_path = \"test_lgb_processed.csv\"\n",
    "\n",
    "logger.info(\"Loading datasets...\")\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "logger.info(\"Datasets loaded successfully.\")\n",
    "logger.info(f\"Train dataset shape: {train_df.shape}\")\n",
    "logger.info(f\"Test dataset shape: {test_df.shape}\")\n",
    "\n",
    "\n",
    "# Split data into features and target\n",
    "X = train_df.drop('Response', axis=1)\n",
    "y = train_df['Response']\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Define the initial parameters for LightGBM\n",
    "initial_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.22787270164926926,\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': 10,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'lambda_l1': 0.1,\n",
    "    'lambda_l2': 0.2,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5\n",
    "}\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'learning_rate': trial.suggest_float('learning_rate', initial_params['learning_rate'] * 0.8, initial_params['learning_rate'] * 1.2),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', int(initial_params['num_leaves'] * 0.8), int(initial_params['num_leaves'] * 1.2)),\n",
    "        'max_depth': trial.suggest_int('max_depth', max(-1, int(initial_params['max_depth'] * 0.8)), max(3, int(initial_params['max_depth'] * 1.2))),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', int(initial_params['min_data_in_leaf'] * 0.8), int(initial_params['min_data_in_leaf'] * 1.2)),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', initial_params['lambda_l1'] * 0.8, initial_params['lambda_l1'] * 1.2),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', initial_params['lambda_l2'] * 0.8, initial_params['lambda_l2'] * 1.2),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', max(0.0, initial_params['feature_fraction'] * 0.8), min(1.0, initial_params['feature_fraction'] * 1.2)),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', max(0.0, initial_params['bagging_fraction'] * 0.8), min(1.0, initial_params['bagging_fraction'] * 1.2)),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', int(initial_params['bagging_freq'] * 0.8), int(initial_params['bagging_freq'] * 1.2))\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    cv_scores = []\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_t, X_v = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_t, y_v = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(X_t, y_t, eval_set=[(X_v, y_v)], callbacks=[lgb.early_stopping(stopping_rounds=10, verbose=False)], eval_metric='auc')\n",
    "\n",
    "        y_pred = model.predict_proba(X_v)[:, 1]\n",
    "        cv_scores.append(roc_auc_score(y_v, y_pred))\n",
    "\n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "# Set up Optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "logger.info(f\"Best parameters from initial search: {best_params}\")\n",
    "logger.info(f\"Best ROC AUC score from initial search: {study.best_value}\")\n",
    "\n",
    "# Save results\n",
    "results_df = study.trials_dataframe()\n",
    "results_df.to_csv('lgb_initial_search_results.csv', index=False)\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "final_model = lgb.LGBMClassifier(**best_params)\n",
    "final_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=[lgb.early_stopping(stopping_rounds=10, verbose=True)], eval_metric='auc')\n",
    "\n",
    "# Evaluate model performance on validation set\n",
    "y_pred_val = final_model.predict_proba(X_val)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_val)\n",
    "logger.info(f\"Validation ROC AUC Score with best parameters: {roc_auc}\")\n",
    "\n",
    "# Save final model\n",
    "final_model.booster_.save_model('final_lgb_model_initial.txt')\n",
    "logger.info('Final model saved to final_lgb_model_initial.txt')\n",
    "\n",
    "# Plot feature importances\n",
    "lgb.plot_importance(final_model, max_num_features=10)\n",
    "plt.title('LightGBM Feature Importances')\n",
    "plt.savefig('graphs_lgb_incremental/lgb_feature_importances_initial.png')\n",
    "plt.show()\n",
    "logger.info('LightGBM feature importances plot saved.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:19:03,732] A new study created in memory with name: no-name-d6c99feb-e7b8-4398-9c33-7aab0558390b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6327410160608012, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6327410160608012\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09007154716275827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09007154716275827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2161241379792734, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2161241379792734\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8401703722550189, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8401703722550189\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6327410160608012, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6327410160608012\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09007154716275827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09007154716275827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2161241379792734, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2161241379792734\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8401703722550189, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8401703722550189\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029034 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6327410160608012, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6327410160608012\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09007154716275827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09007154716275827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2161241379792734, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2161241379792734\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8401703722550189, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8401703722550189\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6327410160608012, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6327410160608012\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09007154716275827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09007154716275827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2161241379792734, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2161241379792734\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8401703722550189, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8401703722550189\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6327410160608012, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6327410160608012\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09007154716275827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09007154716275827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2161241379792734, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2161241379792734\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8401703722550189, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8401703722550189\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6327410160608012, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6327410160608012\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09007154716275827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09007154716275827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2161241379792734, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2161241379792734\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8401703722550189, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8401703722550189\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6327410160608012, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6327410160608012\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09007154716275827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09007154716275827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2161241379792734, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2161241379792734\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8401703722550189, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8401703722550189\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6327410160608012, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6327410160608012\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09007154716275827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09007154716275827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2161241379792734, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2161241379792734\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8401703722550189, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8401703722550189\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6327410160608012, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6327410160608012\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09007154716275827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09007154716275827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2161241379792734, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2161241379792734\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8401703722550189, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8401703722550189\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6327410160608012, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6327410160608012\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09007154716275827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09007154716275827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2161241379792734, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2161241379792734\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8401703722550189, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8401703722550189\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6327410160608012, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6327410160608012\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09007154716275827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09007154716275827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2161241379792734, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2161241379792734\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8401703722550189, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8401703722550189\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6327410160608012, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6327410160608012\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09007154716275827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09007154716275827\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2161241379792734, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2161241379792734\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8401703722550189, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8401703722550189\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:21:10,181] Trial 0 finished with value: 0.8785276544531014 and parameters: {'learning_rate': 0.22776532549698056, 'num_leaves': 42, 'max_depth': 11, 'min_data_in_leaf': 21, 'lambda_l1': 0.09007154716275827, 'lambda_l2': 0.2161241379792734, 'feature_fraction': 0.6327410160608012, 'bagging_fraction': 0.8401703722550189, 'bagging_freq': 4}. Best is trial 0 with value: 0.8785276544531014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8977616615686046, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8977616615686046\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09064445991689024, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09064445991689024\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23357746719162265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23357746719162265\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7328134153571617, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7328134153571617\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8977616615686046, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8977616615686046\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09064445991689024, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09064445991689024\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23357746719162265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23357746719162265\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7328134153571617, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7328134153571617\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8977616615686046, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8977616615686046\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09064445991689024, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09064445991689024\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23357746719162265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23357746719162265\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7328134153571617, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7328134153571617\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8977616615686046, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8977616615686046\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09064445991689024, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09064445991689024\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23357746719162265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23357746719162265\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7328134153571617, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7328134153571617\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8977616615686046, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8977616615686046\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09064445991689024, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09064445991689024\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23357746719162265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23357746719162265\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7328134153571617, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7328134153571617\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8977616615686046, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8977616615686046\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09064445991689024, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09064445991689024\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23357746719162265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23357746719162265\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7328134153571617, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7328134153571617\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8977616615686046, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8977616615686046\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09064445991689024, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09064445991689024\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23357746719162265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23357746719162265\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7328134153571617, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7328134153571617\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8977616615686046, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8977616615686046\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09064445991689024, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09064445991689024\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23357746719162265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23357746719162265\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7328134153571617, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7328134153571617\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8977616615686046, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8977616615686046\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09064445991689024, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09064445991689024\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23357746719162265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23357746719162265\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7328134153571617, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7328134153571617\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8977616615686046, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8977616615686046\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09064445991689024, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09064445991689024\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23357746719162265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23357746719162265\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7328134153571617, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7328134153571617\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8977616615686046, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8977616615686046\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09064445991689024, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09064445991689024\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23357746719162265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23357746719162265\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7328134153571617, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7328134153571617\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8977616615686046, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8977616615686046\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09064445991689024, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09064445991689024\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23357746719162265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23357746719162265\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7328134153571617, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7328134153571617\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:23:03,434] Trial 1 finished with value: 0.878314489469974 and parameters: {'learning_rate': 0.23875883128399322, 'num_leaves': 36, 'max_depth': 14, 'min_data_in_leaf': 21, 'lambda_l1': 0.09064445991689024, 'lambda_l2': 0.23357746719162265, 'feature_fraction': 0.8977616615686046, 'bagging_fraction': 0.7328134153571617, 'bagging_freq': 3}. Best is trial 0 with value: 0.8785276544531014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6821270773446028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6821270773446028\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10666593570668091, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10666593570668091\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2084099059670722, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2084099059670722\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8707908374096319, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8707908374096319\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6821270773446028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6821270773446028\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10666593570668091, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10666593570668091\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2084099059670722, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2084099059670722\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8707908374096319, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8707908374096319\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044874 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6821270773446028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6821270773446028\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10666593570668091, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10666593570668091\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2084099059670722, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2084099059670722\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8707908374096319, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8707908374096319\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6821270773446028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6821270773446028\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10666593570668091, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10666593570668091\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2084099059670722, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2084099059670722\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8707908374096319, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8707908374096319\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6821270773446028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6821270773446028\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10666593570668091, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10666593570668091\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2084099059670722, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2084099059670722\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8707908374096319, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8707908374096319\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6821270773446028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6821270773446028\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10666593570668091, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10666593570668091\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2084099059670722, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2084099059670722\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8707908374096319, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8707908374096319\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032797 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6821270773446028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6821270773446028\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10666593570668091, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10666593570668091\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2084099059670722, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2084099059670722\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8707908374096319, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8707908374096319\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6821270773446028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6821270773446028\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10666593570668091, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10666593570668091\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2084099059670722, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2084099059670722\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8707908374096319, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8707908374096319\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6821270773446028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6821270773446028\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10666593570668091, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10666593570668091\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2084099059670722, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2084099059670722\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8707908374096319, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8707908374096319\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6821270773446028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6821270773446028\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10666593570668091, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10666593570668091\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2084099059670722, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2084099059670722\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8707908374096319, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8707908374096319\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6821270773446028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6821270773446028\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10666593570668091, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10666593570668091\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2084099059670722, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2084099059670722\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8707908374096319, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8707908374096319\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6821270773446028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6821270773446028\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10666593570668091, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10666593570668091\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2084099059670722, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2084099059670722\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8707908374096319, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8707908374096319\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:25:01,124] Trial 2 finished with value: 0.8785655569355572 and parameters: {'learning_rate': 0.2611874029262021, 'num_leaves': 42, 'max_depth': 10, 'min_data_in_leaf': 19, 'lambda_l1': 0.10666593570668091, 'lambda_l2': 0.2084099059670722, 'feature_fraction': 0.6821270773446028, 'bagging_fraction': 0.8707908374096319, 'bagging_freq': 4}. Best is trial 2 with value: 0.8785655569355572.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6946517264701674, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6946517264701674\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12600802528933347, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12600802528933347\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2412483257461979, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2412483257461979\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5999575217157707, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5999575217157707\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6946517264701674, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6946517264701674\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12600802528933347, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12600802528933347\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2412483257461979, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2412483257461979\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5999575217157707, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5999575217157707\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6946517264701674, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6946517264701674\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12600802528933347, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12600802528933347\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2412483257461979, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2412483257461979\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5999575217157707, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5999575217157707\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6946517264701674, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6946517264701674\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12600802528933347, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12600802528933347\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2412483257461979, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2412483257461979\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5999575217157707, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5999575217157707\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6946517264701674, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6946517264701674\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12600802528933347, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12600802528933347\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2412483257461979, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2412483257461979\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5999575217157707, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5999575217157707\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6946517264701674, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6946517264701674\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12600802528933347, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12600802528933347\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2412483257461979, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2412483257461979\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5999575217157707, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5999575217157707\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6946517264701674, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6946517264701674\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12600802528933347, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12600802528933347\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2412483257461979, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2412483257461979\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5999575217157707, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5999575217157707\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6946517264701674, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6946517264701674\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12600802528933347, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12600802528933347\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2412483257461979, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2412483257461979\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5999575217157707, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5999575217157707\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6946517264701674, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6946517264701674\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12600802528933347, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12600802528933347\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2412483257461979, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2412483257461979\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5999575217157707, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5999575217157707\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6946517264701674, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6946517264701674\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12600802528933347, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12600802528933347\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2412483257461979, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2412483257461979\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5999575217157707, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5999575217157707\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6946517264701674, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6946517264701674\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12600802528933347, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12600802528933347\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2412483257461979, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2412483257461979\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5999575217157707, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5999575217157707\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6946517264701674, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6946517264701674\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12600802528933347, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12600802528933347\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2412483257461979, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2412483257461979\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5999575217157707, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5999575217157707\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:26:51,776] Trial 3 finished with value: 0.8780722872085177 and parameters: {'learning_rate': 0.20782774611586147, 'num_leaves': 36, 'max_depth': 11, 'min_data_in_leaf': 16, 'lambda_l1': 0.12600802528933347, 'lambda_l2': 0.2412483257461979, 'feature_fraction': 0.6946517264701674, 'bagging_fraction': 0.5999575217157707, 'bagging_freq': 4}. Best is trial 2 with value: 0.8785655569355572.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6650183824282834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6650183824282834\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10436037671469765, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10436037671469765\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.28199468465048216, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.28199468465048216\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8323050319515766, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8323050319515766\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6650183824282834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6650183824282834\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10436037671469765, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10436037671469765\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.28199468465048216, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.28199468465048216\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8323050319515766, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8323050319515766\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6650183824282834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6650183824282834\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10436037671469765, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10436037671469765\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.28199468465048216, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.28199468465048216\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8323050319515766, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8323050319515766\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6650183824282834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6650183824282834\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10436037671469765, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10436037671469765\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.28199468465048216, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.28199468465048216\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8323050319515766, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8323050319515766\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6650183824282834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6650183824282834\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10436037671469765, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10436037671469765\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.28199468465048216, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.28199468465048216\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8323050319515766, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8323050319515766\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6650183824282834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6650183824282834\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10436037671469765, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10436037671469765\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.28199468465048216, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.28199468465048216\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8323050319515766, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8323050319515766\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6650183824282834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6650183824282834\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10436037671469765, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10436037671469765\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.28199468465048216, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.28199468465048216\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8323050319515766, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8323050319515766\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6650183824282834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6650183824282834\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10436037671469765, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10436037671469765\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.28199468465048216, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.28199468465048216\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8323050319515766, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8323050319515766\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6650183824282834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6650183824282834\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10436037671469765, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10436037671469765\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.28199468465048216, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.28199468465048216\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8323050319515766, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8323050319515766\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6650183824282834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6650183824282834\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10436037671469765, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10436037671469765\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.28199468465048216, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.28199468465048216\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8323050319515766, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8323050319515766\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031605 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6650183824282834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6650183824282834\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10436037671469765, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10436037671469765\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.28199468465048216, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.28199468465048216\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8323050319515766, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8323050319515766\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6650183824282834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6650183824282834\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10436037671469765, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10436037671469765\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.28199468465048216, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.28199468465048216\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8323050319515766, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8323050319515766\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:28:50,559] Trial 4 finished with value: 0.8782705625642407 and parameters: {'learning_rate': 0.21970513303014713, 'num_leaves': 38, 'max_depth': 10, 'min_data_in_leaf': 19, 'lambda_l1': 0.10436037671469765, 'lambda_l2': 0.28199468465048216, 'feature_fraction': 0.6650183824282834, 'bagging_fraction': 0.8323050319515766, 'bagging_freq': 3}. Best is trial 2 with value: 0.8785655569355572.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8254680058271393, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8254680058271393\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.111620219801997, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.111620219801997\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24020653505551243, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24020653505551243\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6780640733397229, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6780640733397229\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8254680058271393, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8254680058271393\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.111620219801997, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.111620219801997\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24020653505551243, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24020653505551243\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6780640733397229, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6780640733397229\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034140 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8254680058271393, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8254680058271393\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.111620219801997, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.111620219801997\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24020653505551243, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24020653505551243\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6780640733397229, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6780640733397229\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8254680058271393, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8254680058271393\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.111620219801997, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.111620219801997\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24020653505551243, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24020653505551243\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6780640733397229, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6780640733397229\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8254680058271393, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8254680058271393\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.111620219801997, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.111620219801997\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24020653505551243, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24020653505551243\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6780640733397229, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6780640733397229\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8254680058271393, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8254680058271393\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.111620219801997, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.111620219801997\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24020653505551243, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24020653505551243\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6780640733397229, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6780640733397229\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8254680058271393, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8254680058271393\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.111620219801997, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.111620219801997\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24020653505551243, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24020653505551243\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6780640733397229, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6780640733397229\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8254680058271393, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8254680058271393\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.111620219801997, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.111620219801997\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24020653505551243, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24020653505551243\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6780640733397229, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6780640733397229\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8254680058271393, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8254680058271393\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.111620219801997, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.111620219801997\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24020653505551243, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24020653505551243\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6780640733397229, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6780640733397229\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8254680058271393, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8254680058271393\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.111620219801997, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.111620219801997\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24020653505551243, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24020653505551243\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6780640733397229, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6780640733397229\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032801 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8254680058271393, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8254680058271393\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.111620219801997, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.111620219801997\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24020653505551243, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24020653505551243\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6780640733397229, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6780640733397229\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8254680058271393, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8254680058271393\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.111620219801997, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.111620219801997\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24020653505551243, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24020653505551243\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6780640733397229, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6780640733397229\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:30:39,759] Trial 5 finished with value: 0.8781728809889526 and parameters: {'learning_rate': 0.2571770577884993, 'num_leaves': 30, 'max_depth': 12, 'min_data_in_leaf': 19, 'lambda_l1': 0.111620219801997, 'lambda_l2': 0.24020653505551243, 'feature_fraction': 0.8254680058271393, 'bagging_fraction': 0.6780640733397229, 'bagging_freq': 3}. Best is trial 2 with value: 0.8785655569355572.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6923916916518184, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6923916916518184\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11968651517638984, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11968651517638984\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2706569257629467, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2706569257629467\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7155042575247995, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7155042575247995\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6923916916518184, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6923916916518184\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11968651517638984, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11968651517638984\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2706569257629467, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2706569257629467\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7155042575247995, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7155042575247995\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032313 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6923916916518184, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6923916916518184\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11968651517638984, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11968651517638984\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2706569257629467, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2706569257629467\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7155042575247995, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7155042575247995\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6923916916518184, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6923916916518184\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11968651517638984, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11968651517638984\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2706569257629467, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2706569257629467\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7155042575247995, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7155042575247995\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6923916916518184, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6923916916518184\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11968651517638984, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11968651517638984\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2706569257629467, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2706569257629467\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7155042575247995, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7155042575247995\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6923916916518184, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6923916916518184\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11968651517638984, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11968651517638984\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2706569257629467, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2706569257629467\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7155042575247995, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7155042575247995\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6923916916518184, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6923916916518184\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11968651517638984, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11968651517638984\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2706569257629467, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2706569257629467\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7155042575247995, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7155042575247995\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6923916916518184, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6923916916518184\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11968651517638984, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11968651517638984\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2706569257629467, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2706569257629467\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7155042575247995, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7155042575247995\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6923916916518184, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6923916916518184\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11968651517638984, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11968651517638984\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2706569257629467, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2706569257629467\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7155042575247995, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7155042575247995\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6923916916518184, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6923916916518184\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11968651517638984, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11968651517638984\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2706569257629467, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2706569257629467\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7155042575247995, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7155042575247995\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6923916916518184, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6923916916518184\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11968651517638984, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11968651517638984\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2706569257629467, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2706569257629467\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7155042575247995, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7155042575247995\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6923916916518184, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6923916916518184\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11968651517638984, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11968651517638984\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2706569257629467, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2706569257629467\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7155042575247995, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7155042575247995\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:32:34,459] Trial 6 finished with value: 0.8783086256136383 and parameters: {'learning_rate': 0.25221731309325873, 'num_leaves': 35, 'max_depth': 12, 'min_data_in_leaf': 18, 'lambda_l1': 0.11968651517638984, 'lambda_l2': 0.2706569257629467, 'feature_fraction': 0.6923916916518184, 'bagging_fraction': 0.7155042575247995, 'bagging_freq': 3}. Best is trial 2 with value: 0.8785655569355572.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7519898286796551, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7519898286796551\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09170489310109028, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09170489310109028\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22710583682510077, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22710583682510077\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7712158605262835, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7712158605262835\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7519898286796551, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7519898286796551\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09170489310109028, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09170489310109028\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22710583682510077, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22710583682510077\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7712158605262835, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7712158605262835\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031842 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7519898286796551, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7519898286796551\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09170489310109028, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09170489310109028\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22710583682510077, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22710583682510077\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7712158605262835, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7712158605262835\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7519898286796551, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7519898286796551\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09170489310109028, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09170489310109028\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22710583682510077, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22710583682510077\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7712158605262835, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7712158605262835\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7519898286796551, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7519898286796551\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09170489310109028, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09170489310109028\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22710583682510077, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22710583682510077\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7712158605262835, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7712158605262835\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7519898286796551, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7519898286796551\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09170489310109028, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09170489310109028\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22710583682510077, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22710583682510077\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7712158605262835, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7712158605262835\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031843 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7519898286796551, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7519898286796551\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09170489310109028, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09170489310109028\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22710583682510077, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22710583682510077\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7712158605262835, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7712158605262835\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7519898286796551, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7519898286796551\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09170489310109028, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09170489310109028\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22710583682510077, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22710583682510077\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7712158605262835, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7712158605262835\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7519898286796551, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7519898286796551\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09170489310109028, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09170489310109028\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22710583682510077, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22710583682510077\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7712158605262835, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7712158605262835\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7519898286796551, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7519898286796551\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09170489310109028, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09170489310109028\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22710583682510077, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22710583682510077\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7712158605262835, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7712158605262835\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033140 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7519898286796551, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7519898286796551\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09170489310109028, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09170489310109028\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22710583682510077, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22710583682510077\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7712158605262835, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7712158605262835\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7519898286796551, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7519898286796551\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09170489310109028, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09170489310109028\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22710583682510077, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22710583682510077\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7712158605262835, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7712158605262835\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:34:25,253] Trial 7 finished with value: 0.8780720210345719 and parameters: {'learning_rate': 0.2528798453961586, 'num_leaves': 29, 'max_depth': 12, 'min_data_in_leaf': 17, 'lambda_l1': 0.09170489310109028, 'lambda_l2': 0.22710583682510077, 'feature_fraction': 0.7519898286796551, 'bagging_fraction': 0.7712158605262835, 'bagging_freq': 3}. Best is trial 2 with value: 0.8785655569355572.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9014526722135849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9014526722135849\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12254260616677046, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12254260616677046\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23058336894956008, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23058336894956008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8673448576231353, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8673448576231353\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9014526722135849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9014526722135849\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12254260616677046, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12254260616677046\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23058336894956008, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23058336894956008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8673448576231353, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8673448576231353\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9014526722135849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9014526722135849\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12254260616677046, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12254260616677046\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23058336894956008, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23058336894956008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8673448576231353, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8673448576231353\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9014526722135849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9014526722135849\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12254260616677046, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12254260616677046\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23058336894956008, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23058336894956008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8673448576231353, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8673448576231353\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9014526722135849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9014526722135849\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12254260616677046, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12254260616677046\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23058336894956008, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23058336894956008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8673448576231353, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8673448576231353\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9014526722135849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9014526722135849\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12254260616677046, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12254260616677046\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23058336894956008, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23058336894956008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8673448576231353, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8673448576231353\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9014526722135849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9014526722135849\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12254260616677046, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12254260616677046\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23058336894956008, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23058336894956008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8673448576231353, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8673448576231353\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9014526722135849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9014526722135849\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12254260616677046, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12254260616677046\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23058336894956008, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23058336894956008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8673448576231353, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8673448576231353\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9014526722135849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9014526722135849\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12254260616677046, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12254260616677046\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23058336894956008, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23058336894956008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8673448576231353, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8673448576231353\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9014526722135849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9014526722135849\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12254260616677046, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12254260616677046\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23058336894956008, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23058336894956008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8673448576231353, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8673448576231353\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9014526722135849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9014526722135849\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12254260616677046, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12254260616677046\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23058336894956008, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23058336894956008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8673448576231353, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8673448576231353\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9014526722135849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9014526722135849\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12254260616677046, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12254260616677046\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23058336894956008, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23058336894956008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8673448576231353, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8673448576231353\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:36:16,478] Trial 8 finished with value: 0.87867603804991 and parameters: {'learning_rate': 0.26751271080960026, 'num_leaves': 38, 'max_depth': 11, 'min_data_in_leaf': 17, 'lambda_l1': 0.12254260616677046, 'lambda_l2': 0.23058336894956008, 'feature_fraction': 0.9014526722135849, 'bagging_fraction': 0.8673448576231353, 'bagging_freq': 4}. Best is trial 8 with value: 0.87867603804991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8861961684902746, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8861961684902746\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12993071021991565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12993071021991565\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24619129168955559, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24619129168955559\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6774162617434398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6774162617434398\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8861961684902746, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8861961684902746\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12993071021991565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12993071021991565\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24619129168955559, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24619129168955559\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6774162617434398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6774162617434398\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041997 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8861961684902746, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8861961684902746\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12993071021991565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12993071021991565\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24619129168955559, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24619129168955559\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6774162617434398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6774162617434398\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8861961684902746, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8861961684902746\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12993071021991565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12993071021991565\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24619129168955559, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24619129168955559\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6774162617434398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6774162617434398\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8861961684902746, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8861961684902746\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12993071021991565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12993071021991565\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24619129168955559, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24619129168955559\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6774162617434398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6774162617434398\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8861961684902746, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8861961684902746\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12993071021991565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12993071021991565\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24619129168955559, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24619129168955559\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6774162617434398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6774162617434398\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048504 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8861961684902746, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8861961684902746\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12993071021991565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12993071021991565\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24619129168955559, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24619129168955559\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6774162617434398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6774162617434398\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8861961684902746, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8861961684902746\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12993071021991565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12993071021991565\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24619129168955559, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24619129168955559\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6774162617434398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6774162617434398\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8861961684902746, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8861961684902746\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12993071021991565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12993071021991565\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24619129168955559, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24619129168955559\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6774162617434398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6774162617434398\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8861961684902746, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8861961684902746\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12993071021991565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12993071021991565\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24619129168955559, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24619129168955559\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6774162617434398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6774162617434398\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8861961684902746, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8861961684902746\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12993071021991565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12993071021991565\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24619129168955559, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24619129168955559\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6774162617434398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6774162617434398\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8861961684902746, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8861961684902746\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12993071021991565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12993071021991565\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24619129168955559, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24619129168955559\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6774162617434398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6774162617434398\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:37:59,965] Trial 9 finished with value: 0.878198270430614 and parameters: {'learning_rate': 0.27526000217668883, 'num_leaves': 28, 'max_depth': 9, 'min_data_in_leaf': 14, 'lambda_l1': 0.12993071021991565, 'lambda_l2': 0.24619129168955559, 'feature_fraction': 0.8861961684902746, 'bagging_fraction': 0.6774162617434398, 'bagging_freq': 4}. Best is trial 8 with value: 0.87867603804991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9014526722135849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9014526722135849\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12254260616677046, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12254260616677046\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23058336894956008, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23058336894956008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8673448576231353, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8673448576231353\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9014526722135849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9014526722135849\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12254260616677046, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12254260616677046\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23058336894956008, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23058336894956008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8673448576231353, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8673448576231353\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 1132047, number of negative: 8071791\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 9203838, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9014526722135849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9014526722135849\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12254260616677046, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12254260616677046\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23058336894956008, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23058336894956008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8673448576231353, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8673448576231353\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.878896\tvalid_0's binary_logloss: 0.252329\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9014526722135849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9014526722135849\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12254260616677046, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12254260616677046\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23058336894956008, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23058336894956008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8673448576231353, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8673448576231353\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArUAAAHFCAYAAADsagEdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAACU4ElEQVR4nOzdeVxN+f8H8NetrtseRSpaLRUjlYgsFRHRWMbYGqTGnn2brCXKIMwwzJhRYRhmMI2lYSJmLOOLLGOMncZWYy8VuXXP7w+Pzs/VXpfcej0fjx66n/M5n/M+73J738/9nHMlgiAIICIiIiJSYxqVHQARERERUUWxqCUiIiIitceiloiIiIjUHotaIiIiIlJ7LGqJiIiISO2xqCUiIiIitceiloiIiIjUHotaIiIiIlJ7LGqJiIiISO2xqCWiKiEuLg4SiQSnTp0qsk9KSgokEgni4uLKdQyJRIKQkJAS+x07dgxhYWF4+vRpodsVCgW+//57+Pr6wtTUFFKpFDVr1kTr1q2xdOlSPHz4UKm/jY0NJBKJ+KWtrY2GDRti8uTJBfqGhYVBIpFAQ0MDN27cKHDsrKwsGBoaQiKRIDAwsMRzefPYr39lZmaWuH95rF69utw/o7ctMDAQ+vr6lR1GhURGRiI+Pr6ywyBSORa1RFRtmJub488//0T37t3f6nGOHTuG8PDwQova58+fo2vXrhgyZAiMjY3x5Zdf4sCBA/j+++/RsWNHLFmyBL179y6wX9u2bfHnn3/izz//xK+//oqRI0fim2++QdeuXQuNQV9fH7GxsQXaf/rpJ8jlckil0lKfz+vHfv1LV1e31GOUxftc1FYFLGqpqtKq7ACIiN4VmUyG1q1bV2oMEydORGJiIjZv3oyBAwcqbevRowdmz56NTZs2FdgvfyY3n7e3N549e4aIiAhcuXIFjRs3Vurfv39/rF+/HuHh4dDQ+P/5i3Xr1qF3797YuXNnqWN+89jqKjs7+60V4urg+fPn0NHRqewwiN4aztQSUbVR1PKDX375BU5OTpDJZLCzs8MXX3whvo1fmI0bN8LR0RG6urpo3rw5du/eLW4LCwvDtGnTAAC2trbiW/WHDh1CamoqYmJi0L179wIFbT5dXV0MHz68VOdjZGQEAIXOugYFBeH27dtITEwU265cuYIjR44gKCioVOOXVlpaGkaOHIn69eujRo0asLW1RXh4OHJzc5X6hYeHw93dHcbGxjA0NISrqyvWrVsHQRDEPjY2Nrhw4QJ+//13MXc2NjYA/n+JSUpKitK4hw4dEnOcz8vLCx988AH++OMPeHh4QFdXVzzvjIwMTJ06Fba2tqhRowbq1auHiRMnIisrq1znb2Njgx49emD37t1wcXGBjo4OHB0dxd+LuLg4ODo6Qk9PD61atSqwRCZ/ScOFCxfQqVMn6OnpoU6dOggJCUF2drZS3xcvXiA0NFQp9rFjxxZ4VyA/ph07dsDFxQXa2toIDw+HRCJBVlYW1q9fL+bXy8sLAPDgwQOMGTMGTZo0gb6+PkxNTdGxY0ccPnxYaez8/0dLly7FsmXLYGtrC319fbRp0wbHjx8vkJ///e9/8Pf3h4mJCbS1tdGgQQNMnDhRqc/Vq1cxaNAgmJqaQiaTwdHREV999ZVSH4VCgQULFsDe3h46OjqoWbMmnJyc8MUXX5T2R0VVHGdqiaha27t3L/r06YMOHTpg69atyM3NxdKlS/Hff/8V2n/Pnj04efIk5s+fD319fSxevBi9e/fG5cuXYWdnh08//RSPHz/GypUrsWPHDpibmwMAmjRpgt27dyM3NxcffvhhmeMUBEEsEl+8eIGTJ09ixYoVaNu2LWxtbQv0b9SoEdq3b4+YmBj4+voCAGJiYmBjY4NOnTqV+9j5NDQ0oKGhgbS0NLRq1QoaGhqYO3cuGjRogD///BMLFixASkqK0hKIlJQUjBw5ElZWVgCA48ePY9y4cbh79y7mzp0LAPj555/Rt29fGBkZYfXq1QBezbCXR2pqKj755BNMnz4dkZGR0NDQQHZ2Njw9PXHnzh3MnDkTTk5OuHDhAubOnYvz589j//79Rb6YKc65c+cQGhqKWbNmwcjICOHh4ejTpw9CQ0Nx4MABREZGQiKRYMaMGejRowdu3rypNGsql8vh5+eHkSNH4rPPPsOxY8ewYMEC/Pvvv9i1axeAVz+HXr164cCBAwgNDUX79u3x119/Yd68eeKSkNdzdfr0aVy8eBGzZ8+Gra0t9PT00KtXL3Ts2BHe3t6YM2cOAMDQ0BAA8PjxYwDAvHnzYGZmhszMTPz888/w8vLCgQMHxOI331dffQUHBwesWLECADBnzhz4+fnh5s2b4guuffv2wd/fH46Ojli2bBmsrKyQkpKC3377TRznn3/+gYeHB6ysrBAdHQ0zMzPs27cP48ePx8OHDzFv3jwAwOLFixEWFobZs2ejQ4cOkMvluHTpUpFr16kaEoiIqoDY2FgBgHDy5Mki+9y8eVMAIMTGxoptLVu2FCwtLYWcnByx7dmzZ4KJiYnw5lMkAKFu3bpCRkaG2JaWliZoaGgIUVFRYtuSJUsEAMLNmzeV9l+0aJEAQNi7d2+B2ORyudLX66ytrQUABb5atWolpKamKvWdN2+eAEB48OCBEBsbK8hkMuHRo0dCbm6uYG5uLoSFhQmCIAh6enrC0KFDi8xVSceeNWuWIAiCMHLkSEFfX1/4999/lfZbunSpAEC4cOFCoePm5eUJcrlcmD9/vmBiYiIoFApxW9OmTQVPT88C++T/jN/M68GDBwUAwsGDB8U2T09PAYBw4MABpb5RUVGChoZGgd+Tbdu2CQCEhISEYvMxdOhQQU9PT6nN2tpa0NHREe7cuSO2nT17VgAgmJubC1lZWWJ7fHy8AEDYuXOn0pgAhC+++EJp3IULFwoAhCNHjgiCIAh79+4VAAiLFy9W6rd161YBgLB27VqlmDQ1NYXLly8XOIfS/uxzc3MFuVwudOrUSejdu7fYnv//qFmzZkJubq7YfuLECQGA8MMPP4htDRo0EBo0aCA8f/68yOP4+voK9evXF9LT05XaQ0JCBG1tbeHx48eCIAhCjx49BGdn5xLjpuqLyw+IqNrKysrCqVOn0KtXL9SoUUNs19fXh7+/f6H7eHt7w8DAQHxct25dmJqa4t9//y13HGfPnoVUKlX6evOuBu3atcPJkydx8uRJHD16FOvWrcODBw/QsWPHAn3zffzxx6hRowY2bdqEhIQEpKWlleqOB296/dj5X2PGjAEA7N69G97e3rCwsEBubq741a1bNwDA77//Lo6TlJQEHx8fGBkZQVNTE1KpFHPnzsWjR49w//79MsdVklq1aqFjx45Kbbt378YHH3wAZ2dnpXh9fX0LLGEoC2dnZ9SrV0987OjoCODVMojX1/Hmtxf2+xIQEKD0eNCgQQCAgwcPAniVPwAFfoYff/wx9PT0cODAAaV2JyenAmutS/L111/D1dUV2tra0NLSglQqxYEDB3Dx4sUCfbt37w5NTU2l471+bleuXMH169cRHBwMbW3tQo/34sULHDhwAL1794aurq7Sz8TPzw8vXrwQlzS0atUK586dw5gxY7Bv3z5kZGSU6dyo6uPyAyKqtp48eQJBEFC3bt0C2wprAwATE5MCbTKZDM+fPy/xePlvu79Z0Njb2+PkyZMAgLVr1+Lbb78tsK+RkRHc3NzExx4eHmjSpAnatGmD6OhoREVFFdhHT08P/fv3R0xMDKytreHj4wNra+sS4yzp2K/777//sGvXriLvppBfcJ84cQJdunSBl5cXvv32W3H9bXx8PBYuXFiq/JVV/tKPN+O9du1aifGWlbGxsdLj/BdJRbW/ePFCqV1LS6vA75aZmRkA4NGjR+K/WlpaqFOnjlI/iUQCMzMzsV++ws6/OMuWLcOUKVMwatQoREREoHbt2tDU1MScOXMKLWrfjDd/6UP+z/LBgwcAgPr16xd5zEePHiE3NxcrV67EypUrC+2T/zMJDQ2Fnp4evv/+e3z99dfQ1NREhw4d8Pnnnxf5+0nVC4taIqq2atWqBYlEUuj62bS0NJUfz8vLC1paWti5cydGjBghtuvo6Ih/lF+/6Kwk+TNj586dK7JPUFAQvvvuO/z111+F3lWhomrXrg0nJycsXLiw0O0WFhYAgC1btkAqlWL37t1Ks3ZlubVU/n45OTlK7UUVooWtja1duzZ0dHQQExNT6D61a9cudTyqlJubi0ePHikVivm/g/ltJiYmyM3NxYMHD5QKW0EQkJaWhpYtWyqNWda1wd9//z28vLywZs0apfZnz56VaZx8+THeuXOnyD61atWCpqYmBg8ejLFjxxbaJ3/NuJaWFiZPnozJkyfj6dOn2L9/P2bOnAlfX1/cvn27Wt/Zgl7h8gMiqrb09PTg5uaG+Ph4vHz5UmzPzMwsU3H5pjdnrPKZm5sjKCgIe/bswZYtW8o9fr6zZ88CAExNTYvs06ZNGwQFBaF3796F3v+2onr06IG///4bDRo0gJubW4Gv/KJWIpFAS0tL6e3q58+fY+PGjQXGLGrmO/8uCH/99ZdSe1luT9ajRw9cv34dJiYmhcabf4zK8OaLjs2bNwOAeIFW/gV+33//vVK/7du3Iysrq9QXABaVX4lEUuCivL/++gt//vlnqcZ9U+PGjdGgQQPExMQUeCGST1dXF97e3jhz5gycnJwK/ZkU9u5IzZo10bdvX4wdOxaPHz8ucEcMqp44U0tEVUpSUlKhf+D8/PwK7T9//nx0794dvr6+mDBhAvLy8rBkyRLo6+uLV4OXVbNmzQAAX3zxBYYOHQqpVAp7e3sYGBhgxYoVuHnzJgICArBz50707NkTFhYWyM7OxqVLl7BlyxZoa2sXeHv86dOn4tpCuVyOixcvIjIyEjKZrMgZrnzr1q0r13mUxvz585GYmAgPDw+MHz8e9vb2ePHiBVJSUpCQkICvv/4a9evXR/fu3bFs2TIMGjQII0aMwKNHj7B06dJC72zQrFkzbNmyBVu3boWdnR20tbXRrFkztGzZEvb29pg6dSpyc3NRq1Yt/Pzzzzhy5Eip4504cSK2b9+ODh06YNKkSXBycoJCocCtW7fw22+/YcqUKXB3d1dlikqlRo0aiI6ORmZmJlq2bCne/aBbt25o164dAKBz587w9fXFjBkzkJGRgbZt24p3P3BxccHgwYNLdaxmzZrh0KFD2LVrF8zNzWFgYAB7e3v06NEDERERmDdvHjw9PXH58mXMnz8ftra2Be5+UVpfffUV/P390bp1a0yaNAlWVla4desW9u3bJxbxX3zxBdq1a4f27dtj9OjRsLGxwbNnz3Dt2jXs2rVLXEvs7++PDz74AG5ubqhTpw7+/fdfrFixAtbW1mjUqFG54qMqprKvVCMiUoX8K+OL+rp582ahdz8QBEH4+eefhWbNmgk1atQQrKyshEWLFgnjx48XatWqpdQPgDB27NgCx7a2ti5wNXloaKhgYWEhaGhoFLgyPy8vT9iwYYPQuXNnoXbt2oKWlpZgZGQktGrVSpgzZ47SVfT5479+LpqamoKVlZXQt29f4cyZM0p9X7/7QXHKcveD7t27F9vnwYMHwvjx4wVbW1tBKpUKxsbGQosWLYRZs2YJmZmZYr+YmBjB3t5ekMlkgp2dnRAVFSWsW7euwB0NUlJShC5duggGBgYCAMHa2lrcduXKFaFLly6CoaGhUKdOHWHcuHHCnj17Cr37QdOmTQuNNzMzU5g9e7Zgb28v1KhRQzAyMhKaNWsmTJo0SUhLSyv2XIu6+0FhOSrs9yX/d3DJkiUFxvzrr78ELy8vQUdHRzA2NhZGjx6tlD9BEITnz58LM2bMEKytrQWpVCqYm5sLo0ePFp48eVKqmATh1Z0Z2rZtK+jq6goAxDtN5OTkCFOnThXq1asnaGtrC66urkJ8fLwwdOhQpZ9BYefw+jnPmzdPqe3PP/8UunXrJhgZGQkymUxo0KCBMGnSpAJ5CQoKEurVqydIpVKhTp06goeHh7BgwQKxT3R0tODh4SHUrl1b/L8aHBwspKSkFHqeVP1IBOG1u14TERHkcrl4Nfvr99MkehsCAwOxbds2ZGZmVnYoRGqNyw+IqNoLDg5G586dYW5ujrS0NHz99de4ePEiP6mIiEiNsKglomrv2bNnmDp1Kh48eACpVApXV1ckJCTAx8enskMjIqJS4vIDIiIiIlJ7vKUXEREREak9FrVEREREpPZY1BIRERGR2uOFYlQtKBQK3Lt3DwYGBmX+6EgiIiKqHIIg4NmzZ7CwsICGRvFzsSxqqVq4d+8eLC0tKzsMIiIiKofbt2+jfv36xfZhUUvVgoGBAQDg5s2bMDY2ruRo1JtcLsdvv/2GLl26FPgoVyob5lJ1mEvVYS5Vh7msuIyMDFhaWop/x4vDopaqhfwlBwYGBjA0NKzkaNSbXC6Hrq4uDA0N+SRdQcyl6jCXqsNcqg5zqTqlWTrIC8WIiIiISO2xqCUiIiIitceiloiIiIjUHotaIiIiIlJ7LGqJiIiISO2xqCUiIiIitceiloiIiIjUHotaIiIiIlJ7LGqJiIiISO2xqCUiIiIitceiloiIiIjUHotaIiIiIlJ7LGqJiIiISO2xqCUiIiIitceiloiIiIjUHotaIiIiIlJ7LGqJiIiISO2xqCUiIiIitceiloiIiIjUHotaIiIiIlJ7LGqJiIiISO2xqCUiIiIitceiloiIiIjUHotaIiIiIlJ7LGqJiIiISO2xqKUCwsLC4OzsXNlhEBER0Vvyxx9/wN/fHxYWFpBIJIiPj1faLggCwsLCYGFhAR0dHXh5eeHChQtKfdLS0jB48GCYmZlBT08Prq6u2LZtW4Fj7dmzB+7u7tDR0UHt2rXRp0+ft3JOLGqrGX9/f/j4+BS67c8//4REIkHHjh1x4MCBMo1rY2ODFStWqCBCIiIietuysrLQvHlzrFq1qtDtixcvxrJly7Bq1SqcPHkSZmZm6Ny5M549eyb2GTx4MC5fvoydO3fi/Pnz6NOnD/r3748zZ86IfbZv347Bgwdj2LBhOHfuHI4ePYpBgwa9lXOSCIIgvJWR6b0UHx+PPn364ObNm7C2tlbaNnz4cJw6dUrpl7G0bGxsMHHiREycOFFFkapWRkYGjIyM0GDKVuRq6VV2OGpNpilgcas8TD+hiZw8SWWHo9aYS9VhLlWHuVSd9zGXKYu6F2iTSCT4+eef0atXLwCvZmktLCwwceJEzJgxAwCQk5ODunXr4vPPP8fIkSMBAPr6+lizZg0GDx4sjmViYoLFixcjODgYubm5sLGxQXh4OIKDg8sVb/7f7/T0dBgaGhbblzO11UyPHj1gamqKuLg4pfbs7Gxs3boVwcHBBZYfBAYGolevXli6dCnMzc1hYmKCsWPHQi6XAwC8vLzw77//YtKkSZBIJJBIXv3HffToEQYOHIj69etDV1cXzZo1ww8//KB03GfPniEgIAB6enowNzfH8uXL4eXlpVQcv3z5EtOnT0e9evWgp6cHd3d3HDp06G2kh4iIqNq7efMm0tLS0KVLF7FNJpPB09MTx44dE9vatWuHrVu34vHjx1AoFNiyZQtycnLg5eUFADh9+jTu3r0LDQ0NuLi4wNzcHN26dSuwjEFVWNRWM1paWhgyZAji4uLw+iT9Tz/9hJcvXyIgIKDQ/Q4ePIjr16/j4MGDWL9+PeLi4sTCeMeOHahfvz7mz5+P1NRUpKamAgBevHiBFi1aYPfu3fj7778xYsQIDB48GP/73//EcSdPnoyjR49i586dSExMxOHDh3H69GmlYw8bNgxHjx7Fli1b8Ndff+Hjjz9G165dcfXqVRVnh4iIiNLS0gAAdevWVWqvW7euuA0Atm7ditzcXJiYmEAmk2HkyJH4+eef0aBBAwDAjRs3ALy6Vmf27NnYvXs3atWqBU9PTzx+/FjlcWupfER67wUFBWHJkiU4dOgQvL29AQAxMTHo06cPatWqVeg+tWrVwqpVq6CpqQkHBwd0794dBw4cwPDhw2FsbAxNTU0YGBjAzMxM3KdevXqYOnWq+HjcuHHYu3cvfvrpJ7i7u+PZs2dYv349Nm/ejE6dOgEAYmNjYWFhIe5z/fp1/PDDD7hz547YPnXqVOzduxexsbGIjIwsNN6cnBzk5OSIjzMyMgAAMg0BmppccVMRMg1B6V8qP+ZSdZhL1WEuVed9zGX+u6xvys3NFbfl5uYWaAOAvLw8pTFmzpyJx48fY+/evTAxMcHOnTvx8ccfIykpCc2aNcPLly8BAJ999hk+/PBDAMDatWtha2uLLVu2YPjw4eWOtzAsaqshBwcHeHh4ICYmBt7e3rh+/ToOHz6M3377rch9mjZtCk1NTfGxubk5zp8/X+xx8vLysGjRImzduhV3794VC009vVdrWm/cuAG5XI5WrVqJ+xgZGcHe3l58fPr0aQiCgMaNGyuNnZOTAxMTkyKPHRUVhfDw8ALts10U0NXNKzZuKp0IN0Vlh1BlMJeqw1yqDnOpOu9TLhMSEgptT05OhlQqBfD/M7Xbt2+HnZ2d2Ofvv/+Gnp4eEhISkJqaitWrV+PLL7/EixcvcPfuXbRo0QLW1taYOXMmRo8ejVu3bgEAnj59qnTcWrVq4eDBg6hXr16J8WZnZ5f63FjUVlPBwcEICQnBV199hdjYWFhbW4uzpYXJ/0XPJ5FIoFAU/580Ojoay5cvx4oVK9CsWTPo6elh4sSJ4iu3/OUP+Wtw872+LEKhUEBTUxPJyclKRTXwaoF6UUJDQzF58mTxcUZGBiwtLbHgjAZypZpF7kclk2kIiHBTYM4pDeQo3o8LH9QVc6k6zKXqMJeq8z7m8u8w30LbW7RoAT8/PwD/fzuvFy9eiG0vX77E0KFDERkZCT8/P3Fiy9PTE46OjuI4X331FerXrw8/Pz+0a9cOCxYsgImJiTiOXC5Heno6OnbsKLYVJ/+d1tJgUVtN9evXDxMmTMDmzZuxfv16DB8+vEBxWRY1atQQ35bId/jwYfTs2ROffPIJgFcF6tWrV8Vf/gYNGkAqleLEiROwtLQE8OqX9+rVq/D09AQAuLi4IC8vD/fv30f79u1LHY9MJoNMJivQnqOQIPc9uQJV3eUoJO/N1bzqjrlUHeZSdZhL1Xmfcpk/SZWZmYlr166J7bdv38aFCxdgbGwMKysrTJw4EVFRUXBwcECjRo0QGRkJXV1dDB48GFKpFM2aNUPDhg0REhKCpUuXwsTEBPHx8di/fz92794NqVQKExMTjBo1CvPnz4eNjQ2sra2xZMkSAMCAAQMKTJgVF29psKitpvT19dG/f3/MnDkT6enpCAwMrNB4NjY2+OOPPzBgwADIZDLUrl0bDRs2xPbt23Hs2DHUqlULy5YtQ1pamljUGhgYYOjQoZg2bRqMjY1hamqKefPmQUNDQyywGzdujICAAAwZMgTR0dFwcXHBw4cPxfU6pXmV97r/hXYqdtkClUwulyMhIQF/h/mW6cmGCmIuVYe5VB3mUnXe51yeOnVKvK4GgPju5tChQxEXF4fp06fj+fPnGDNmDJ48eQJ3d3f89ttvMDAwAPCq2ExISMBnn30Gf39/ZGZmomHDhli/fr3S3+YlS5ZAS0sLgwcPxvPnz+Hu7o6kpKQir+GpCBa11VhwcDDWrVuHLl26wMrKqkJjzZ8/HyNHjkSDBg2Qk5MDQRAwZ84c3Lx5E76+vtDV1cWIESPQq1cvpKeni/stW7YMo0aNQo8ePWBoaIjp06fj9u3b0NbWFvvExsZiwYIFmDJlCu7evQsTExO0adOmzAUtERERveLl5YXiPqpAIpEgLCwMYWFhRfZp1KgRtm/fXuxxpFIpli5diqVLl5Y31FLjhy/QeyUrKwv16tVDdHR0uW/UXJj8mzc/fPiQM7UVlD/z4Ofn997NPKgb5lJ1mEvVYS5Vh7msuLJ8+AJnaqlSnTlzBpcuXUKrVq2Qnp6O+fPnAwB69uxZyZERERGROmFRS5Vu6dKluHz5MmrUqIEWLVrg8OHDqF27dmWHRURERGqERS1VKhcXFyQnJ1d2GERERKTm+DG5RERERKT2WNQSERERkdpjUUtEREREao9FLRERERGpPRa1RERERKT2WNQSERERkdpjUUtEREREao9FLRERERGpPRa1RERERKT2WNQSERERkdpjUUtEREREao9FLRERERGpPRa1RERERKT2WNQSERERkdpjUUtEREREao9FLRERERGpPRa1RERERKT2WNQSERERkdpjUUtEREREao9FrRqIi4tDzZo1KzuMcvHy8sLEiRMrOwwiIpW4e/cuPvnkE5iYmEBXVxfOzs5ITk4WtwcGBkIikSh9tW7dWmmMkSNHokGDBtDR0UGdOnXQs2dPXLp06V2fClGVU+2L2mPHjkFTUxNdu3at7FBUIi4uTunJ1NzcHP369cPNmzcrJZ4dO3YgIiKiUo5NRKRKT548Qdu2bSGVSvHrr7/in3/+QXR0dIFJh65duyI1NVX8SkhIUNreokULxMbG4uLFi9i3bx8EQUCXLl2Ql5f3Ds+GqOrRquwAKltMTAzGjRuH7777Drdu3YKVlVVlh1RhhoaGuHz5MgRBwKVLlzBy5Eh8+OGHOHv2LDQ1NZX6CoKAvLw8aGm9nV8FY2PjtzJueblHHUCull5lh6HWZJoCFrcCPgjbh5w8SWWHo9aYS9V5m7lMWdQdAPD555/D0tISsbGx4jYbG5uCschkMDMzK3K8ESNGKO2/YMECNG/eHCkpKWjQoIHqAieqZqr1TG1WVhZ+/PFHjB49Gj169EBcXJy47dChQ5BIJDhw4ADc3Nygq6sLDw8PXL58WewTFhYGZ2dnbNy4ETY2NjAyMsKAAQPw7NkzsY+NjQ1WrFihdFxnZ2eEhYWJj5ctW4ZmzZpBT08PlpaWGDNmDDIzM8t9XhKJBGZmZjA3N4e3tzfmzZuHv//+G9euXRPPa9++fXBzc4NMJsPhw4chCAIWL14MOzs76OjooHnz5ti2bVuBfOzbtw8uLi7Q0dFBx44dcf/+ffz6669wdHSEoaEhBg4ciOzsbHG/N5cfSCQSxMfHK8Vbs2ZNMfcpKSmQSCT48ccf0b59e+jo6KBly5a4cuUKTp48CTc3N+jr66Nr16548OBBuXNERFRWO3fuhJubGz7++GOYmprCxcUF3377bYF+hw4dgqmpKRo3bozhw4fj/v37RY6ZlZWF2NhY2NrawtLS8m2GT1TlVeuZ2q1bt8Le3h729vb45JNPMG7cOMyZMwcSyf+/yp81axaio6NRp04djBo1CkFBQTh69Ki4/fr164iPj8fu3bvx5MkT9OvXD4sWLcLChQtLHYeGhga+/PJL2NjY4ObNmxgzZgymT5+O1atXq+Q8dXR0AAByuVxsmz59OpYuXQo7OzvUrFkTs2fPxo4dO7BmzRo0atQIf/zxBz755BPUqVMHnp6e4n5hYWFYtWoVdHV10a9fP/Tr1w8ymQybN29GZmYmevfujZUrV2LGjBkVinnevHlYsWIFrKysEBQUhIEDB8LQ0BBffPGFeOy5c+dizZo1he6fk5ODnJwc8XFGRgYAQKYhQFNTqFBs1Z1MQ1D6l8qPuVSdt5nL/OfOGzduYM2aNZgwYQKmTZuGU6dOYfz48dDU1MTgwYMBAJ07d0bv3r1hZWWFlJQUhIWFwdvbG//73/8gk8nEMb/++muEhoYiKysL9vb2SEhIgEQiUXqeriz5MbwPsag75rLiypK7al3Urlu3Dp988gmAV2ugMjMzceDAAfj4+Ih9Fi5cKBZ1n332Gbp3744XL15AW1sbAKBQKBAXFwcDAwMAwODBg3HgwIEyFbWvz2Ta2toiIiICo0ePVklRe+fOHSxZsgT169dH48aN8fDhQwDA/Pnz0blzZwCvZgqWLVuGpKQktGnTBgBgZ2eHI0eO4JtvvlEqahcsWIC2bdsCAIKDgxEaGorr16/Dzs4OANC3b18cPHiwwkXt1KlT4evrCwCYMGECBg4ciAMHDigd+/WZ9TdFRUUhPDy8QPtsFwV0dbluTRUi3BSVHUKVwVyqztvIZf6a2Ly8PDRo0AAeHh5ITU1FvXr10KlTJyxevBgmJiYAAH19fQDArVu3oKGhgYkTJ2LEiBFYsGCB+PwKACYmJliyZAmePHmC+Ph4dO/eHYsWLUKNGjVUHn95JSYmVnYIVQZzWX6vv/tbkmpb1F6+fBknTpzAjh07AABaWlro378/YmJilIpaJycn8Xtzc3MAwP3798W1tzY2NmJBm9+nuLeaCnPw4EFERkbin3/+QUZGBnJzc/HixQtkZWVBT6/s6z/T09Ohr68PQRCQnZ0NV1dX7NixQ+nJ0s3NTfz+n3/+wYsXL8QiN9/Lly/h4uKi1PZ6PurWrQtdXV2xoM1vO3HiRJljftObxwGAZs2aKbUVl+fQ0FBMnjxZfJyRkQFLS0ssOKOBXKlmkftRyWQaAiLcFJhzSgM5Cq4DrQjmUnXeZi7/Dnv1AtvCwgIeHh7w8/MTt92+fRtRUVFKbW+KjIyEoaFhkX0mTJgAU1NTvHjxAr169VJp7OUhl8uRmJiIzp07QyqVVnY4ao25rLj8d1pLo9oWtevWrUNubi7q1asntgmCAKlUiidPnohtr/8S5i9LUCgUhW7P7/P6dg0NDQiC8tthr0+l//vvv/Dz88OoUaMQEREBY2NjHDlyBMHBweV+u8LAwACnT5+GhoYG6tatW2hh/Hpbfrx79uxRygcApbfLgIL5KOn83ySRSIrNR1HHKaytuOPIZLICsQNAjkKCXF6QoxI5CgkvblIR5lJ13kYu85972rZti6tXryo9F12/fh3W1tZFFiyPHj3C7du3Ub9+/SL7CIIgXrT7PhU+Uqn0vYpHnTGX5VeWvFXLojY3NxcbNmxAdHQ0unTporTto48+wqZNm/DBBx+o5Fh16tRBamqq+DgjI0Pp9lqnTp1Cbm4uoqOjoaHx6rq9H3/8sULH1NDQQMOGDUvdv0mTJpDJZLh165bSUoO34c18XL16tUxvLRARVZZJkybBw8MDkZGR6NevH06cOIG1a9di7dq1AIDMzEyEhYXho48+grm5OVJSUjBz5kzUrl0bvXv3BvBqXe7WrVvRpUsX1KlTB3fv3sXnn38OHR2dYmd7iahk1bKozb+oKzg4GEZGRkrb+vbti3Xr1mH58uUqOVbHjh0RFxcHf39/1KpVC3PmzFG6rVaDBg2Qm5uLlStXwt/fH0ePHsXXX3+tkmOXloGBAaZOnYpJkyZBoVCgXbt2yMjIwLFjx6Cvr4+hQ4eq7FgdO3bEqlWr0Lp1aygUCsyYMeOdvnr9X2gnce0blY9cLkdCQgL+DvPlzEMFMZeq8y5y2bJlS/z8888IDQ3F/PnzYWtrixUrViAgIAAAoKmpifPnz2PDhg14+vSpeAearVu3isvUtLW1cfjwYaxYsQJPnjxB3bp10aFDBxw7dgympqZvJW6i6qJaFrXr1q2Dj49PgYIWeDVTGxkZidOnT6vkWKGhobhx4wZ69OgBIyMjREREKM3UOjs7Y9myZfj8888RGhqKDh06ICoqCkOGDFHJ8UsrIiICpqamiIqKwo0bN1CzZk24urpi5syZKj1OdHQ0hg0bhg4dOsDCwgJffPGF0qfxEBG9z3r06IEePXoUuk1HRwf79u0rdn8LC4sCH8ZARKohEd5c4EhUBWVkZMDIyAgPHz7kTG0F5c+I+fn5cXaxgphL1WEuVYe5VB3msuLy/36np6fD0NCw2L7V+sMXiIiIiKhqYFGrZpo2bQp9ff1CvzZt2lTZ4RERERFVimq5pladJSQkFHmrr/z7uRIRERFVNyxq1Yy1tXVlh0BERET03uHyAyIiIiJSeyxqiYiIiEjtsaglIiIiIrXHopaIiIiI1B6LWiIiIiJSeyxqiYiIiEjtsaglIiIiIrXHopaIiIiI1B6LWiIiIiJSeyxqiYiIiEjtsaglIiIiIrXHopaIiIiI1B6LWiIiIiJSeyxqiYiIiEjtsaglIiIiIrXHopaIiIiI1B6LWiIiIiJSeyxqiYjovRYWFgaJRKL0ZWZmJm6XSCSoUaMGevXqhRo1aoh9lixZAgB4/Pgxxo0bB3t7e+jq6sLKygrjx49Henp6ZZ0SEb0FalvUHjp0CBKJBE+fPgUAxMXFoWbNmpUaU1m8Gf/7QCKRID4+vrLDKJXAwED06tWrssMgonekadOmSE1NFb/Onz8vbktNTcWtW7cQGxuLW7duISYmBhKJBB999BEA4N69e7h37x6WLl2K8+fPIy4uDnv37kVwcHBlnQ4RvQWVWtQGBgaKr6ilUins7OwwdepUZGVllXms/v3748qVK28hyoKysrIwY8YM2NnZQVtbG3Xq1IGXlxd27979To5fHmlpaRg3bhzs7Owgk8lgaWkJf39/HDhwoLJDIyIqkZaWFszMzMSvOnXqiNvy22rVqgUzMzP88ssv8Pb2hp2dHQDggw8+wPbt2+Hv748GDRqgY8eOWLhwIXbt2oXc3NzKOiUiUjGtyg6ga9euiI2NhVwux+HDh/Hpp58iKysLa9asKdM4Ojo60NHReUtRKhs1ahROnDiBVatWoUmTJnj06BGOHTuGR48evZPjl1VKSgratm2LmjVrYvHixXBycoJcLse+ffswduxYXLp0qbJDfGfcow4gV0uvssNQazJNAYtbAR+E7UNOnqSyw1FrzGXJUhZ1BwBcvXoVFhYWkMlkcHd3R2RkpFi0vu6///7Dnj17sH79+mLHTU9Ph6GhIbS0Kv3PIBGpSKUvP5DJZDAzM4OlpSUGDRqEgIAAxMfHIycnB+PHj4epqSm0tbXRrl07nDx5sshxClt+sHPnTri5uUFbWxu1a9dGnz59AADz589Hs2bNCozRokULzJ07t8SYd+3ahZkzZ8LPzw82NjZo0aIFxo0bh6FDh4p9vv/+e7i5ucHAwABmZmYYNGgQ7t+/X+y4x44dQ4cOHaCjowNLS0uMHz9eadZ69erVaNSoEbS1tVG3bl307du3xFgBYMyYMZBIJDhx4gT69u2Lxo0bo2nTppg8eTKOHz+u1Pfhw4fo3bs3dHV10ahRI+zcuVPclpeXh+DgYNja2kJHRwf29vb44osvlPbPXxawdOlSmJubw8TEBGPHjoVcLhf72NjYIDIyEkFBQTAwMICVlRXWrl2rNM7du3fRv39/1KpVCyYmJujZsydSUlJKdb5EVLW4u7tjw4YN2LdvH7799lukpaXBw8Oj0ImEjRs3wsDAQHy+L8yjR48QERGBkSNHvs2wiegde+9eouro6EAul2P69OnYvn071q9fD2trayxevBi+vr64du0ajI2NSxxnz5496NOnD2bNmoWNGzfi5cuX2LNnDwAgKCgI4eHhOHnyJFq2bAkA+Ouvv3DmzBn89NNPJY5tZmaGhIQE9OnTBwYGBoX2efnyJSIiImBvb4/79+9j0qRJCAwMREJCQqH9z58/D19fX0RERGDdunV48OABQkJCEBISgtjYWJw6dQrjx4/Hxo0b4eHhgcePH+Pw4cMlxvr48WPs3bsXCxcuhJ5ewRnKN18IhIeHY/HixViyZAlWrlyJgIAA/PvvvzA2NoZCoUD9+vXx448/onbt2jh27BhGjBgBc3Nz9OvXTxzj4MGDMDc3x8GDB3Ht2jX0798fzs7OGD58uNgnOjoaERERmDlzJrZt24bRo0ejQ4cOcHBwQHZ2Nry9vdG+fXv88ccf0NLSwoIFC9C1a1f89ddfqFGjRonnnZOTg5ycHPFxRkYGAECmIUBTUyhxfyqaTENQ+pfKj7ksmVwuh4+Pj/jYwcEBbm5ucHBwQExMDCZOnCj2A15NcAwcOBCamppKL6bzZWRkwM/PD46Ojpg5c2ahfaq7/JwwNxXHXFZcWXInEQSh0p5NAwMD8fTpU/HipBMnTsDPzw/e3t745ZdfEBcXh0GDBgF4dVI2NjaYOHEipk2bhkOHDsHb2xtPnjxBzZo1ERcXh4kTJ4oXXnl4eMDOzg7ff/99ocfOn2VdvXo1AGDSpEk4e/YsDh48WGLcf/zxBwICAvDff/+hefPmaNeuHfr27Yu2bdsWuc/JkyfRqlUrPHv2DPr6+gXiHzJkCHR0dPDNN9+I+xw5cgSenp7IyspCQkIChg0bhjt37hRZSBfmxIkTcHd3x44dO9C7d+9i+0okEsyePRsREREAXq0dNjAwQEJCArp27VroPmPHjsV///2Hbdu2AXj1Mz106BCuX78OTU1NAEC/fv2goaGBLVu2AHg1U9u+fXts3LgRACAIAszMzBAeHo5Ro0YhJiYGixcvxsWLFyGRvHpL9uXLl6hZsybi4+PRpUuXAr87bwoLC0N4eHiB9s2bN0NXV7eErBHR+27evHkwNzfHqFGjxLYLFy5g1qxZWL58OWxtbQvs8/z5c4SFhUEmk2H27NmleoFMRJUrOzsbgwYNEpcMFafSZ2p3794NfX195ObmQi6Xo2fPnhg3bhy2bdumVCRKpVK0atUKFy9eLNW4Z8+eVZoZfNPw4cMRFBSEZcuWQVNTE5s2bUJ0dHSpxu7QoQNu3LiB48eP4+jRo0hKSsIXX3yB8PBwzJkzBwBw5swZhIWF4ezZs3j8+DEUCgUA4NatW2jSpEmBMZOTk3Ht2jVs2rRJbBMEAQqFAjdv3kTnzp1hbW0NOzs7dO3aFV27dhWXCRQn/zVLfnFYEicnJ/F7PT09GBgYKC2b+Prrr/Hdd9/h33//xfPnz/Hy5Us4OzsrjdG0aVOxoAUAc3NzpSuV3zxO/u158o+Tn4s3i/cXL17g+vXrpTqP0NBQTJ48WXyckZEBS0tLLDijgVypZjF7UklkGgIi3BSYc0oDOQquA60I5rJkf4f5FmjLycnB2LFj0bNnT/j5+QF4NfHxxRdfwMXFBWPHji2wT0ZGBrp37466deti586dfHFbDLlcjsTERHTu3BlSqbSyw1FrzGXF5b/TWhqVXtR6e3tjzZo1kEqlsLCwgFQqxblz5wAULMQEQSh1cVbSRWP+/v6QyWT4+eefIZPJkJOTI97+pTSkUinat2+P9u3b47PPPsOCBQswf/58zJgxA3K5HF26dEGXLl3w/fffo06dOrh16xZ8fX3x8uXLQsdTKBQYOXIkxo8fX2CblZUVatSogdOnT+PQoUP47bffMHfuXISFheHkyZPF3sqsUaNGkEgkuHjxYqlugfXmfzqJRCIW5D/++CMmTZqE6OhotGnTBgYGBliyZAn+97//lXqM0vRRKBRo0aKFUoGf7/Urnosjk8kgk8kKtOcoJMjlBTkqkaOQ8OImFWEuiyaVSjF16lT4+/vDysoK9+/fx4IFC5CRkYGgoCDxuSQjIwPHjh1DdHR0geeXZ8+eoXv37sjOzsamTZvw/PlzPH/+HMCr55TXX4TT/5NKpSzEVIS5LL+y5K3Si1o9PT00bNhQqa1hw4aoUaMGjhw5orT84NSpU+L6qZI4OTnhwIEDGDZsWKHbtbS0MHToUMTGxkImk2HAgAEVeuXepEkT5Obm4sWLF7h69SoePnyIRYsWwdLSEgBw6tSpYvd3dXXFhQsXCuTizZh9fHzg4+ODefPmoWbNmkhKSir2gghjY2P4+vriq6++wvjx4wusq3369Gmp7+97+PBheHh4YMyYMWJbaWdOy8LV1RVbt26FqalpiW81lNX/QjvBxMREpWNWN3K5HAkJCfg7zJdP0hXEXJbOnTt3MHDgQDx8+BB16tRB69atcfz4cVhbW4t9fvzxRwiCgP79+xfYPzk5WXzx/eZz7M2bN2FjY/NW4yeid6PSi9rC6OnpYfTo0Zg2bRqMjY1hZWWFxYsXIzs7u9Q3y543bx46deqEBg0aYMCAAcjNzcWvv/6K6dOni30+/fRTODo6AgCOHj1a6vi8vLwwcOBAuLm5wcTEBP/88w9mzpwJb29vGBoaijOrK1euxKhRo/D333+L61SLMmPGDLRu3Rpjx47F8OHDoaenh4sXLyIxMRErV67E7t27cePGDXTo0AG1atVCQkICFAoF7O3tS4x39erV8PDwQKtWrTB//nw4OTkhNzcXiYmJWLNmTamXdDRs2FC8AtnW1hYbN27EyZMnC127VhEBAQFYsmQJevbsifnz56N+/fq4desWduzYgWnTpqF+/foqPR4Rvd/y1+MX59NPP4WFhQWMjIwKbPPy8kIlXj5CRO9Ipd/SqyiLFi3CRx99hMGDB8PV1RXXrl3Dvn37UKtWrVLt7+XlhZ9++gk7d+6Es7MzOnbsWOBt8kaNGsHDwwP29vZwd3cvdWy+vr5Yv349unTpAkdHR4wbNw6+vr748ccfAbx6OysuLg4//fQTmjRpgkWLFmHp0qXFjunk5ITff/8dV69eRfv27eHi4oI5c+bA3NwcwKu7FOzYsQMdO3aEo6Mjvv76a/zwww9o2rRpifHa2tri9OnT8Pb2xpQpU/DBBx+gc+fOOHDgQJnuBzxq1Cj06dMH/fv3h7u7Ox49eqQ0a6squrq6+OOPP2BlZYU+ffrA0dERQUFBeP78ucpnbomIiKhqqNS7H1Q2QRDg4OCAkSNHKl1URFVPRkYGjIyM8PDhQy4/qKD8t8z9/Pz4lnkFMZeqw1yqDnOpOsxlxeX//VaLux9Ulvv372Pjxo24e/duketuiYiIiEg9VNuitm7duqhduzbWrl1bYEmDvr5+kfv9+uuvaN++/dsOr9SKukVYvn/++QdWVlbvMCIiIiKid6/aFrXFrbo4e/Zskdvq1av3FqIpPwsLi2LjtbCweHfBEBEREVWSalvUFqe422q9b7S0tNQqXiIiIqK34b29+wERERERUWmxqCUiIiIitceiloiIiIjUHotaIiIiIlJ7LGqJiIiISO2xqCUiIiIitceiloiIiIjUHotaIiIiIlJ7LGqJiIiISO2xqCUiIiIitceiloiIiIjUHotaIiIiIlJ7LGqJiIiISO2xqCUiIiIitceiloiIiIjUHotaIiIiIlJ7LGqJiIiISO2xqK0iDh06BIlEgqdPn1Z2KCphY2ODFStWVHYYRFQKYWFhkEgkSl9mZmbi9h07dsDX1xe1a9eGRCLB2bNnixxLEAR069YNEokE8fHxbz94IqoyWNS+A4GBgeITvZaWFqysrDB69Gg8efJEZcfw8PBAamoqjIyMVDZmaRw8eBB+fn4wMTGBrq4umjRpgilTpuDu3bvvNA4iqlxNmzZFamqq+HX+/HlxW1ZWFtq2bYtFixaVOM6KFSsgkUjeZqhEVEVpVXYA1UXXrl0RGxuL3Nxc/PPPPwgKCsLTp0/xww8/qGT8GjVqKM2MvAvffPMNxowZg6FDh2L79u2wsbHBrVu3sGHDBkRHR2PZsmXvNJ7ScI86gFwtvcoOQ63JNAUsbgV8ELYPOXksPiqiKuQyZVF3AICWllaRz0GDBw9+1Tclpdixzp07h2XLluHkyZMwNzdXaZxEVPVxpvYdkclkMDMzQ/369dGlSxf0798fv/32m7g9NjYWjo6O0NbWhoODA1avXq20/7Fjx+Ds7AxtbW24ubkhPj5e6W28wpYfbN++HU2bNoVMJoONjQ2io6OVxrSxsUFkZCSCgoJgYGAAKysrrF27tlTnc+fOHYwfPx7jx49HTEwMvLy8YGNjgw4dOuC7777D3LlzSx3H/fv34e/vDx0dHdja2mLTpk0Fjpeeno4RI0bA1NQUhoaG6NixI86dO1eqWIno7bt69SosLCxga2uLAQMG4MaNG2XaPzs7GwMHDsSqVave+Qt0IqoaWNRWghs3bmDv3r2QSqUAgG+//RazZs3CwoULcfHiRURGRmLOnDlYv349AODZs2fw9/dHs2bNcPr0aURERGDGjBnFHiM5ORn9+vXDgAEDcP78eYSFhWHOnDmIi4tT6hcdHQ03NzecOXMGY8aMwejRo3Hp0qUSz+Gnn37Cy5cvMX369EK316xZs9RxBAYGIiUlBUlJSdi2bRtWr16N+/fvi9sFQUD37t2RlpaGhIQEJCcnw9XVFZ06dcLjx49LjJWI3i53d3ds2LAB+/btw7fffou0tDR4eHjg0aNHpR5j0qRJ8PDwQM+ePd9ipERUlXH5wTuye/du6OvrIy8vDy9evAAA8e35iIgIREdHo0+fPgAAW1tb/PPPP/jmm28wdOhQbNq0CRKJBN9++y20tbXRpEkT3L17F8OHDy/yeMuWLUOnTp0wZ84cAEDjxo3xzz//YMmSJQgMDBT7+fn5YcyYMQCAGTNmYPny5Th06BAcHByKPZ+rV6/C0NCwxLcIS4rjypUr+PXXX3H8+HG4u7sDANatWwdHR0dxjIMHD+L8+fO4f/8+ZDIZAGDp0qWIj4/Htm3bMGLEiALHzcnJQU5Ojvg4IyMDACDTEKCpKRQbMxVPpiEo/UvlVxVyKZfL4ePjIz52cHCAm5sbHBwcEBMTg4kTJyr1zf83/3sA2LVrF5KSknDixAml9tzcXKXHJcXx+r9Ufsyl6jCXFVeW3LGofUe8vb2xZs0aZGdn47vvvsOVK1cwbtw4PHjwALdv30ZwcLBSkZqbmyte9HX58mU4OTlBW1tb3N6qVatij3fx4sUCMx5t27bFihUrkJeXB01NTQCAk5OTuD3/iuXXZ0mLIghCqS7mKCmOixcvQktLC25ubuJ2BwcHcaYXeDXbm5mZCRMTE6Vxnj9/juvXrxd63KioKISHhxdon+2igK5uXolxU8ki3BSVHUKVoc65TEhIKLTdzMwMSUlJaNy4sdj233//AQCOHDmCe/fuie2xsbG4fv06ateurTRG//794ejoiIULF5Y6nsTExLKET8VgLlWHuSy/7OzsUvdlUfuO6OnpoWHDhgCAL7/8Et7e3ggPD0dISAiAV0sQ8mcq8+UXnoUVkIJQ/MxOaffJXwKRTyKRQKEo+Q9s48aNkZ6ejtTU1GJna0uKI//74gpkhUIBc3NzHDp0qMC214vf14WGhmLy5Mni44yMDFhaWmLBGQ3kSjWLPBaVTKYhIMJNgTmnNJCjUM+Lm94XVSGXf4f5FmjLycnB2LFj0bNnT/j5+Ynt+ReKtWvXDs7OzmK7q6srHj58qDSGq6srli5diu7du8PW1rbEOORyORITE9G5c+cCz2tUNsyl6jCXFZf/TmtpsKitJPPmzUO3bt0wevRo1KtXDzdu3EBAQEChfR0cHLBp0ybk5OSIb7+fOnWq2PGbNGmCI0eOKLUdO3YMjRs3Fovliujbty8+++wzLF68GMuXLy+w/enTp6hZs2aJcTg6OiI3NxenTp0SZ58vX76sdMGbq6sr0tLSoKWlBRsbm1LFJ5PJxFy9LkchQa6aXmX+vslRSNT2iv33jTrnUiqVYurUqfD394eVlRXu37+PBQsWICMjA0FBQZBKpXj8+DFu3bolzs7euHEDUqkUZmZmMDMzg6WlJSwtLQuMbWtrqzTTW9p4WDyoBnOpOsxl+ZUlbyxqK4mXlxeaNm2KyMhIhIWFYfz48TA0NES3bt2Qk5ODU6dO4cmTJ5g8eTIGDRqEWbNmYcSIEfjss89w69YtLF26FEDRM5xTpkxBy5YtERERgf79++PPP//EqlWrCtxVobwsLS2xfPlyhISEICMjA0OGDIGNjQ3u3LmDDRs2QF9fH9HR0SXGYW9vj65du2L48OFYu3YttLS0MHHiROjo6IjH8vHxQZs2bdCrVy98/vnnsLe3x71795CQkIBevXopLV0oyf9COxVYxkBlI5fLkZCQgL/DfPkkXUFVJZd37tzBwIED8fDhQ9SpUwetW7fG8ePHYW1tDQDYuXMnhg0bJvYfMGAAgFcv7sPCwiojZCKqigR664YOHSr07NmzQPumTZuEGjVqCLdu3RI2bdokODs7CzVq1BBq1aoldOjQQdixY4fY9+jRo4KTk5NQo0YNoUWLFsLmzZsFAMKlS5cEQRCEgwcPCgCEJ0+eiPts27ZNaNKkiSCVSgUrKythyZIlSse3trYWli9frtTWvHlzYd68eaU+t8TERMHX11eoVauWoK2tLTg4OAhTp04V7t27V+o4UlNThe7duwsymUywsrISNmzYUCC2jIwMYdy4cYKFhYUglUoFS0tLISAgQLh161ap4kxPTxcACA8fPiz1uVHhXr58KcTHxwsvX76s7FDUHnOpOsyl6jCXqsNcVlz+3+/09PQS+0oEoYTFmfRe2rRpE4YNG4b09HSlWU0qXEZGBoyMjPDw4UPO1FZQ/uyin5+fWs8uvg+YS9VhLlWHuVQd5rLi8v9+p6enw9DQsNi+XH6gJjZs2AA7OzvUq1cP586dw4wZM9CvXz8WtERERETghy+ojbS0NHzyySdwdHTEpEmT8PHHH5f607/KIzIyEvr6+oV+devW7a0dl4iIiKg8OFOrJqZPn17kp3e9DaNGjUK/fv0K3cbZYSIiInrfsKilQhkbG8PY2LiywyAiIiIqFS4/ICIiIiK1x6KWiIiIiNQei1oiIiIiUnssaomIiIhI7bGoJSIiIiK1x6KWiIiIiNQei1oiIiIiUnssaomIiIhI7bGoJSIiIiK1x6KWiIiIiNQei1oiIiIiUnssaomIiIhI7bGoJSIiIiK1p7Ki9unTp6oaioiIiIioTMpV1H7++efYunWr+Lhfv34wMTFBvXr1cO7cOZUFR0RERERUGuUqar/55htYWloCABITE5GYmIhff/0V3bp1w7Rp01QaIBERERFRSbTKs1NqaqpY1O7evRv9+vVDly5dYGNjA3d3d5UGSERERERUknLN1NaqVQu3b98GAOzduxc+Pj4AAEEQkJeXp7roiIjovRcWFgaJRKL0ZWZmJm7fsWMHfH19Ubt2bUgkEpw9e7bIsQRBQLdu3SCRSBAfH//2gyeiKqNcM7V9+vTBoEGD0KhRIzx69AjdunUDAJw9exYNGzZUaYBERPT+a9q0Kfbv3y8+1tTUFL/PyspC27Zt8fHHH2P48OHFjrNixQpIJJK3FicRVV3lKmqXL18OGxsb3L59G4sXL4a+vj6AV8sSxowZo9IAqWo4duwY2rdvj86dO2Pv3r2VHQ4RqZiWlpbS7OzrBg8eDABISUkpdoxz585h2bJlOHnyJMzNzVUdIhFVceUqaqVSKaZOnVqgfeLEiRWNh6qomJgYjBs3Dt999x1u3boFKyurSonDPeoAcrX0KuXYVYVMU8DiVsAHYfuQk8cZtYqoCrlMWdQdAHD16lVYWFhAJpPB3d0dkZGRsLOzK/U42dnZGDhwIFatWlVkcUxEVJxy36d248aNaNeuHSwsLPDvv/8CePW20S+//KKy4KhqyMrKwo8//ojRo0ejR48eiIuLU9q+c+dONGrUCDo6OvD29sb69eshkUiU7n187NgxdOjQATo6OrC0tMT48eORlZX1bk+EiArl7u6ODRs2YN++ffj222+RlpYGDw8PPHr0qNRjTJo0CR4eHujZs+dbjJSIqrJyzdSuWbMGc+fOxcSJE7Fw4ULx4rCaNWtixYoVfFIiJVu3boW9vT3s7e3xySefYNy4cZgzZw4kEglSUlLQt29fTJgwAZ9++inOnDlT4F2A8+fPw9fXFxEREVi3bh0ePHiAkJAQhISEIDY2ttBj5uTkICcnR3yckZEBAJBpCNDUFN7eyVYDMg1B6V8qv6qQS7lcLl4sDAAODg5wc3ODg4MDYmJilN7Bk8vl4r/53wPArl27kJSUhBMnTii15+bmKj0uKY7X/6XyYy5Vh7msuLLkTiIIQpmfTZs0aYLIyEj06tULBgYGOHfuHOzs7PD333/Dy8sLDx8+LOuQVIW1bdsW/fr1w4QJE5Cbmwtzc3P88MMP8PHxwWeffYY9e/bg/PnzYv/Zs2dj4cKFePLkCWrWrIkhQ4ZAR0cH33zzjdjnyJEj8PT0RFZWFrS1tQscMywsDOHh4QXaN2/eDF1d3bdzokQkmjdvHszNzTFq1Cix7b///sPIkSOxbNkypaUJ3333Hfbs2aN0gZhCoYCGhgYcHR2xcOHCdxo7Eb0/srOzMWjQIKSnp8PQ0LDYvuWaqb158yZcXFwKtMtkMr4lTEouX76MEydOYMeOHQBeXUzSv39/xMTEwMfHB5cvX0bLli2V9mnVqpXS4+TkZFy7dg2bNm0S2wRBgEKhwM2bN+Ho6FjguKGhoZg8ebL4OCMjA5aWllhwRgO5Us0C/an0ZBoCItwUmHNKAzkK9VwH+r6oCrn8O8y3QFtOTg7Gjh2Lnj17ws/PT2zPv1CsXbt2cHZ2FttdXV0LTIa4urpi6dKl6N69O2xtbUuMQy6XIzExEZ07d4ZUKi3fyRAA5lKVmMuKy3+ntTTKVdTa2tri7NmzsLa2Vmr/9ddf0aRJk/IMSVXUunXrkJubi3r16oltgiBAKpXiyZMnEAShwO173nzzQKFQYOTIkRg/fnyB8Yu64Ewmk0EmkxVoz1FIkKumF+S8b3IUErW9uOl9o865zL9w2N/fH1ZWVrh//z4WLFiAjIwMBAUFQSqV4vHjx7h16xbu3bsHALhx4wakUinMzMxgZmYGS0tL8QN9Xmdra4vGjRuXOR4WD6rBXKoOc1l+ZclbuYraadOmYezYsXjx4gUEQcCJEyfwww8/ICoqCt999115hqQqKDc3Fxs2bEB0dDS6dOmitO2jjz7Cpk2b4ODggISEBKVtp06dUnrs6uqKCxcuqOQeyP8L7QQTE5MKj1OdyeVyJCQk4O8wXz5JV1BVyeWdO3cwcOBAPHz4EHXq1EHr1q1x/PhxceJj586dGDZsmNh/wIABAF4tUQgLC6uMkImoCipXUTts2DDk5uZi+vTp4lqHevXq4YsvvhCfrIh2796NJ0+eIDg4GEZGRkrb+vbti3Xr1mHHjh1YtmwZZsyYgeDgYJw9e1a8O0L+DO6MGTPQunVrjB07FsOHD4eenh4uXryIxMRErFy58l2fFhG9YcuWLcVuDwwMRGBgYJnGLMflHkRUzZX5ll65ublYv349/P398e+//+L+/ftIS0vD7du3ERwc/DZiJDW1bt06+Pj4FChogVcztWfPnsWTJ0+wbds27NixA05OTlizZg1mzZoFAOLyAScnJ/z++++4evUq2rdvDxcXF8yZM4c3ZyciIiJRmWdqtbS0MHr0aFy8eBEAULt2bZUHRVXDrl27itzm6uoqzsS4urriww8/FLctXLgQ9evXV7qrQcuWLfHbb7+9vWCJiIhIrZVr+YG7uzvOnDlT4EIxovJYvXo1WrZsCRMTExw9ehRLlixBSEhIZYdFREREaqRcRe2YMWMwZcoU3LlzBy1atICenvLHjjo5OakkOKoerl69igULFuDx48ewsrLClClTEBoaWtlhERERkRopV1Hbv39/AFC6xZJEIhFvz5T/CWNEpbF8+XIsX768ssMgIiIiNVbuD18gIiIiInpflKuo5VpaIiIiInqflKuo3bBhQ7HbhwwZUq5giIiIiIjKo1xF7YQJE5Qey+VyZGdno0aNGtDV1WVRS0RERETvVJk/fAEAnjx5ovSVmZmJy5cvo127dvjhhx9UHSMRERERUbHKVdQWplGjRli0aFGBWVwiIiIiordNZUUtAGhqauLevXuqHJKIiIiIqETlWlO7c+dOpceCICA1NRWrVq1C27ZtVRIYEREREVFplauo7dWrl9JjiUSCOnXqoGPHjoiOjlZFXEREREREpVauolahUKg6DiIiIiKicivXmtr58+cjOzu7QPvz588xf/78CgdFRERERFQW5Spqw8PDkZmZWaA9Ozsb4eHhFQ6KiIiIiKgsylXUCoIAiURSoP3cuXMwNjaucFBERERERGVRpjW1tWrVgkQigUQiQePGjZUK27y8PGRmZmLUqFEqD5KIiIiIqDhlKmpXrFgBQRAQFBSE8PBwGBkZidtq1KgBGxsbtGnTRuVBEhEREREVp0xF7dChQwEAtra28PDwgFQqfStBERERERGVRblu6eXp6Sl+//z5c8jlcqXthoaGFYuKiIiIiKgMynWhWHZ2NkJCQmBqagp9fX3UqlVL6YuIiIiI6F0qV1E7bdo0JCUlYfXq1ZDJZPjuu+8QHh4OCwsLbNiwQdUxEpGK/PHHH/D394eFhQUkEgni4+OVtgcGBooXg+Z/tW7dWqnPd999h1mzZsHExAQSiQRPnz59dydARERUhHIVtbt27cLq1avRt29faGlpoX379pg9ezYiIyOxadMmVcdIRbCxscGKFSuK3J6SkgKJRIKzZ8+WarzAwMACH4FMVUtWVhaaN2+OVatWFdmna9euSE1NFb8SEhKUtmdnZ8PV1RUzZsx42+ESERGVWrnW1D5+/Bi2trYAXq2fffz4MQCgXbt2GD16tOqiq8L8/f3x/Plz7N+/v8C2P//8Ex4eHkhOToarq2u5j2FpaYnU1FTUrl27IqFWWJcuXXDgwAEcPXq0wKzfu+YedQC5WnqVGkNlSFnUHQDQrVs3dOvWrdi+MpkMZmZmRW4fP348EhISoKdX/fJIRETvr3LN1NrZ2SElJQUA0KRJE/z4448AXs3g1qxZU1WxVWnBwcFISkrCv//+W2BbTEwMnJ2dK1TQAoCmpibMzMygpVWu1y4qcevWLfz5558ICQnBunXrKi0OKr1Dhw7B1NQUjRs3xvDhw3H//v3KDomIiKhE5Spqhw0bhnPnzgEAQkNDxbW1kyZNwrRp01QaYFXVo0cPmJqaIi4uTqk9OzsbW7duRXBwMI4dO4YOHTpAR0cHlpaWGD9+PLKysgr0DwoKgoGBAaysrLB27VpxW2HLDy5cuIDu3bvD0NAQBgYGaN++Pa5fv15ojIIgYPHixbCzs4OOjg6aN2+Obdu2lek8Y2Nj0aNHD4wePRpbt24tEP+zZ88QEBAAPT09mJubY/ny5fDy8sLEiRPFPi9fvsT06dNRr1496Onpwd3dHYcOHSpTHFQ63bp1w6ZNm5CUlITo6GicPHkSHTt2RE5OTmWHRkREVKxyTeFNmjRJ/N7b2xuXLl3CqVOn0KBBAzRv3lxlwVVlWlpaGDJkCOLi4jB37lzx09l++uknvHz5Es2bN4evry8iIiKwbt06PHjwACEhIQgJCUFsbKw4TnR0NCIiIjBz5kxs27YNo0ePRocOHeDg4FDgmHfv3kWHDh3g5eWFpKQkGBoa4ujRo8jNzS00xtmzZ2PHjh1Ys2YNGjVqhD/++AOffPIJ6tSpo3Rbt6IIgoDY2Fh89dVXcHBwQOPGjfHjjz9i2LBhYp/Jkyfj6NGj2LlzJ+rWrYu5c+fi9OnTcHZ2FvsMGzYMKSkp2LJlCywsLPDzzz+ja9euOH/+PBo1alTosXNycpQKsYyMDACATEOApqZQYuxVzZu33cuXm5urtK1Pnz7i9/b29mjevDkaNmyIX375Bb1791YaK//3Ri6XFzk+FS8/b8xfxTGXqsNcqg5zWXFlyZ1EEIQK/YV/8eIFtLW1KzJEtXXp0iU4OjoiKSkJ3t7eAF7dA7hevXrQ0tKCjo4OvvnmG7H/kSNH4OnpiaysLGhra8PGxgbt27fHxo0bAbwqIs3MzBAeHo5Ro0YhJSUFtra2OHPmDJydnTFz5kxs2bIFly9fLvSDMwIDA/H06VPEx8cjKysLtWvXRlJSktKnxH366afIzs7G5s2bSzy/xMREBAQE4N69e9DS0sKKFSuwbds2HDlyBMCrWVoTExNs3rwZffv2BQCkp6fDwsICw4cPx4oVK3D9+nU0atQId+7cgYWFhTi2j48PWrVqhcjIyEKPHRYWhvDw8ALtmzdvhq6ubomxVwe9evXCZ599VuI659GjR6Nz585KBS8AnD9/HnPmzMH3338PfX39txkqERFVU9nZ2Rg0aBDS09NL/ByEcs3U5uXlITIyEl9//TX+++8/XLlyBXZ2dpgzZw5sbGwQHBxcrsCrGwcHB3h4eCAmJgbe3t64fv06Dh8+jN9++w0TJkzAtWvXlO4mIQgCFAoFbt68CUdHRwCAk5OTuF0ikcDMzKzINZBnz55F+/btS/VJcP/88w9evHiBzp07K7W/fPkSLi4upTq/devWoX///uKa3oEDB2LatGm4fPky7O3tcePGDcjlcrRq1Urcx8jICPb29uLj06dPQxAENG7cWGnsnJwcmJiYFHns0NBQTJ48WXyckZEBS0tLLDijgVypZqnir0r+DvMttL1Fixbw8/Mrcr9Hjx7h8ePH8PT0FPvJ5XIkJibCzc0NwKsLAbmWvnzyc9m5c2d+QmMFMZeqw1yqDnNZcfnvtJZGuYrahQsXYv369Vi8eDGGDx8utjdr1gzLly9nUVsGwcHBCAkJwVdffYXY2FhYW1ujU6dOUCgUGDlyJMaPH19gHysrK/H7N/+TSCQSKBSKQo+lo6NT6rjyx9izZw/q1auntE0mk5W4/+PHjxEfHw+5XI41a9aI7Xl5eYiJicHnn3+O/DcJ8pde5Hv9zQOFQgFNTU0kJydDU1O5GC1udlAmkxUaZ45Cgtw8SSF7VG35vyeZmZm4du2a2H779m1cuHABxsbGMDY2RlhYGD766COYm5sjJSUFM2fORO3atfHxxx+LY6SlpeHGjRvijPelS5fENd3Gxsbv/uSqAKlUyj94KsJcqg5zqTrMZfmVJW/lKmo3bNiAtWvXolOnThg1apTY7uTkhEuXLpVnyGqrX79+mDBhAjZv3oz169dj+PDhkEgkcHV1xYULF9CwYUOVHcvJyQnr16+HXC4v8ZekSZMmkMlkuHXrVqnWz75p06ZNqF+/foGb+x84cABRUVFYuHAhGjRoAKlUihMnTsDS0hLAq1dkV69eFY/p4uKCvLw83L9/H+3bty9zHG/6X2inYmd4q7pTp06JS10AiLPZQ4cOxZo1a3D+/Hls2LABT58+hbm5Oby9vbF161YYGBiI+6xduxYLFiwQH3fo0AHAq4sCAwMD382JEBERvaFcRe3du3cLLbYUCgUXQ5eRvr4++vfvj5kzZyI9PV0sCmbMmIHWrVtj7NixGD58OPT09HDx4kUkJiZi5cqV5TpWSEgIVq5ciQEDBiA0NBRGRkY4fvw4WrVqpfSWPwAYGBhg6tSpmDRpEhQKBdq1a4eMjAwcO3YM+vr6GDp0aLHHWrduHfr27YsPPvhAqd3a2hozZszAnj170LNnTwwdOhTTpk2DsbExTE1NMW/ePGhoaIizt40bN0ZAQACGDBmC6OhouLi44OHDh0hKSkKzZs2KfeucCvLy8kJxy+j37dtX4hhz586Fm5sb/Pz8OPNARETvjXLd0qtp06Y4fPhwgfaffvqp1Ost6f8FBwfjyZMn8PHxEZcWODk54ffff8fVq1fRvn17uLi4YM6cOTA3Ny/3cUxMTJCUlITMzEx4enqiRYsW+Pbbb4ssTCIiIjB37lxERUXB0dERvr6+2LVrl/jBG0VJTk7GuXPn8NFHHxXYZmBggC5duoj3rF22bBnatGmDHj16wMfHB23btoWjo6PSxYexsbEYMmQIpkyZAnt7e3z44Yf43//+J87uEhEREZXr7ge7du3C4MGDERoaivnz5yM8PByXL1/Ghg0bsHv37gIXFxGVVlZWFurVq4fo6GiVrs3OyMiAkZERHj58WK2XH6iCXC5HQkICZ2pVgLlUHeZSdZhL1WEuKy7/73dp7n5QppnaGzduQBAE+Pv7Y+vWrUhISIBEIsHcuXNx8eJF7Nq1iwUtlcmZM2fwww8/4Pr16zh9+jQCAgIAAD179qzkyIiIiEidlKmobdSoER48eAAA8PX1hZmZGa5du4bs7GwcOXIEXbp0eStB0vtn1KhR0NfXL/Tr9YsHS2Pp0qVo3rw5fHx8kJWVhcOHD6N27dpvKXIiIiKqisp0odibKxV+/fVXREVFqTQgUg/z58/H1KlTC91W0tsDr3NxcUFycrKqwiIiIqJqqlx3P8hXwQ8jIzVmamoKU1PTyg6DiIiICEAZlx9IJJICN8p/8zERERER0btW5uUHgYGB4ic1vXjxAqNGjYKenp5Svx07dqguQiIiIiKiEpSpqH3zhvuffPKJSoMhIiIiIiqPMhW1sbGxbysOIiIiIqJyK9cnihERERERvU9Y1BIRERGR2mNRS0RERERqj0UtEREREak9FrVEREREpPZY1BIRERGR2mNRS0RERERqj0UtEREREak9FrVEREREpPZY1BIRERGR2mNRS0RERERqj0UtEREREak9FrVEREREpPZY1FaAjY0NVqxYUeT2lJQUSCQSnD17tlTjBQYGolevXiqJjaq+P/74A/7+/rCwsIBEIkF8fLy4TS6XY8aMGWjWrBn09PRgYWGBIUOG4N69e0pj5OTkYNy4cahduzb09PTw4Ycf4s6dO+/4TIiIiCqu2ha1/v7+8PHxKXTbn3/+CYlEgtOnT1foGJaWlkhNTcUHH3xQoXHKI7+gzv8yMDBA06ZNMXbsWFy9evWdx0Oql5WVhebNm2PVqlUFtmVnZ+P06dOYM2cOTp8+jR07duDKlSv48MMPlfpNnDgRP//8M7Zs2YIjR44gMzMTPXr0QF5e3rs6DSIiIpXQquwAKktwcDD69OmDf//9F9bW1krbYmJi4OzsDFdX1wodQ1NTE2ZmZhUao6L279+Ppk2bIjs7G+fPn8cXX3yB5s2bY9euXejUqVOlxlYZ3KMOIFdLr7LDqJCURd0BAN26dUO3bt0K7WNkZITExESltpUrV6JVq1a4desWrKyskJ6ejnXr1mHjxo3iC7zvv/8elpaW2L9/P3x9fd/uiRAREalQtZ2p7dGjB0xNTREXF6fUnp2dja1btyI4OBjHjh1Dhw4doKOjA0tLS4wfPx5ZWVkF+gcFBcHAwABWVlZYu3atuK2w5QcXLlxA9+7dYWhoCAMDA7Rv3x7Xr18vNEZBELB48WLY2dlBR0cHzZs3x7Zt28p0niYmJjAzM4OdnR169uyJ/fv3w93dHcHBweJs3PXr19GzZ0/UrVsX+vr6aNmyJfbv3680jo2NDRYsWIAhQ4ZAX18f1tbW+OWXX/DgwQP07NkT+vr6aNasGU6dOiXu8+jRIwwcOBD169eHrq4umjVrhh9++EFp3GfPniEgIAB6enowNzfH8uXL4eXlhYkTJ4p9Xr58ienTp6NevXrQ09ODu7s7Dh06VKY8EJCeng6JRIKaNWsCAJKTkyGXy9GlSxexj4WFBT744AMcO3askqIkIiIqn2o7U6ulpYUhQ4YgLi4Oc+fOhUQiAQD89NNPePnyJZo3bw5fX19ERERg3bp1ePDgAUJCQhASEoLY2FhxnOjoaERERGDmzJnYtm0bRo8ejQ4dOsDBwaHAMe/evYsOHTrAy8sLSUlJMDQ0xNGjR5Gbm1tojLNnz8aOHTuwZs0aNGrUCH/88Qc++eQT1KlTB56enuU6bw0NDUyYMAG9e/dGcnIyWrVqhczMTPj5+WHBggXQ1tbG+vXr4e/vj8uXL8PKykrcd/ny5YiMjMScOXOwfPlyDB48GG3btkVQUBCWLFmCGTNmYMiQIbhw4QIkEglevHiBFi1aYMaMGTA0NMSePXswePBg2NnZwd3dHQAwefJkHD16FDt37kTdunUxd+5cnD59Gs7OzuJxhw0bhpSUFGzZsgUWFhb4+eef0bVrV5w/fx6NGjUq9DxzcnKQk5MjPs7IyAAAyDQEaGoK5crd+0IulxfanpubW+S2Fy9eYMaMGRgwYAB0dHQgl8tx584d1KhRA/r6+kr7mZqa4t69e0WOld9e1HYqPeZSdZhL1WEuVYe5rLiy5E4iCIJ6/4WvgEuXLsHR0RFJSUnw9vYGAHh6eqJevXrQ0tKCjo4OvvnmG7H/kSNH4OnpiaysLGhra8PGxgbt27fHxo0bAbyaWTUzM0N4eDhGjRqFlJQU2Nra4syZM3B2dsbMmTOxZcsWXL58GVKptEA8gYGBePr0KeLj45GVlYXatWsjKSkJbdq0Eft8+umnyM7OxubNm4s9tzePXdh5b926Ff369St0/6ZNm2L06NEICQkBgALnmpaWBnNzc8yZMwfz588HABw/fhxt2rRBampqkcsuunfvDkdHRyxduhTPnj2DiYkJNm/ejL59+wJ4NZtoYWGB4cOHY8WKFbh+/ToaNWqEO3fuwMLCQhzHx8cHrVq1QmRkZKHHCQsLQ3h4eIH2zZs3Q1dXt5jMqadevXrhs88+Q+vWrQtsy83NxeLFi/Hw4UMsWLBAPP/ff/8dK1euLDD7P2/ePJiZmWH06NHvJHYiIqKiZGdnY9CgQUhPT4ehoWGxfavtTC0AODg4wMPDAzExMfD29sb169dx+PBh/Pbbb5gwYQKuXbuGTZs2if0FQYBCocDNmzfh6OgIAHBychK3SyQSmJmZ4f79+4Ue7+zZs2jfvn2hBe2b/vnnH7x48QKdO3dWan/58iVcXFzKc7qi/Ncx+bPTWVlZCA8Px+7du3Hv3j3k5ubi+fPnuHXrltJ+r59r3bp1AQDNmjUr0Hb//n2YmZkhLy8PixYtwtatW3H37l1x9lRP79Wa1hs3bkAul6NVq1biGEZGRrC3txcfnz59GoIgoHHjxkqx5OTkwMTEpMhzDA0NxeTJk8XHGRkZsLS0xIIzGsiVapYiS++vv8MKX+vaokUL+Pn5KbXJ5XIMHDgQz58/x9GjR5VypqOjg+XLl6NNmzaoVauW2D5nzhy4ubkVGOv1MRMTE9G5c+dS/S5T0ZhL1WEuVYe5VB3msuLy32ktjWpd1AKvLhgLCQnBV199hdjYWFhbW6NTp05QKBQYOXIkxo8fX2Cf19+Sf/OXVCKRQKFQFHosHR2dUseVP8aePXtQr149pW0ymazU4xTm4sWLAABbW1sAwLRp07Bv3z4sXboUDRs2hI6ODvr27YuXL18q7ff6ueYXxIW15cceHR2N5cuXY8WKFeKtpSZOnCiO+2Zxne/1Nw8UCgU0NTWRnJwMTU3lYlRfX7/Ic5TJZIXmKUchQW6epJA91EdRT4xaWlpK2+RyOQICAnD9+nUcPHgQderUUerv7u4OqVSKQ4cOiTP2qampuHDhApYsWVLiE7BUKuWTtIowl6rDXKoOc6k6zGX5lSVv1b6o7devHyZMmIDNmzdj/fr1GD58OCQSCVxdXXHhwgU0bNhQZcdycnLC+vXrIZfLS/whNWnSBDKZDLdu3Sr3+tnCKBQKfPnll7C1tRVnfA8fPozAwED07t0bAJCZmYmUlJQKH+vw4cPo2bMnPvnkE/HYV69eFWe5GzRoAKlUihMnTsDS0hLAq1dkV69eFc/ZxcUFeXl5uH//Ptq3b1/hmKqSzMxMXLt2TXx88+ZNnD17FsbGxrCwsEDfvn1x+vRp7N69G3l5eUhLSwMAGBsbo0aNGjAyMkJwcDCmTJkCExMTGBsbY+rUqWjWrFmRt7sjIiJ6X1X7olZfXx/9+/fHzJkzkZ6ejsDAQADAjBkz0Lp1a4wdOxbDhw+Hnp4eLl68iMTERKxcubJcxwoJCcHKlSsxYMAAhIaGwsjICMePH0erVq2U3nIHAAMDA0ydOhWTJk2CQqFAu3btkJGRgWPHjkFfXx9Dhw4t1TEfPXqEtLQ0ZGdn4++//8aKFStw4sQJ7NmzR5z5bNiwIXbs2AF/f39IJBLMmTOnyNnmsmjYsCG2b9+OY8eOoVatWli2bBnS0tLEotbAwABDhw7FtGnTYGxsDFNTU8ybNw8aGhri7G3jxo0REBCAIUOGIDo6Gi4uLnj48CGSkpLQrFmzIt8iL8r/QjsVu2xBnZw6dUpcCw5AXG4xdOhQhIWFYefOnQBQYE31wYMH4eXlBeDVxX9aWlro168fnj9/jk6dOiEuLq7ArDgREdH7rtoXtcCrJQjr1q1Dly5dxKUFTk5O+P333zFr1iy0b98egiCgQYMG6N+/f7mPY2JigqSkJEybNg2enp7Q1NSEs7Mz2rZtW2j/iIgImJqaIioqCjdu3EDNmjXh6uqKmTNnlvqY+TNuurq6sLa2hre3N9auXas0A718+XIEBQXBw8MDtWvXxowZM8q0hqUoc+bMwc2bN+Hr6wtdXV2MGDECvXr1Qnp6uthn2bJlGDVqFHr06AFDQ0NMnz4dt2/fhra2ttgnNjYWCxYswJQpU3D37l2YmJigTZs2ZS5oqxovLy8Ud51naa4B1dbWxsqVK8v9Qo2IiOh9Ua3vfkDvn6ysLNSrVw/R0dEIDg5W2bgZGRkwMjLCw4cPq8xMbWWRy+VISEiAn58f14hVEHOpOsyl6jCXqsNcVlz+32/e/YDee2fOnMGlS5fQqlUrpKeni7cH69mzZyVHRkREROqk2n6imLobNWoU9PX1C/0aNWpUZYdXJkuXLkXz5s3h4+ODrKwsHD58GLVr167ssIiIiEiNcKZWTc2fPx9Tp04tdFtJ0/PvExcXFyQnJ1d2GERERKTmWNSqKVNTU5iamlZ2GERERETvBS4/ICIiIiK1x6KWiIiIiNQei1oiIiIiUnssaomIiIhI7bGoJSIiIiK1x6KWiIiIiNQei1oiIiIiUnssaomIiIhI7bGoJSIiIiK1x6KWiIiIiNQei1oiIiIiUnssaomIiIhI7bGoJSIiIiK1x6KWiIiIiNQei1oiIiIiUnssaomIiIhI7bGoJSIiIiK1x6KWqIKioqIgkUgwceJEsU0QBISFhcHCwgI6Ojrw8vLChQsXKi9IIiKiKo5FbQUcOnQIEokET58+fWfHlEgkiI+Pf2fHe19VRu4Lc/LkSaxduxZOTk5K7YsXL8ayZcuwatUqnDx5EmZmZujcuTOePXtWSZESERFVbVWmqA0MDIREIoFEIoFUKoWdnR2mTp2KrKyst3ZMDw8PpKamwsjI6K0d423y8vJSml2kssnMzERAQAC+/fZb1KpVS2wXBAErVqzArFmz0KdPH3zwwQdYv349srOzsXnz5kqMmIiIqOrSquwAVKlr166IjY2FXC7H4cOH8emnnyIrKwtr1qxR6ieXyyGVSit8vBo1asDMzKzC41RXgiAgLy8PWlrv7tfQPeoAcrX0yr1/yqLu4vdjx45F9+7d4ePjgwULFojtN2/eRFpaGrp06SK2yWQyeHp64tixYxg5cmS5j09ERESFqzIztcCrwsHMzAyWlpYYNGgQAgICEB8fj7CwMDg7OyMmJgZ2dnaQyWQQBAHp6ekYMWIETE1NYWhoiI4dO+LcuXMAgMuXL0MikeDSpUtKx1i2bBlsbGwgCEKhb4Fv374dTZs2hUwmg42NDaKjo5X2L2z5QM2aNREXFwcAePnyJUJCQmBubg5tbW3Y2NggKiqq0PPt2LEjQkJClNoePXoEmUyGpKSkMufPxsYGkZGRCAoKgoGBAaysrLB27Vpxe3GxpaSkQCKR4OzZs2L/p0+fQiKR4NChQwD+f8nAvn374ObmBplMhsOHD0MQBCxevBh2dnbQ0dFB8+bNsW3bNqXYEhIS0LhxY+jo6MDb2xspKSllPj9V2rJlC5KTkwv92aSlpQEA6tatq9Ret25dcRsRERGpVpWaqX2Tjo4O5HI5AODatWv48ccfsX37dmhqagIAunfvDmNjYyQkJMDIyAjffPMNOnXqhCtXrsDe3h4tWrTApk2bEBERIY65efNmDBo0CBKJpMDxkpOT0a9fP4SFhaF///44duwYxowZAxMTEwQGBpYq5i+//BI7d+7Ejz/+CCsrK9y+fRu3b98utO+nn36KkJAQREdHQyaTAQA2bdoECwsLeHt7lyVVoujoaERERGDmzJnYtm0bRo8ejQ4dOsDBwaFMsRVn+vTpWLp0Kezs7FCzZk3Mnj0bO3bswJo1a9CoUSP88ccf+OSTT1CnTh14enri9u3b6NOnD0aNGoXRo0fj1KlTmDJlSrHHyMnJQU5Ojvg4IyMDACDTEKCpKZQ55nxyuRy3b9/GhAkTsGfPHmhqakIul0MQBCgUCsjlcuTm5gIAcnNzxd8/AMjLyxPHUGf58av7ebwPmEvVYS5Vh7lUHeay4sqSuypb1J44cQKbN29Gp06dALyaZdy4cSPq1KkDAEhKSsL58+dx//59sSBcunQp4uPjsW3bNowYMQIBAQFYtWqVWNReuXIFycnJ2LBhQ6HHXLZsGTp16oQ5c+YAABo3box//vkHS5YsKXVRe+vWLTRq1Ajt2rWDRCKBtbV1kX0/+ugjjBs3Dr/88gv69esHAIiNjRXXF5eHn58fxowZAwCYMWMGli9fjkOHDsHBwaFMsRVn/vz56Ny5MwAgKysLy5YtQ1JSEtq0aQMAsLOzw5EjR/DNN9/A09MTa9asgZ2dHZYvXw6JRAJ7e3ucP38en3/+eZHHiIqKQnh4eIH22S4K6OrmlStu4NWM8fHjx3H//n24u7uL7QqFAocPH8ZXX32Fr776CsCrWXs7Ozuxz99//w09PT0kJCSU+/jvk8TExMoOocpgLlWHuVQd5lJ1mMvyy87OLnXfKlXU7t69G/r6+uIMWc+ePbFy5UqsXr0a1tbWYkELvJpVzczMhImJidIYz58/x/Xr1wEAAwYMwLRp03D8+HG0bt0amzZtgrOzM5o0aVLo8S9evIiePXsqtbVt2xYrVqxAXl6eOENcnMDAQHTu3Bn29vbo2rUrevToobQ283UymQyffPIJYmJi0K9fP5w9exbnzp2r0N0RXr+KXyKRwMzMDPfv3y9zbMVxc3MTv//nn3/w4sULscjN9/LlS7i4uAB4ldfWrVsrFer5BXBRQkNDMXnyZPFxRkYGLC0tseCMBnKlJf8civJ3mC/at28vvojIN3z4cNjb22Pq1Klo2rQpwsPD8eLFC/j5+YnnM3ToUERGRopt6koulyMxMRGdO3dWydr06oy5VB3mUnWYS9VhLisu/53W0qhSRa23tzfWrFkDqVQKCwsLpV8gPT3li4MUCgXMzc3F9Z6vq1mzJgDA3Nwc3t7e2Lx5M1q3bo0ffvih2It8BEEoMEMqCMpvdUskkgJtr0+tu7q64ubNm/j111+xf/9+9OvXDz4+PgXWmOb79NNP4ezsjDt37iAmJgadOnUq9wwqgAL/6SQSCRQKRYmxaWhoFDjfot4yeP1nkT/2nj17UK9ePaV++TPob+arNGQymbj/63IUEuTmlW8WG3iVH2NjYxgbGyu16+vro06dOmIhPnHiRERFRcHBwQGNGjVCZGQkdHV1MXjw4CrzxCaVSqvMuVQ25lJ1mEvVYS5Vh7ksv7LkrUoVtXp6emjYsGGp+rq6uiItLQ1aWlqwsbEpsl9AQABmzJiBgQMH4vr16xgwYECRfZs0aYIjR44otR07dgyNGzcWZ2nr1KmD1NRUcfvVq1cLTK0bGhqif//+6N+/P/r27YuuXbvi8ePHBQopAGjWrBnc3Nzw7bffYvPmzVi5cmVpTr/ciootfxY8NTVVLOxev2isKE2aNIFMJsOtW7fg6elZZJ83Z5+PHz9ervj/F9qpwOz82zB9+nQ8f/4cY8aMwZMnT+Du7o7ffvsNBgYGb/3YRERE1VGVKmrLwsfHB23atEGvXr3w+eefw97eHvfu3UNCQgJ69eolvkXep08fjB49GqNHj4a3t3eB2cTXTZkyBS1btkRERAT69++PP//8E6tWrcLq1avFPh07dsSqVavQunVrKBQKzJgxQ+lVyPLly2Fubg5nZ2doaGjgp59+gpmZmTh7XJj8C8Z0dXXRu3fviienCMXFpqGhgdatW2PRokWwsbHBw4cPMXv27BLHNDAwwNSpUzFp0iQoFAq0a9cOGRkZOHbsGPT19TF06FCMGjUK0dHRmDx5MkaOHInk5GTxbhHvizdn/CUSCcLCwhAWFlYp8RAREVU3VeqWXmUhkUiQkJCADh06ICgoCI0bN8aAAQOQkpKidCsmQ0ND+Pv749y5cwgICCh2TFdXV/z444/YsmULPvjgA8ydOxfz589XukgsOjoalpaW6NChAwYNGoSpU6dCV1dX3K6vr4/PP/8cbm5uaNmyJVJSUpCQkCC+vV+YgQMHQktLC4MGDYK2tnb5k1KCkmKLiYmBXC6Hm5sbJkyYoHTv1uJERERg7ty5iIqKgqOjI3x9fbFr1y7Y2toCAKysrLB9+3bs2rULzZs3x9dff43IyMi3dp5ERESkfiRCeRYs0nvl9u3bsLGxwcmTJ+Hq6lrZ4byXMjIyYGRkhIcPH76T5QdVmVwuR0JCAvz8/LhGrIKYS9VhLlWHuVQd5rLi8v9+p6enw9DQsNi+1Xb5QVUgl8uRmpqKzz77DK1bt2ZBS0RERNVWtV1+UBUcPXoU1tbWSE5Oxtdff6207fDhw9DX1y/yi4iIiKgq4UytGvPy8irydldubm6luvsAERERUVXAoraK0tHRKfXtzYiIiIjUHZcfEBEREZHaY1FLRERERGqPRS0RERERqT0WtURERESk9ljUEhEREZHaY1FLRERERGqPRS0RERERqT0WtURERESk9ljUEhEREZHaY1FLRERERGqPRS0RERERqT0WtURERESk9ljUEhEREZHaY1FLRERERGqPRS0RERERqT0WtURERESk9ljUEhEREZHaY1FLlcrLywsTJ06s7DDKZM2aNXBycoKhoSEMDQ3Rpk0b/Prrr+L2//77D4GBgbCwsICuri66du2Kq1evVmLEREREVR+LWkJaWhomTJiAhg0bQltbG3Xr1kW7du3w9ddfIzs7u7LDe+/Ur18fixYtwqlTp3Dq1Cl07NgRPXv2xIULFyAIAnr16oUbN27gl19+wZkzZ2BtbQ0fHx9kZWVVduhERERVllZlB0CV68aNG2jbti1q1qyJyMhINGvWDLm5ubhy5QpiYmJgYWGBDz/8sLLDLFJeXh4kEgk0NEr3+sw96gBytfTKdayURd0BAP7+/krtCxcuxJo1a3D8+HFIpVIcP34cf//9N5o2bQoAWL16NUxNTfHDDz/g008/LdexiYiIqHicqa3mxowZAy0tLZw6dQr9+vWDo6MjmjVrho8++gh79uwRC7j09HSMGDECpqamMDQ0RMeOHXHu3DlxnLCwMDg7O2Pjxo2wsbGBkZERBgwYgGfPnol9srKyMGTIEOjr68Pc3BzR0dEF4nn58iWmT5+OevXqQU9PD+7u7jh06JC4PS4uDjVr1sTu3bvRpEkTyGQy/Pvvv28vQSXIy8vDli1bkJWVhTZt2iAnJwcAoK2tLfbR1NREjRo1cOTIkcoKk4iIqMpjUVuNPXr0CL/99hvGjh0LPb3CZy8lEgkEQUD37t2RlpaGhIQEJCcnw9XVFZ06dcLjx4/FvtevX0d8fDx2796N3bt34/fff8eiRYvE7dOmTcPBgwfx888/47fffsOhQ4eQnJysdLxhw4bh6NGj2LJlC/766y98/PHHBdakZmdnIyoqCt999x0uXLgAU1NTFWemZOfPn4e+vj5kMhlGjRqFn3/+GU2aNIGDgwOsra0RGhqKJ0+e4OXLl1i0aBHS0tKQmpr6zuMkIiKqLrj8oBq7du0aBEGAvb29Unvt2rXx4sULAMDYsWPh6+uL8+fP4/79+5DJZACApUuXIj4+Htu2bcOIESMAAAqFAnFxcTAwMAAADB48GAcOHMDChQuRmZmJdevWYcOGDejcuTMAYP369ahfv7543OvXr+OHH37AnTt3YGFhAQCYOnUq9u7di9jYWERGRgIA5HI5Vq9ejebNmxd5bjk5OeKsKQBkZGQAAGQaAjQ1hXLlSy6Xi9/b2dnh5MmTSE9Px44dOzB06FDs378fTZo0wdatWzFixAgYGxtDU1MTnTp1QteuXQuMoa7yz6EqnEtlYy5Vh7lUHeZSdZjLiitL7ljUEiQSidLjEydOQKFQICAgADk5OUhOTkZmZiZMTEyU+j1//hzXr18XH9vY2IgFLQCYm5vj/v37AF4VrC9fvkSbNm3E7cbGxkoF9enTpyEIAho3bqx0nJycHKVj16hRA05OTsWeU1RUFMLDwwu0z3ZRQFc3r9h9i5KQkFBoe9u2bbFv3z5Mnz4dY8aMAQDMnz8fWVlZyM3NhZGREaZNm4aGDRsWOYY6SkxMrOwQqgzmUnWYS9VhLlWHuSy/slywzqK2GmvYsCEkEgkuXbqk1G5nZwcA0NHRAfBqBtbc3FxpbWu+mjVrit9LpVKlbRKJBAqFAgAgCCXPjioUCmhqaiI5ORmamppK2/T19cXvdXR0ChTibwoNDcXkyZPFxxkZGbC0tMSCMxrIlWoWs2fR/g7zLXLbF198gbp168LPz6/AtqtXr+L69etYsWKFOEutzuRyORITE9G5c+cCP3MqG+ZSdZhL1WEuVYe5rLj8d1pLg0VtNWZiYoLOnTtj1apVGDduXJHral1dXZGWlgYtLS3Y2NiU61gNGzYU7wxgZWUFAHjy5AmuXLkCT09PAICLiwvy8vJw//59tG/fvlzHySeTycSlEq/LUUiQm1d8QVyU/CekmTNnolu3brC0tMSzZ8+wZcsW/P7779i7dy+kUil++ukn1KlTB1ZWVjh//jwmTJiAXr16FVrwqjOpVMonaRVhLlWHuVQd5lJ1mMvyK0veWNRWc6tXr0bbtm3h5uaGsLAwODk5QUNDAydPnsSlS5fQokUL+Pj4oE2bNujVqxc+//xz2Nvb4969e0hISECvXr3g5uZW4nH09fURHByMadOmwcTEBHXr1sWsWbOUbsXVuHFjBAQEYMiQIYiOjoaLiwsePnyIpKQkNGvWTCVF4f9COxVYRlFW//33HwYPHozU1FQYGRnByckJe/fuFWdhU1NTMXnyZPz3338wNzfHkCFDMGfOnArHTkREREVjUVvNNWjQAGfOnEFkZCRCQ0Nx584dyGQyNGnSBFOnTsWYMWMgkUiQkJCAWbNmISgoCA8ePICZmRk6dOiAunXrlvpYS5YsQWZmJj788EMYGBhgypQpSE9PV+oTGxuLBQsWYMqUKbh79y5MTEzQpk2b92qWc926dcVuHz9+PMaPH/+OoiEiIiIAkAilWexIpOYyMjJgZGSEhw8fVnimtrqTy+VISEiAn58f306rIOZSdZhL1WEuVYe5rLj8v9/p6ekwNDQsti/vU0tEREREao9FLRERERGpPRa1RERERKT2WNQSERERkdpjUUtEREREao9FLRERERGpPRa1RERERKT2WNQSERERkdpjUUtEREREao9FLRERERGpPRa1RERERKT2WNQSERERkdpjUUtEREREao9FLRERERGpPRa1RERERKT2WNQSERERkdpjUUtEREREao9FLRERERGpPRa1RERERKT2WNQSERERkdpjUUtEREREao9FLRGAP/74A/7+/rCwsIBEIkF8fLzS9h07dsDX1xe1a9eGRCLB2bNnKyVOIiIiKhyL2rfg0KFDkEgkePr0aan6p6SkvHeFko2NDVasWFHZYbwzWVlZaN68OVatWlXk9rZt22LRokXvODIiIiIqDa3KDuB9FRgYiPXr1wMAtLS0YGxsDCcnJwwcOBCBgYHQ0Cj69YCHhwdSU1NhZGRUqmNZWloiNTUVtWvXVknspREWFob4+PgiC+mTJ09CT0/vncVT2bp164Zu3boVuX3w4MEAXr0AISIiovcPi9pidO3aFbGxscjLy8N///2HvXv3YsKECdi2bRt27twJLa2C6ZPL5ahRowbMzMxKfRxNTc0y9X8X6tSpU9khvBXuUQeQq/X/xXrKou6VGA0RERGpCpcfFEMmk8HMzAz16tWDq6srZs6ciV9++QW//vor4uLiAAASiQRff/01evbsCT09PSxYsEBp+UF6ejp0dHSwd+9epbF37NgBPT09ZGZmFlh+kL//gQMH4ObmBl1dXXh4eODy5ctKYyxYsACmpqYwMDDAp59+is8++wzOzs4qOfc3lx88ffoUI0aMQN26daGtrY0PPvgAu3fvFrcfO3YMHTp0gI6ODiwtLTF+/HhkZWUpjRcZGYmgoCAYGBjAysoKa9euFbe/fPkSISEhMDc3h7a2NmxsbBAVFSVuT09Px4gRI2BqagpDQ0N07NgR586dU8m5EhERkfrjTG0ZdezYEc2bN8eOHTvw6aefAgDmzZuHqKgoLF++HJqamrh586bY38jICN27d8emTZvQtWtXsX3z5s3o2bMn9PX18fDhw0KPNWvWLERHR6NOnToYNWoUgoKCcPToUQDApk2bsHDhQqxevRpt27bFli1bEB0dDVtbW5Wfs0KhQLdu3fDs2TN8//33aNCgAf755x9oamoCAM6fPw9fX19ERERg3bp1ePDgAUJCQhASEoLY2FhxnOjoaERERGDmzJnYtm0bRo8ejQ4dOsDBwQFffvkldu7ciR9//BFWVla4ffs2bt++DQAQBAHdu3eHsbExEhISYGRkhG+++QadOnXClStXYGxsXCDmnJwc5OTkiI8zMjIAADINAZqagtgul8sLPefc3NxCt+W3yeXyIvet6l7PAVUMc6k6zKXqMJeqw1xWXFlyx6K2HBwcHPDXX3+JjwcNGoSgoCDx8etFLQAEBARgyJAhyM7Ohq6uLjIyMrBnzx5s37692OMsXLgQnp6eAIDPPvsM3bt3x4sXL6CtrY2VK1ciODgYw4YNAwDMnTsXv/32GzIzM1V1mqL9+/fjxIkTuHjxIho3bgwAsLOzE7cvWbIEgwYNwsSJEwEAjRo1wpdffglPT0+sWbMG2traAAA/Pz+MGTMGADBjxgwsX74chw4dgoODA27duoVGjRqhXbt2kEgksLa2Fsc/ePAgzp8/j/v370MmkwEAli5divj4eGzbtg0jRowoEHNUVBTCw8MLtM92UUBXN098nJCQUOg5JycnQyqVFmj/77//AABHjhzBvXv3ik5aNZCYmFjZIVQZzKXqMJeqw1yqDnNZftnZ2aXuy6K2HARBgEQiER+7ubkV27979+7Q0tLCzp07MWDAAGzfvh0GBgbo0qVLsfs5OTmJ35ubmwMA7t+/DysrK1y+fFksEPO1atUKSUlJZT2dEp09exb169cXC9o3JScn49q1a9i0aZPYJggCFAoFbt68CUdHRwDK5yORSGBmZob79+8DeHVhXufOnWFvb4+uXbuiR48eYn6Sk5ORmZkJExMTpeM+f/4c169fLzSm0NBQTJ48WXyckZEBS0tLLDijgVypptj+d5hvofu3aNECfn5+BdrzLxRr166dypZ6qBu5XI7ExER07ty50MKfSo+5VB3mUnWYS9VhLisu/53W0mBRWw4XL15Uepu/pLsE1KhRA3379sXmzZsxYMAAbN68Gf379y/0QrPXvf4fIL+IVigUBdryCYKAt0FHR6fY7QqFAiNHjsT48eMLbLOyshK/f/M/tEQiEc/H1dUVN2/exK+//or9+/ejX79+8PHxwbZt26BQKGBubo5Dhw4VGL9mzZqFxiSTycRZ3dflKCTIzfv/vOXHlJmZiWvXrontt2/fxoULF2BsbAwrKys8fvwYt27dEmdnb9y4AalUCjMzs/fuIr93RSqV8klaRZhL1WEuVYe5VB3msvzKkjcWtWWUlJSE8+fPY9KkSWXaLyAgAF26dMGFCxdw8OBBREREVCgOe3t7nDhxQrzVFACcOnWqQmMWxcnJCXfu3MGVK1cKna11dXXFhQsX0LBhwwodx9DQEP3790f//v3Rt29fdO3aFY8fP4arqyvS0tKgpaUFGxubCh3jf6GdCsz4Aq9y5+3tLT7On+UdOnQo4uLisHPnTnGpBwAMGDAAwKv11GFhYRWKiYiIiCqORW0xcnJykJaWpnRLr6ioKPTo0QNDhgwp01ienp6oW7cuAgICYGNjg9atW1cotnHjxmH48OFwc3ODh4cHtm7dir/++ktprWtJnj9/XuA+tfr6+gWKU09PT3To0AEfffQRli1bhoYNG+LSpUuQSCTo2rUrZsyYgdatW2Ps2LEYPnw49PT0cPHiRSQmJmLlypWlimX58uUwNzeHs7MzNDQ08NNPP8HMzAw1a9aEj48P2rRpg169euHzzz+Hvb097t27h4SEBPTq1avE5R+l4eXlVexMd2BgIAIDAyt8HCIiIno7WNQWY+/evTA3N4eWlhZq1aqF5s2b48svv8TQoUOL/fCFwkgkEgwcOBBLlizB3LlzKxxbQEAAbty4galTp+LFixfo168fAgMDceLEiVKPceXKFbi4uCi1eXp6Fvo2//bt2zF16lQMHDgQWVlZaNiwofjpWk5OTvj9998xa9YstG/fHoIgoEGDBujfv3+pY9HX18fnn3+Oq1evQlNTEy1btkRCQoKY54SEBMyaNQtBQUF48OABzMzM0KFDB9StW7fUxyAiIqKqSyK8rYWY9M517twZZmZm2LhxY2WH8t7JyMiAkZERHj58WOjyAyo9uVyOhIQE+Pn5cY1YBTGXqsNcqg5zqTrMZcXl//1OT0+HoaFhsX05U6umsrOz8fXXX8PX1xeampr44YcfsH//ft42hIiIiKolFrVqSiKRICEhAQsWLEBOTg7s7e2xfft2+Pj4AHj1dn5Rfv31V7Rv3/5dhUpERET01rGoVVM6OjrYv39/kdvfvADsdfXq1XsLERERERFVHha1VVRFb69FREREpE7Kdgk/EREREdF7iEUtEREREak9FrVEREREpPZY1BIRERGR2mNRS0RERERqj0UtEREREak9FrVEREREpPZY1BIRERGR2mNRS0RERERqj0UtEREREak9FrVEREREpPZY1BIRERGR2mNRS0RERERqj0UtEREREak9FrVEREREpPZY1BIRERGR2mNRS0RERERqj0UtEREREak9FrVEREREpPZY1BIRERGR2mNRS0RERERqj0UtEREREak9rcoOgOhdEAQBAPDs2TNIpdJKjka9yeVyZGdnIyMjg7msIOZSdZhL1WEuVYe5rLiMjAwA//93vDgsaqlaePToEQDA1ta2kiMhIiKisnr27BmMjIyK7cOilqoFY2NjAMCtW7dK/E9BxcvIyIClpSVu374NQ0PDyg5HrTGXqsNcqg5zqTrMZcUJgoBnz57BwsKixL4saqla0NB4tXzc6P/au/egqM77DeDPCnuBFZaL4oIxIGnikgJGocQgCWoasV5qJhPaOl6wtelgqoE4TbVJUzVepzMxJmnUajMwiclYG4iNNuMEFWwJqIVAg0IxwQvWwWJSQK1VhH1+f2Q8v6yAQULExeczszPue7777vs+Mvr1zDlHh0N/sPSSwMBAZdlLlGXvUZa9R1n2HmX59XT3ZJRuFBMRERERr6emVkRERES8nppauS1YrVYsXboUVqu1r5fi9ZRl71GWvUdZ9h5l2XuU5c1lYneekSAiIiIicgvTmVoRERER8XpqakVERETE66mpFRERERGvp6ZWRERERLyemlq5LWzYsAHDhw+HzWZDQkIC/va3v/X1km4pa9aswXe+8x0EBAQgLCwMjz76KGpraz1qSGLZsmWIiIiAn58fxo0bhyNHjnjUXL58GQsXLsSgQYNgt9vx/e9/H//6179u5lZuOWvWrIHJZEJ2drYxpiy77/Tp05g1axZCQ0Ph7++P++67D+Xl5cZxZdk9bW1t+PWvf43hw4fDz88P0dHReOGFF+B2u40aZdm5v/71r5g2bRoiIiJgMpmwY8cOj+O9lVtTUxNmz54Nh8MBh8OB2bNno7m5+RveXT9DkX5u27ZtNJvN3LJlC6urq5mVlUW73c6TJ0/29dJuGWlpaczJyeHhw4dZWVnJKVOm8M477+SFCxeMmrVr1zIgIIB5eXmsqqriD3/4Q4aHh/PcuXNGTWZmJocOHcqCggJ+9NFHHD9+PEeOHMm2tra+2FafO3ToEKOiohgfH8+srCxjXFl2z3/+8x9GRkZy7ty5PHjwII8fP849e/bw008/NWqUZfesXLmSoaGh3LVrF48fP84//elPHDhwINevX2/UKMvOvf/++3zuueeYl5dHAHz33Xc9jvdWbpMmTWJsbCxLSkpYUlLC2NhYTp069WZts19QUyv9XlJSEjMzMz3GXC4XlyxZ0kcruvU1NjYSAPfv30+SdLvddDqdXLt2rVFz6dIlOhwObtq0iSTZ3NxMs9nMbdu2GTWnT5/mgAEDuHv37pu7gVvA+fPneffdd7OgoICpqalGU6ssu2/x4sVMSUnp8riy7L4pU6bwJz/5icfYY489xlmzZpFUlt11bVPbW7lVV1cTAA8cOGDUlJaWEgD/+c9/fsO76j90+YH0a62trSgvL8fEiRM9xidOnIiSkpI+WtWtr6WlBQAQEhICADh+/DjOnDnjkaPVakVqaqqRY3l5Oa5cueJRExERgdjY2Nsy65///OeYMmUKvvvd73qMK8vue++995CYmIj09HSEhYVh1KhR2LJli3FcWXZfSkoK9u7di6NHjwIA/vGPf6C4uBiTJ08GoCx7qrdyKy0thcPhwP3332/UjBkzBg6H47bNtid8+3oBIt+kzz77DO3t7RgyZIjH+JAhQ3DmzJk+WtWtjSQWLVqElJQUxMbGAoCRVWc5njx50qixWCwIDg7uUHO7Zb1t2zaUl5ejrKyswzFl2X3Hjh3Dxo0bsWjRIjz77LM4dOgQnnrqKVitVsyZM0dZ3oDFixejpaUFLpcLPj4+aG9vx6pVqzBjxgwA+rnsqd7K7cyZMwgLC+swf1hY2G2bbU+oqZXbgslk8nhPssOYfGHBggX4+OOPUVxc3OFYT3K83bI+deoUsrKy8MEHH8Bms3VZpyy/mtvtRmJiIlavXg0AGDVqFI4cOYKNGzdizpw5Rp2y/Gp//OMfsXXrVrz99tv49re/jcrKSmRnZyMiIgIZGRlGnbLsmd7IrbN6ZXtjdPmB9GuDBg2Cj49Ph3/pNjY2dviXtQALFy7Ee++9h8LCQtxxxx3GuNPpBIDr5uh0OtHa2oqmpqYua24H5eXlaGxsREJCAnx9feHr64v9+/fjlVdega+vr5GFsvxq4eHhuPfeez3GYmJiUF9fD0A/lzfimWeewZIlS/CjH/0IcXFxmD17Np5++mmsWbMGgLLsqd7Kzel04t///neH+c+ePXvbZtsTamqlX7NYLEhISEBBQYHHeEFBAZKTk/toVbcekliwYAHy8/Oxb98+DB8+3OP48OHD4XQ6PXJsbW3F/v37jRwTEhJgNps9ahoaGnD48OHbKuuHH34YVVVVqKysNF6JiYmYOXMmKisrER0drSy7aezYsR0eLXf06FFERkYC0M/ljbh48SIGDPD8K9/Hx8d4pJey7Jneyu2BBx5AS0sLDh06ZNQcPHgQLS0tt222PdIXd6eJ3ExXH+n1+uuvs7q6mtnZ2bTb7Txx4kRfL+2WMX/+fDocDhYVFbGhocF4Xbx40ahZu3YtHQ4H8/PzWVVVxRkzZnT62Jo77riDe/bs4UcffcQJEyb0+8f9dMeXn35AKsvuOnToEH19fblq1Sp+8sknfOutt+jv78+tW7caNcqyezIyMjh06FDjkV75+fkcNGgQf/nLXxo1yrJz58+fZ0VFBSsqKgiA69atY0VFhfFYyN7KbdKkSYyPj2dpaSlLS0sZFxenR3rdIDW1clt47bXXGBkZSYvFwtGjRxuPqpIvAOj0lZOTY9S43W4uXbqUTqeTVquVDz30EKuqqjzm+d///scFCxYwJCSEfn5+nDp1Kuvr62/ybm491za1yrL7du7cydjYWFqtVrpcLm7evNnjuLLsnnPnzjErK4t33nknbTYbo6Oj+dxzz/Hy5ctGjbLsXGFhYad/PmZkZJDsvdw+//xzzpw5kwEBAQwICODMmTPZ1NR0k3bZP5hIsm/OEYuIiIiI9A5dUysiIiIiXk9NrYiIiIh4PTW1IiIiIuL11NSKiIiIiNdTUysiIiIiXk9NrYiIiIh4PTW1IiIiIuL11NSKiMgta9y4ccjOzu7rZYiIF1BTKyLipebOnQuTydTh9emnn/bK/Lm5uQgKCuqVuXoqPz8fK1as6NM1XE9RURFMJhOam5v7eikitz3fvl6AiIj03KRJk5CTk+MxNnjw4D5aTdeuXLkCs9l8w58LCQn5BlbTO65cudLXSxCRL9GZWhERL2a1WuF0Oj1ePj4+AICdO3ciISEBNpsN0dHRWL58Odra2ozPrlu3DnFxcbDb7Rg2bBiefPJJXLhwAcAXZyB//OMfo6WlxTgDvGzZMgCAyWTCjh07PNYRFBSE3NxcAMCJEydgMpmwfft2jBs3DjabDVu3bgUA5OTkICYmBjabDS6XCxs2bLju/q69/CAqKgorV67EnDlzMHDgQERGRuLPf/4zzp49i+nTp2PgwIGIi4tDWVmZ8ZmrZ5x37NiBe+65BzabDY888ghOnTrl8V0bN27EXXfdBYvFghEjRuDNN9/0OG4ymbBp0yZMnz4ddrsdP/3pTzF+/HgAQHBwMEwmE+bOnQsA2L17N1JSUhAUFITQ0FBMnToVdXV1xlxXM8rPz8f48ePh7++PkSNHorS01OM7P/zwQ6SmpsLf3x/BwcFIS0tDU1MTAIAkfvvb3yI6Ohp+fn4YOXIk3nnnnevmKdKvUUREvFJGRganT5/e6bHdu3czMDCQubm5rKur4wcffMCoqCguW7bMqHnppZe4b98+Hjt2jHv37uWIESM4f/58kuTly5e5fv16BgYGsqGhgQ0NDTx//jxJEgDfffddj+9zOBzMyckhSR4/fpwAGBUVxby8PB47doynT5/m5s2bGR4ebozl5eUxJCSEubm5Xe4xNTWVWVlZxvvIyEiGhIRw06ZNPHr0KOfPn8+AgABOmjSJ27dvZ21tLR999FHGxMTQ7XaTJHNycmg2m5mYmMiSkhKWlZUxKSmJycnJxrz5+fk0m8187bXXWFtbyxdffJE+Pj7ct2+fUQOAYWFhfP3111lXV8cTJ04wLy+PAFhbW8uGhgY2NzeTJN955x3m5eXx6NGjrKio4LRp0xgXF8f29naPjFwuF3ft2sXa2lo+/vjjjIyM5JUrV0iSFRUVtFqtnD9/PisrK3n48GG++uqrPHv2LEny2Wefpcvl4u7du1lXV8ecnBxarVYWFRV1madIf6amVkTES2VkZNDHx4d2u914Pf744yTJBx98kKtXr/aof/PNNxkeHt7lfNu3b2doaKjxPicnhw6Ho0Ndd5va9evXe9QMGzaMb7/9tsfYihUr+MADD3S5ps6a2lmzZhnvGxoaCIDPP/+8MVZaWkoAbGhoMPYBgAcOHDBqampqCIAHDx4kSSYnJ/OJJ57w+O709HROnjzZY9/Z2dkeNYWFhQTApqamLvdAko2NjQTAqqoqkv+f0R/+8Aej5siRIwTAmpoakuSMGTM4duzYTue7cOECbTYbS0pKPMbnzZvHGTNmXHctIv2VrqkVEfFi48ePx8aNG433drsdAFBeXo6///3vWLVqlXGsvb0dly5dwsWLF+Hv74/CwkKsXr0a1dXVOHfuHNra2nDp0iX897//Neb5OhITE41fnz17FqdOncK8efPwxBNPGONtbW1wOBw3NG98fLzx6yFDhgAA4uLiOow1NjbC6XQCAHx9fT3W43K5EBQUhJqaGiQlJaGmpgY/+9nPPL5n7NixePnll7vc0/XU1dXh+eefx4EDB/DZZ5/B7XYDAOrr6xEbG9vpXsLDw411u1wuVFZWIj09vdP5q6urcenSJTzyyCMe462trRg1alS31ijS36ipFRHxYna7Hd/61rc6jLvdbixfvhyPPfZYh2M2mw0nT57E5MmTkZmZiRUrViAkJATFxcWYN2/eV94AZTKZQNJjrLPPfLkxvtrUbdmyBffff79H3dVrgLvryzecmUymLseufue1412NXXucZIex7jb706ZNw7Bhw7BlyxZERETA7XYjNjYWra2tX7mXq+v28/Prcv6rNX/5y18wdOhQj2NWq7VbaxTpb9TUioj0Q6NHj0ZtbW2nDS8AlJWVoa2tDS+++CIGDPjinuHt27d71FgsFrS3t3f47ODBg9HQ0GC8/+STT3Dx4sXrrmfIkCEYOnQojh07hpkzZ97odr62trY2lJWVISkpCQBQW1uL5uZmuFwuAEBMTAyKi4sxZ84c4zMlJSWIiYm57rwWiwUAPHL6/PPPUVNTg9///vd48MEHAQDFxcU3vOb4+Hjs3bsXy5cv73Ds3nvvhdVqRX19PVJTU294bpH+SE2tiEg/9Jvf/AZTp07FsGHDkJ6ejgEDBuDjjz9GVVUVVq5cibvuugttbW149dVXMW3aNHz44YfYtGmTxxxRUVG4cOEC9u7di5EjR8Lf3x/+/v6YMGECfve732HMmDFwu91YvHhxtx7XtWzZMjz11FMIDAzE9773PVy+fBllZWVoamrCokWLvqkoAHxxRnThwoV45ZVXYDabsWDBAowZM8Zocp955hn84Ac/wOjRo/Hwww9j586dyM/Px549e647b2RkJEwmE3bt2oXJkyfDz88PwcHBCA0NxebNmxEeHo76+nosWbLkhtf8q1/9CnFxcXjyySeRmZkJi8WCwsJCpKenY9CgQfjFL36Bp59+Gm63GykpKTh37hxKSkowcOBAZGRk9CgnEa/W1xf1iohIz1zv6QfkF09ASE5Opp+fHwMDA5mUlMTNmzcbx9etW8fw8HD6+fkxLS2Nb7zxRoebnjIzMxkaGkoAXLp0KUny9OnTnDhxIu12O++++26+//77nd4oVlFR0WFNb731Fu+77z5aLBYGBwfzoYceYn5+fpd76OxGsZdeesmjBtfcuHbt91+94S0vL4/R0dG0WCycMGECT5w44THPhg0bGB0dTbPZzHvuuYdvvPHGdb/nqhdeeIFOp5Mmk4kZGRkkyYKCAsbExNBqtTI+Pp5FRUUen+8so6amJgJgYWGhMVZUVMTk5GRarVYGBQUxLS3N+P1xu918+eWXOWLECJrNZg4ePJhpaWncv39/l3mK9Gcm8poLo0RERPqR3NxcZGdn63/9Eunn9J8viIiIiIjXU1MrIiIiIl5Plx+IiIiIiNfTmVoRERER8XpqakVERETE66mpFRERERGvp6ZWRERERLyemloRERER8XpqakVERETE66mpFRERERGvp6ZWRERERLyemloRERER8Xr/Byfxkn4+SJncAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 2: Intermediate Search\n",
    "\n",
    "# Adjusting logging file for the intermediate search\n",
    "logging.basicConfig(level=logging.INFO, filename='lgb_intermediate_tuning.log', filemode='w',\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Adapt ranges based on the initial search results\n",
    "initial_params.update(best_params)\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'learning_rate': trial.suggest_float('learning_rate', initial_params['learning_rate'] * 0.8, initial_params['learning_rate'] * 1.2),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', int(initial_params['num_leaves'] * 0.8), int(initial_params['num_leaves'] * 1.2)),\n",
    "        'max_depth': trial.suggest_int('max_depth', max(-1, int(initial_params['max_depth'] * 0.8)), max(3, int(initial_params['max_depth'] * 1.2))),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', int(initial_params['min_data_in_leaf'] * 0.8), int(initial_params['min_data_in_leaf'] * 1.2)),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', initial_params['lambda_l1'] * 0.8, initial_params['lambda_l1'] * 1.2),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', initial_params['lambda_l2'] * 0.8, initial_params['lambda_l2'] * 1.2),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', max(0.0, initial_params['feature_fraction'] * 0.8), min(1.0, initial_params['feature_fraction'] * 1.2)),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', max(0.0, initial_params['bagging_fraction'] * 0.8), min(1.0, initial_params['bagging_fraction'] * 1.2)),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', int(initial_params['bagging_freq'] * 0.8), int(initial_params['bagging_freq'] * 1.2))\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    cv_scores = []\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_t, X_v = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_t, y_v = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(X_t, y_t, eval_set=[(X_v, y_v)], callbacks=[lgb.early_stopping(stopping_rounds=10, verbose=False)], eval_metric='auc')\n",
    "\n",
    "        y_pred = model.predict_proba(X_v)[:, 1]\n",
    "        cv_scores.append(roc_auc_score(y_v, y_pred))\n",
    "\n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "# Set up Optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "logger.info(f\"Best parameters from intermediate search: {best_params}\")\n",
    "logger.info(f\"Best ROC AUC score from intermediate search: {study.best_value}\")\n",
    "\n",
    "# Save results\n",
    "results_df = study.trials_dataframe()\n",
    "results_df.to_csv('lgb_intermediate_search_results.csv', index=False)\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "final_model = lgb.LGBMClassifier(**best_params)\n",
    "final_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=[lgb.early_stopping(stopping_rounds=10, verbose=True)], eval_metric='auc')\n",
    "\n",
    "# Evaluate model performance on validation set\n",
    "y_pred_val = final_model.predict_proba(X_val)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_val)\n",
    "logger.info(f\"Validation ROC AUC Score with best parameters: {roc_auc}\")\n",
    "\n",
    "# Save final model\n",
    "final_model.booster_.save_model('final_lgb_model_intermediate.txt')\n",
    "logger.info('Final model saved to final_lgb_model_intermediate.txt')\n",
    "\n",
    "# Plot feature importances\n",
    "lgb.plot_importance(final_model, max_num_features=10)\n",
    "plt.title('LightGBM Feature Importances')\n",
    "plt.savefig('graphs_lgb_incremental/lgb_feature_importances_intermediate.png')\n",
    "plt.show()\n",
    "logger.info('LightGBM feature importances plot saved.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:38:39,408] A new study created in memory with name: no-name-a06856a3-b8ea-4077-bc7e-f905c3209910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.880768371391293, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.880768371391293\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12868061891657523, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12868061891657523\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24931906776417134, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24931906776417134\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8718085359089548, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8718085359089548\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.880768371391293, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.880768371391293\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12868061891657523, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12868061891657523\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24931906776417134, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24931906776417134\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8718085359089548, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8718085359089548\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045852 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.880768371391293, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.880768371391293\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12868061891657523, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12868061891657523\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24931906776417134, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24931906776417134\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8718085359089548, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8718085359089548\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.880768371391293, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.880768371391293\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12868061891657523, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12868061891657523\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24931906776417134, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24931906776417134\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8718085359089548, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8718085359089548\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.880768371391293, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.880768371391293\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12868061891657523, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12868061891657523\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24931906776417134, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24931906776417134\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8718085359089548, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8718085359089548\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.880768371391293, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.880768371391293\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12868061891657523, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12868061891657523\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24931906776417134, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24931906776417134\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8718085359089548, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8718085359089548\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045860 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.880768371391293, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.880768371391293\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12868061891657523, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12868061891657523\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24931906776417134, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24931906776417134\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8718085359089548, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8718085359089548\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.880768371391293, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.880768371391293\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12868061891657523, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12868061891657523\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24931906776417134, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24931906776417134\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8718085359089548, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8718085359089548\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.880768371391293, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.880768371391293\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12868061891657523, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12868061891657523\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24931906776417134, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24931906776417134\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8718085359089548, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8718085359089548\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.880768371391293, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.880768371391293\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12868061891657523, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12868061891657523\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24931906776417134, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24931906776417134\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8718085359089548, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8718085359089548\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044843 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.880768371391293, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.880768371391293\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12868061891657523, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12868061891657523\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24931906776417134, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24931906776417134\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8718085359089548, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8718085359089548\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.880768371391293, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.880768371391293\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12868061891657523, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12868061891657523\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24931906776417134, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24931906776417134\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8718085359089548, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8718085359089548\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:40:33,578] Trial 0 finished with value: 0.8785903983225479 and parameters: {'learning_rate': 0.27832253650255445, 'num_leaves': 35, 'max_depth': 10, 'min_data_in_leaf': 17, 'lambda_l1': 0.12868061891657523, 'lambda_l2': 0.24931906776417134, 'feature_fraction': 0.880768371391293, 'bagging_fraction': 0.8718085359089548, 'bagging_freq': 4}. Best is trial 0 with value: 0.8785903983225479.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9227710691704795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9227710691704795\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13068775085167342, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13068775085167342\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2231086088335952, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2231086088335952\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8872906108969144, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8872906108969144\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9227710691704795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9227710691704795\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13068775085167342, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13068775085167342\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2231086088335952, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2231086088335952\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8872906108969144, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8872906108969144\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9227710691704795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9227710691704795\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13068775085167342, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13068775085167342\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2231086088335952, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2231086088335952\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8872906108969144, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8872906108969144\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9227710691704795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9227710691704795\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13068775085167342, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13068775085167342\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2231086088335952, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2231086088335952\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8872906108969144, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8872906108969144\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9227710691704795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9227710691704795\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13068775085167342, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13068775085167342\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2231086088335952, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2231086088335952\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8872906108969144, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8872906108969144\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9227710691704795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9227710691704795\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13068775085167342, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13068775085167342\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2231086088335952, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2231086088335952\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8872906108969144, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8872906108969144\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9227710691704795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9227710691704795\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13068775085167342, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13068775085167342\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2231086088335952, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2231086088335952\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8872906108969144, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8872906108969144\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9227710691704795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9227710691704795\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13068775085167342, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13068775085167342\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2231086088335952, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2231086088335952\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8872906108969144, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8872906108969144\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9227710691704795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9227710691704795\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13068775085167342, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13068775085167342\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2231086088335952, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2231086088335952\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8872906108969144, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8872906108969144\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9227710691704795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9227710691704795\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13068775085167342, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13068775085167342\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2231086088335952, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2231086088335952\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8872906108969144, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8872906108969144\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9227710691704795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9227710691704795\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13068775085167342, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13068775085167342\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2231086088335952, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2231086088335952\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8872906108969144, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8872906108969144\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9227710691704795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9227710691704795\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13068775085167342, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13068775085167342\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2231086088335952, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2231086088335952\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8872906108969144, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8872906108969144\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:42:28,892] Trial 1 finished with value: 0.8787049245290742 and parameters: {'learning_rate': 0.28629255358418654, 'num_leaves': 41, 'max_depth': 12, 'min_data_in_leaf': 17, 'lambda_l1': 0.13068775085167342, 'lambda_l2': 0.2231086088335952, 'feature_fraction': 0.9227710691704795, 'bagging_fraction': 0.8872906108969144, 'bagging_freq': 4}. Best is trial 1 with value: 0.8787049245290742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9731382044447767, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9731382044447767\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1245205730648077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1245205730648077\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23073999958088598, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23073999958088598\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8143382740680455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8143382740680455\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9731382044447767, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9731382044447767\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1245205730648077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1245205730648077\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23073999958088598, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23073999958088598\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8143382740680455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8143382740680455\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9731382044447767, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9731382044447767\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1245205730648077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1245205730648077\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23073999958088598, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23073999958088598\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8143382740680455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8143382740680455\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9731382044447767, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9731382044447767\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1245205730648077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1245205730648077\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23073999958088598, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23073999958088598\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8143382740680455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8143382740680455\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9731382044447767, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9731382044447767\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1245205730648077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1245205730648077\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23073999958088598, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23073999958088598\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8143382740680455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8143382740680455\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9731382044447767, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9731382044447767\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1245205730648077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1245205730648077\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23073999958088598, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23073999958088598\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8143382740680455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8143382740680455\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9731382044447767, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9731382044447767\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1245205730648077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1245205730648077\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23073999958088598, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23073999958088598\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8143382740680455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8143382740680455\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9731382044447767, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9731382044447767\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1245205730648077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1245205730648077\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23073999958088598, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23073999958088598\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8143382740680455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8143382740680455\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9731382044447767, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9731382044447767\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1245205730648077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1245205730648077\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23073999958088598, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23073999958088598\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8143382740680455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8143382740680455\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9731382044447767, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9731382044447767\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1245205730648077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1245205730648077\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23073999958088598, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23073999958088598\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8143382740680455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8143382740680455\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9731382044447767, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9731382044447767\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1245205730648077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1245205730648077\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23073999958088598, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23073999958088598\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8143382740680455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8143382740680455\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9731382044447767, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9731382044447767\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1245205730648077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1245205730648077\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23073999958088598, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23073999958088598\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8143382740680455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8143382740680455\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:44:22,593] Trial 2 finished with value: 0.8786037088278503 and parameters: {'learning_rate': 0.24441899950929344, 'num_leaves': 41, 'max_depth': 10, 'min_data_in_leaf': 15, 'lambda_l1': 0.1245205730648077, 'lambda_l2': 0.23073999958088598, 'feature_fraction': 0.9731382044447767, 'bagging_fraction': 0.8143382740680455, 'bagging_freq': 4}. Best is trial 1 with value: 0.8787049245290742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9863538517745377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9863538517745377\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12983440352902872, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12983440352902872\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22980071720832737, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22980071720832737\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9010803977527969, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9010803977527969\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9863538517745377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9863538517745377\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12983440352902872, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12983440352902872\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22980071720832737, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22980071720832737\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9010803977527969, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9010803977527969\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9863538517745377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9863538517745377\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12983440352902872, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12983440352902872\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22980071720832737, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22980071720832737\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9010803977527969, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9010803977527969\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9863538517745377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9863538517745377\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12983440352902872, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12983440352902872\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22980071720832737, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22980071720832737\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9010803977527969, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9010803977527969\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9863538517745377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9863538517745377\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12983440352902872, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12983440352902872\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22980071720832737, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22980071720832737\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9010803977527969, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9010803977527969\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9863538517745377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9863538517745377\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12983440352902872, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12983440352902872\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22980071720832737, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22980071720832737\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9010803977527969, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9010803977527969\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9863538517745377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9863538517745377\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12983440352902872, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12983440352902872\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22980071720832737, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22980071720832737\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9010803977527969, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9010803977527969\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9863538517745377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9863538517745377\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12983440352902872, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12983440352902872\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22980071720832737, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22980071720832737\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9010803977527969, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9010803977527969\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9863538517745377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9863538517745377\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12983440352902872, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12983440352902872\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22980071720832737, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22980071720832737\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9010803977527969, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9010803977527969\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9863538517745377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9863538517745377\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12983440352902872, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12983440352902872\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22980071720832737, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22980071720832737\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9010803977527969, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9010803977527969\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034548 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9863538517745377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9863538517745377\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12983440352902872, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12983440352902872\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22980071720832737, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22980071720832737\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9010803977527969, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9010803977527969\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9863538517745377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9863538517745377\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12983440352902872, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12983440352902872\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22980071720832737, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22980071720832737\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9010803977527969, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9010803977527969\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:46:16,653] Trial 3 finished with value: 0.8784638618750296 and parameters: {'learning_rate': 0.26916571889894025, 'num_leaves': 34, 'max_depth': 9, 'min_data_in_leaf': 17, 'lambda_l1': 0.12983440352902872, 'lambda_l2': 0.22980071720832737, 'feature_fraction': 0.9863538517745377, 'bagging_fraction': 0.9010803977527969, 'bagging_freq': 4}. Best is trial 1 with value: 0.8787049245290742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.92452305165529, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.92452305165529\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13008083784028118, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13008083784028118\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23632141644103108, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23632141644103108\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9433784148543037, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9433784148543037\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.92452305165529, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.92452305165529\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13008083784028118, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13008083784028118\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23632141644103108, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23632141644103108\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9433784148543037, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9433784148543037\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.92452305165529, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.92452305165529\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13008083784028118, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13008083784028118\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23632141644103108, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23632141644103108\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9433784148543037, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9433784148543037\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.92452305165529, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.92452305165529\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13008083784028118, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13008083784028118\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23632141644103108, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23632141644103108\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9433784148543037, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9433784148543037\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.92452305165529, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.92452305165529\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13008083784028118, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13008083784028118\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23632141644103108, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23632141644103108\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9433784148543037, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9433784148543037\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.92452305165529, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.92452305165529\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13008083784028118, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13008083784028118\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23632141644103108, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23632141644103108\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9433784148543037, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9433784148543037\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.92452305165529, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.92452305165529\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13008083784028118, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13008083784028118\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23632141644103108, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23632141644103108\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9433784148543037, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9433784148543037\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.92452305165529, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.92452305165529\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13008083784028118, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13008083784028118\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23632141644103108, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23632141644103108\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9433784148543037, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9433784148543037\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.92452305165529, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.92452305165529\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13008083784028118, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13008083784028118\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23632141644103108, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23632141644103108\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9433784148543037, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9433784148543037\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.92452305165529, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.92452305165529\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13008083784028118, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13008083784028118\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23632141644103108, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23632141644103108\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9433784148543037, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9433784148543037\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.92452305165529, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.92452305165529\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13008083784028118, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13008083784028118\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23632141644103108, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23632141644103108\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9433784148543037, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9433784148543037\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.92452305165529, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.92452305165529\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13008083784028118, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13008083784028118\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23632141644103108, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23632141644103108\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9433784148543037, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9433784148543037\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:48:13,583] Trial 4 finished with value: 0.8785167005546479 and parameters: {'learning_rate': 0.2557437176128387, 'num_leaves': 37, 'max_depth': 9, 'min_data_in_leaf': 16, 'lambda_l1': 0.13008083784028118, 'lambda_l2': 0.23632141644103108, 'feature_fraction': 0.92452305165529, 'bagging_fraction': 0.9433784148543037, 'bagging_freq': 3}. Best is trial 1 with value: 0.8787049245290742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8172076844792285, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8172076844792285\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12602838358035842, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12602838358035842\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21177724452439387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21177724452439387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9335787479900166, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9335787479900166\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8172076844792285, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8172076844792285\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12602838358035842, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12602838358035842\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21177724452439387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21177724452439387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9335787479900166, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9335787479900166\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8172076844792285, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8172076844792285\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12602838358035842, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12602838358035842\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21177724452439387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21177724452439387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9335787479900166, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9335787479900166\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8172076844792285, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8172076844792285\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12602838358035842, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12602838358035842\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21177724452439387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21177724452439387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9335787479900166, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9335787479900166\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8172076844792285, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8172076844792285\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12602838358035842, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12602838358035842\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21177724452439387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21177724452439387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9335787479900166, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9335787479900166\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8172076844792285, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8172076844792285\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12602838358035842, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12602838358035842\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21177724452439387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21177724452439387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9335787479900166, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9335787479900166\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031736 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8172076844792285, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8172076844792285\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12602838358035842, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12602838358035842\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21177724452439387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21177724452439387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9335787479900166, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9335787479900166\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8172076844792285, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8172076844792285\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12602838358035842, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12602838358035842\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21177724452439387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21177724452439387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9335787479900166, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9335787479900166\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8172076844792285, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8172076844792285\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12602838358035842, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12602838358035842\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21177724452439387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21177724452439387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9335787479900166, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9335787479900166\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8172076844792285, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8172076844792285\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12602838358035842, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12602838358035842\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21177724452439387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21177724452439387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9335787479900166, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9335787479900166\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8172076844792285, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8172076844792285\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12602838358035842, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12602838358035842\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21177724452439387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21177724452439387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9335787479900166, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9335787479900166\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8172076844792285, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8172076844792285\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12602838358035842, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12602838358035842\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21177724452439387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21177724452439387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9335787479900166, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9335787479900166\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:50:10,025] Trial 5 finished with value: 0.8787298941037186 and parameters: {'learning_rate': 0.29368556085907255, 'num_leaves': 40, 'max_depth': 12, 'min_data_in_leaf': 16, 'lambda_l1': 0.12602838358035842, 'lambda_l2': 0.21177724452439387, 'feature_fraction': 0.8172076844792285, 'bagging_fraction': 0.9335787479900166, 'bagging_freq': 4}. Best is trial 5 with value: 0.8787298941037186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.83325081446477, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.83325081446477\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11348481489085901, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11348481489085901\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2512971792185537, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2512971792185537\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9054252747137104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9054252747137104\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.83325081446477, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.83325081446477\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11348481489085901, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11348481489085901\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2512971792185537, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2512971792185537\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9054252747137104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9054252747137104\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.83325081446477, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.83325081446477\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11348481489085901, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11348481489085901\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2512971792185537, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2512971792185537\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9054252747137104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9054252747137104\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.83325081446477, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.83325081446477\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11348481489085901, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11348481489085901\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2512971792185537, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2512971792185537\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9054252747137104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9054252747137104\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.83325081446477, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.83325081446477\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11348481489085901, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11348481489085901\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2512971792185537, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2512971792185537\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9054252747137104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9054252747137104\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.83325081446477, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.83325081446477\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11348481489085901, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11348481489085901\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2512971792185537, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2512971792185537\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9054252747137104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9054252747137104\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.83325081446477, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.83325081446477\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11348481489085901, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11348481489085901\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2512971792185537, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2512971792185537\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9054252747137104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9054252747137104\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.83325081446477, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.83325081446477\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11348481489085901, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11348481489085901\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2512971792185537, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2512971792185537\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9054252747137104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9054252747137104\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.83325081446477, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.83325081446477\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11348481489085901, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11348481489085901\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2512971792185537, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2512971792185537\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9054252747137104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9054252747137104\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.83325081446477, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.83325081446477\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11348481489085901, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11348481489085901\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2512971792185537, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2512971792185537\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9054252747137104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9054252747137104\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.83325081446477, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.83325081446477\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11348481489085901, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11348481489085901\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2512971792185537, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2512971792185537\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9054252747137104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9054252747137104\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.83325081446477, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.83325081446477\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11348481489085901, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11348481489085901\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2512971792185537, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2512971792185537\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9054252747137104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9054252747137104\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:52:08,841] Trial 6 finished with value: 0.8785185241197176 and parameters: {'learning_rate': 0.24112501422582988, 'num_leaves': 40, 'max_depth': 10, 'min_data_in_leaf': 16, 'lambda_l1': 0.11348481489085901, 'lambda_l2': 0.2512971792185537, 'feature_fraction': 0.83325081446477, 'bagging_fraction': 0.9054252747137104, 'bagging_freq': 3}. Best is trial 5 with value: 0.8787298941037186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9221876362526457, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9221876362526457\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11915706712230983, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11915706712230983\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.25142698702709954, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.25142698702709954\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8134041041674662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8134041041674662\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9221876362526457, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9221876362526457\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11915706712230983, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11915706712230983\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.25142698702709954, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.25142698702709954\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8134041041674662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8134041041674662\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9221876362526457, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9221876362526457\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11915706712230983, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11915706712230983\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.25142698702709954, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.25142698702709954\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8134041041674662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8134041041674662\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9221876362526457, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9221876362526457\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11915706712230983, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11915706712230983\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.25142698702709954, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.25142698702709954\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8134041041674662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8134041041674662\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9221876362526457, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9221876362526457\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11915706712230983, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11915706712230983\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.25142698702709954, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.25142698702709954\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8134041041674662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8134041041674662\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9221876362526457, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9221876362526457\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11915706712230983, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11915706712230983\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.25142698702709954, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.25142698702709954\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8134041041674662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8134041041674662\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9221876362526457, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9221876362526457\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11915706712230983, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11915706712230983\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.25142698702709954, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.25142698702709954\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8134041041674662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8134041041674662\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9221876362526457, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9221876362526457\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11915706712230983, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11915706712230983\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.25142698702709954, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.25142698702709954\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8134041041674662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8134041041674662\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9221876362526457, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9221876362526457\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11915706712230983, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11915706712230983\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.25142698702709954, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.25142698702709954\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8134041041674662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8134041041674662\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9221876362526457, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9221876362526457\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11915706712230983, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11915706712230983\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.25142698702709954, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.25142698702709954\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8134041041674662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8134041041674662\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9221876362526457, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9221876362526457\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11915706712230983, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11915706712230983\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.25142698702709954, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.25142698702709954\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8134041041674662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8134041041674662\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9221876362526457, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9221876362526457\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11915706712230983, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11915706712230983\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.25142698702709954, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.25142698702709954\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8134041041674662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8134041041674662\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:54:01,773] Trial 7 finished with value: 0.8786450236359005 and parameters: {'learning_rate': 0.29374734854439744, 'num_leaves': 36, 'max_depth': 12, 'min_data_in_leaf': 18, 'lambda_l1': 0.11915706712230983, 'lambda_l2': 0.25142698702709954, 'feature_fraction': 0.9221876362526457, 'bagging_fraction': 0.8134041041674662, 'bagging_freq': 3}. Best is trial 5 with value: 0.8787298941037186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9000511728831261, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9000511728831261\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11138105205675859, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11138105205675859\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22688282547695848, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22688282547695848\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8574550608782354, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8574550608782354\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9000511728831261, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9000511728831261\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11138105205675859, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11138105205675859\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22688282547695848, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22688282547695848\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8574550608782354, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8574550608782354\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041326 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9000511728831261, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9000511728831261\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11138105205675859, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11138105205675859\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22688282547695848, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22688282547695848\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8574550608782354, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8574550608782354\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9000511728831261, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9000511728831261\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11138105205675859, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11138105205675859\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22688282547695848, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22688282547695848\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8574550608782354, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8574550608782354\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9000511728831261, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9000511728831261\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11138105205675859, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11138105205675859\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22688282547695848, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22688282547695848\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8574550608782354, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8574550608782354\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9000511728831261, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9000511728831261\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11138105205675859, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11138105205675859\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22688282547695848, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22688282547695848\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8574550608782354, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8574550608782354\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9000511728831261, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9000511728831261\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11138105205675859, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11138105205675859\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22688282547695848, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22688282547695848\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8574550608782354, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8574550608782354\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9000511728831261, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9000511728831261\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11138105205675859, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11138105205675859\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22688282547695848, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22688282547695848\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8574550608782354, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8574550608782354\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9000511728831261, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9000511728831261\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11138105205675859, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11138105205675859\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22688282547695848, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22688282547695848\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8574550608782354, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8574550608782354\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9000511728831261, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9000511728831261\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11138105205675859, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11138105205675859\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22688282547695848, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22688282547695848\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8574550608782354, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8574550608782354\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9000511728831261, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9000511728831261\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11138105205675859, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11138105205675859\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22688282547695848, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22688282547695848\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8574550608782354, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8574550608782354\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9000511728831261, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9000511728831261\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11138105205675859, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11138105205675859\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22688282547695848, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22688282547695848\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8574550608782354, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8574550608782354\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:55:55,882] Trial 8 finished with value: 0.8785867599182872 and parameters: {'learning_rate': 0.266759996608297, 'num_leaves': 37, 'max_depth': 9, 'min_data_in_leaf': 16, 'lambda_l1': 0.11138105205675859, 'lambda_l2': 0.22688282547695848, 'feature_fraction': 0.9000511728831261, 'bagging_fraction': 0.8574550608782354, 'bagging_freq': 4}. Best is trial 5 with value: 0.8787298941037186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8456835407261167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8456835407261167\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.131299287764372, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.131299287764372\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2370937868039509, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2370937868039509\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9380305728290746, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9380305728290746\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8456835407261167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8456835407261167\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.131299287764372, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.131299287764372\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2370937868039509, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2370937868039509\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9380305728290746, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9380305728290746\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8456835407261167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8456835407261167\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.131299287764372, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.131299287764372\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2370937868039509, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2370937868039509\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9380305728290746, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9380305728290746\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8456835407261167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8456835407261167\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.131299287764372, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.131299287764372\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2370937868039509, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2370937868039509\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9380305728290746, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9380305728290746\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8456835407261167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8456835407261167\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.131299287764372, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.131299287764372\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2370937868039509, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2370937868039509\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9380305728290746, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9380305728290746\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8456835407261167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8456835407261167\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.131299287764372, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.131299287764372\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2370937868039509, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2370937868039509\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9380305728290746, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9380305728290746\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8456835407261167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8456835407261167\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.131299287764372, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.131299287764372\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2370937868039509, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2370937868039509\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9380305728290746, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9380305728290746\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8456835407261167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8456835407261167\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.131299287764372, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.131299287764372\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2370937868039509, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2370937868039509\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9380305728290746, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9380305728290746\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8456835407261167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8456835407261167\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.131299287764372, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.131299287764372\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2370937868039509, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2370937868039509\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9380305728290746, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9380305728290746\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8456835407261167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8456835407261167\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.131299287764372, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.131299287764372\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2370937868039509, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2370937868039509\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9380305728290746, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9380305728290746\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 754698, number of negative: 5381194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 6135892, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8456835407261167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8456835407261167\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.131299287764372, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.131299287764372\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2370937868039509, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2370937868039509\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9380305728290746, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9380305728290746\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8456835407261167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8456835407261167\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.131299287764372, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.131299287764372\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2370937868039509, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2370937868039509\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9380305728290746, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9380305728290746\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 01:57:52,912] Trial 9 finished with value: 0.8787239343438076 and parameters: {'learning_rate': 0.26958396758117703, 'num_leaves': 39, 'max_depth': 9, 'min_data_in_leaf': 18, 'lambda_l1': 0.131299287764372, 'lambda_l2': 0.2370937868039509, 'feature_fraction': 0.8456835407261167, 'bagging_fraction': 0.9380305728290746, 'bagging_freq': 4}. Best is trial 5 with value: 0.8787298941037186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8172076844792285, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8172076844792285\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12602838358035842, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12602838358035842\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21177724452439387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21177724452439387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9335787479900166, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9335787479900166\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8172076844792285, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8172076844792285\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12602838358035842, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12602838358035842\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21177724452439387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21177724452439387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9335787479900166, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9335787479900166\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 1132047, number of negative: 8071791\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 9203838, number of used features: 10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8172076844792285, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8172076844792285\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12602838358035842, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12602838358035842\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21177724452439387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21177724452439387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9335787479900166, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9335787479900166\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.878967\tvalid_0's binary_logloss: 0.252275\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8172076844792285, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8172076844792285\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12602838358035842, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12602838358035842\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21177724452439387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21177724452439387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9335787479900166, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9335787479900166\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 3: Fine-Tuned Search\n",
    "\n",
    "# Adjusting logging file for the fine-tuned search\n",
    "logging.basicConfig(level=logging.INFO, filename='lgb_fine_tuning.log', filemode='w',\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Adapt ranges based on the intermediate search results\n",
    "initial_params.update(best_params)\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'learning_rate': trial.suggest_float('learning_rate', initial_params['learning_rate'] * 0.9, initial_params['learning_rate'] * 1.1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', int(initial_params['num_leaves'] * 0.9), int(initial_params['num_leaves'] * 1.1)),\n",
    "        'max_depth': trial.suggest_int('max_depth', max(-1, int(initial_params['max_depth'] * 0.9)), max(3, int(initial_params['max_depth'] * 1.1))),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', int(initial_params['min_data_in_leaf'] * 0.9), int(initial_params['min_data_in_leaf'] * 1.1)),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', initial_params['lambda_l1'] * 0.9, initial_params['lambda_l1'] * 1.1),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', initial_params['lambda_l2'] * 0.9, initial_params['lambda_l2'] * 1.1),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', max(0.0, initial_params['feature_fraction'] * 0.9), min(1.0, initial_params['feature_fraction'] * 1.1)),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', max(0.0, initial_params['bagging_fraction'] * 0.9), min(1.0, initial_params['bagging_fraction'] * 1.1)),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', int(initial_params['bagging_freq'] * 0.9), int(initial_params['bagging_freq'] * 1.1))\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    cv_scores = []\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_t, X_v = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_t, y_v = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(X_t, y_t, eval_set=[(X_v, y_v)], callbacks=[lgb.early_stopping(stopping_rounds=10, verbose=False)], eval_metric='auc')\n",
    "\n",
    "        y_pred = model.predict_proba(X_v)[:, 1]\n",
    "        cv_scores.append(roc_auc_score(y_v, y_pred))\n",
    "\n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "# Set up Optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "logger.info(f\"Best parameters from fine-tuned search: {best_params}\")\n",
    "logger.info(f\"Best ROC AUC score from fine-tuned search: {study.best_value}\")\n",
    "\n",
    "# Save results\n",
    "results_df = study.trials_dataframe()\n",
    "results_df.to_csv('lgb_fine_tuned_search_results.csv', index=False)\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "final_model = lgb.LGBMClassifier(**best_params)\n",
    "final_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=[lgb.early_stopping(stopping_rounds=10, verbose=True)], eval_metric='auc')\n",
    "\n",
    "# Evaluate model performance on validation set\n",
    "y_pred_val = final_model.predict_proba(X_val)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_val)\n",
    "logger.info(f\"Validation ROC AUC Score with best parameters: {roc_auc}\")\n",
    "\n",
    "# Save final model\n",
    "final_model.booster_.save_model('final_lgb_model_fine_tuned.txt')\n",
    "logger.info('Final model saved to final_lgb_model_fine_tuned.txt')\n",
    "\n",
    "# Plot feature importances\n",
    "lgb.plot_importance(final_model, max_num_features=10)\n",
    "plt.title('LightGBM Feature Importances')\n",
    "plt.savefig('graphs_lgb_incremental/lgb_feature_importances_fine_tuned.png')\n",
    "plt.show()\n",
    "logger.info('LightGBM feature importances plot saved.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
