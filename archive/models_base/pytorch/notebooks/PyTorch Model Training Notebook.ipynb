{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.0042, Training ROC AUC: 0.8551, Validation Loss: 0.2651, Validation ROC AUC: 0.8576\n",
      "Epoch [2/10], Loss: 0.0041, Training ROC AUC: 0.8574, Validation Loss: 0.2650, Validation ROC AUC: 0.8582\n",
      "Epoch [3/10], Loss: 0.0041, Training ROC AUC: 0.8582, Validation Loss: 0.2647, Validation ROC AUC: 0.8588\n",
      "Epoch [4/10], Loss: 0.0041, Training ROC AUC: 0.8588, Validation Loss: 0.2644, Validation ROC AUC: 0.8592\n",
      "Epoch [5/10], Loss: 0.0041, Training ROC AUC: 0.8591, Validation Loss: 0.2640, Validation ROC AUC: 0.8597\n"
     ]
    }
   ],
   "source": [
    "# PyTorch Model Training Notebook\n",
    "\n",
    "# Import Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "# Setting up the logger\n",
    "logging.basicConfig(level=logging.INFO, filename='model_training_pytorch_base.log', filemode='w',\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Create directories for storing graphs\n",
    "os.makedirs('graphs_pytorch_base', exist_ok=True)\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "\n",
    "# Load Data\n",
    "train_path = \"C:/Users/paulo/OneDrive/Documents/Binary-Classification-of-Insurance-Cross-Selling/train.csv\"\n",
    "test_path = \"C:/Users/paulo/OneDrive/Documents/Binary-Classification-of-Insurance-Cross-Selling/test.csv\"\n",
    "\n",
    "logger.info(\"Loading datasets...\")\n",
    "train_df = pd.read_csv(train_path, index_col='id')\n",
    "test_df = pd.read_csv(test_path, index_col='id')\n",
    "logger.info(\"Datasets loaded successfully.\")\n",
    "logger.info(f\"Train dataset shape: {train_df.shape}\")\n",
    "logger.info(f\"Test dataset shape: {test_df.shape}\")\n",
    "\n",
    "# Use a 40% sample of the training data\n",
    "logger.info(\"Sampling 40% of the training data...\")\n",
    "train_sample = train_df.sample(frac=0.4, random_state=42)\n",
    "test_sample = test_df.copy()  # Use the entire test set for final evaluation\n",
    "logger.info(f\"Train sample shape: {train_sample.shape}\")\n",
    "logger.info(f\"Test sample shape: {test_sample.shape}\")\n",
    "\n",
    "# Data Preprocessing\n",
    "# Copy the sample data\n",
    "train_pytorch = train_sample.copy()\n",
    "test_pytorch = test_sample.copy()\n",
    "\n",
    "# Fill missing values\n",
    "for col in train_pytorch.select_dtypes(include=['int64', 'float64']).columns:\n",
    "    train_pytorch[col] = train_pytorch[col].fillna(train_pytorch[col].median())\n",
    "    if col in test_pytorch.columns:\n",
    "        test_pytorch[col] = test_pytorch[col].fillna(test_pytorch[col].median())\n",
    "\n",
    "for col in train_pytorch.select_dtypes(include=['object']).columns:\n",
    "    train_pytorch[col] = train_pytorch[col].fillna(train_pytorch[col].mode()[0])\n",
    "    if col in test_pytorch.columns:\n",
    "        test_pytorch[col] = test_pytorch[col].fillna(test_pytorch[col].mode()[0])\n",
    "\n",
    "logger.info(\"Missing values handled.\")\n",
    "\n",
    "# Encode categorical variables using one-hot encoding\n",
    "train_pytorch = pd.get_dummies(train_pytorch)\n",
    "test_pytorch = pd.get_dummies(test_pytorch)\n",
    "\n",
    "# Ensure the test set has the same columns as the training set\n",
    "test_pytorch = test_pytorch.reindex(columns=train_pytorch.columns, fill_value=0)\n",
    "\n",
    "logger.info(\"Categorical variables encoded and aligned.\")\n",
    "\n",
    "# Split data into features and target\n",
    "X = train_pytorch.drop('Response', axis=1)\n",
    "y = train_pytorch['Response']\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(test_pytorch.drop('Response', axis=1, errors='ignore'))  # Test data doesn't have 'Response' column\n",
    "\n",
    "logger.info(\"Features standardized.\")\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "logger.info(\"Data converted to PyTorch tensors and DataLoader created.\")\n",
    "\n",
    "# Define the model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "model = SimpleNN(input_dim).to(device)\n",
    "logger.info(\"Model defined.\")\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "logger.info(\"Loss function and optimizer defined.\")\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate running loss\n",
    "        epoch_loss += loss.item()\n",
    "        total += y_batch.size(0)\n",
    "        \n",
    "        # Store true and predicted values for ROC AUC calculation\n",
    "        y_true.extend(y_batch.cpu().numpy())\n",
    "        y_pred.extend(outputs.detach().cpu().numpy())\n",
    "    \n",
    "    # Calculate training ROC AUC\n",
    "    train_roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    \n",
    "    # Calculate metrics on validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor)\n",
    "        val_loss = criterion(val_outputs, y_val_tensor).item()\n",
    "        val_roc_auc = roc_auc_score(y_val_tensor.cpu(), val_outputs.cpu())\n",
    "    \n",
    "    logger.info(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/total:.4f}, Training ROC AUC: {train_roc_auc:.4f}, Validation Loss: {val_loss:.4f}, Validation ROC AUC: {val_roc_auc:.4f}\")\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/total:.4f}, Training ROC AUC: {train_roc_auc:.4f}, Validation Loss: {val_loss:.4f}, Validation ROC AUC: {val_roc_auc:.4f}\")\n",
    "    model.train()\n",
    "\n",
    "# Final predictions on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_pytorch_test = model(X_test_tensor).cpu().numpy().flatten()\n",
    "\n",
    "# Save final predictions\n",
    "test_pytorch['Response_PyTorch'] = y_pred_pytorch_test\n",
    "test_pytorch[['Response_PyTorch']].to_csv('test_predictions_pytorch_base.csv', index=True)\n",
    "\n",
    "logger.info('Final predictions saved to test_predictions_pytorch_base.csv')\n",
    "print('Final predictions saved to test_predictions_pytorch_base.csv')\n",
    "\n",
    "# Visualize loss over epochs (if desired)\n",
    "loss_values = [loss.item() for epoch in range(num_epochs)]\n",
    "plt.plot(range(num_epochs), loss_values)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.savefig('graphs_pytorch_base/training_loss.png')\n",
    "plt.show()\n",
    "logger.info('Training loss plot saved.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
