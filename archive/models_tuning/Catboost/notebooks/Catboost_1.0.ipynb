{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Library Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "import klib\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from catboost import CatBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 00:37:26,180 - __main__ - INFO - Setup and Imports complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Setup Logging\n",
    "class Logger:\n",
    "    def __init__(self):\n",
    "        self.logger = self.setup_logging()\n",
    "    \n",
    "    def setup_logging(self):\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        log_file_name = f'training_{timestamp}.log'\n",
    "\n",
    "        if os.path.exists('training.log'):\n",
    "            os.remove('training.log')\n",
    "\n",
    "        logger = logging.getLogger(__name__)\n",
    "        logger.setLevel(logging.INFO)\n",
    "\n",
    "        console_handler = logging.StreamHandler()\n",
    "        file_handler = logging.FileHandler(log_file_name)\n",
    "\n",
    "        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "        console_handler.setFormatter(formatter)\n",
    "        file_handler.setFormatter(formatter)\n",
    "\n",
    "        logger.addHandler(console_handler)\n",
    "        logger.addHandler(file_handler)\n",
    "        return logger\n",
    "    \n",
    "    def info(self, message):\n",
    "        self.logger.info(message)\n",
    "    \n",
    "    def error(self, message):\n",
    "        self.logger.error(message)\n",
    "\n",
    "logger = Logger()\n",
    "logger.info(\"Setup and Imports complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 00:37:37,329 - __main__ - INFO - Datasets loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Data Handling Class\n",
    "class DataHandler:\n",
    "    def __init__(self, logger):\n",
    "        self.logger = logger\n",
    "\n",
    "    def load_data(self, train_path, test_path):\n",
    "        try:\n",
    "            train_df = pd.read_csv(train_path)\n",
    "            test_df = pd.read_csv(test_path)\n",
    "            self.logger.info(\"Datasets loaded successfully.\")\n",
    "            return train_df, test_df\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error loading datasets: {e}\")\n",
    "            return None, None\n",
    "\n",
    "    def rename_columns(self, df, column_mapping):\n",
    "        df.rename(columns=column_mapping, inplace=True)\n",
    "        self.logger.info(\"Columns renamed.\")\n",
    "        return df\n",
    "\n",
    "data_handler = DataHandler(logger)\n",
    "train_df, test_df = data_handler.load_data(r\"C:\\Users\\paulo\\OneDrive\\Documents\\Binary-Classification-of-Insurance-Cross-Selling\\model testing\\xgboost\\featured engineered\\klib_full_trainset.csv\", r\"C:\\Users\\paulo\\OneDrive\\Documents\\Binary-Classification-of-Insurance-Cross-Selling\\model testing\\xgboost\\featured engineered\\klib_full_testset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 00:37:37,341 - __main__ - INFO - Columns renamed.\n",
      "2024-07-15 00:37:37,342 - __main__ - INFO - Columns renamed.\n",
      "2024-07-15 00:37:42,487 - __main__ - INFO - Training set shape: (9172186, 9)\n",
      "2024-07-15 00:37:42,488 - __main__ - INFO - Validation set shape: (2293047, 9)\n"
     ]
    }
   ],
   "source": [
    "# Ensure datasets are loaded correctly\n",
    "if train_df is not None and test_df is not None:\n",
    "    new_column_names = {\n",
    "        'gender': 'Gender',\n",
    "        'age': 'Age',\n",
    "        'driving_license': 'Driving_License',\n",
    "        'region_code': 'Region_Code',\n",
    "        'previously_insured': 'Previously_Insured',\n",
    "        'vehicle_age': 'Vehicle_Age',\n",
    "        'vehicle_damage': 'Vehicle_Damage',\n",
    "        'annual_premium': 'Annual_Premium',\n",
    "        'policy_sales_channel': 'Policy_Sales_Channel',\n",
    "        'vintage': 'Vintage',\n",
    "        'response': 'Response'\n",
    "    }\n",
    "\n",
    "    train_df = data_handler.rename_columns(train_df, new_column_names)\n",
    "    test_df = data_handler.rename_columns(test_df, new_column_names)\n",
    "\n",
    "    # Split the data into training and validation sets before preprocessing\n",
    "    X = train_df.drop(columns=['Response'])\n",
    "    y = train_df['Response']\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "    logger.info(f\"Training set shape: {X_train.shape}\")\n",
    "    logger.info(f\"Validation set shape: {X_val.shape}\")\n",
    "else:\n",
    "    raise ValueError(\"Failed to load datasets. Check the file paths and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Feature Engineering Classes\n",
    "class InteractionFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.feature_names = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X['Age_Annual_Premium'] = X['Age'] * X['Annual_Premium']\n",
    "        X['Age_Vintage'] = X['Age'] * X['Vintage']\n",
    "        X['Annual_Premium_Vintage'] = X['Annual_Premium'] * X['Vintage']\n",
    "        X['Age_Region_Code'] = X['Age'] * X['Region_Code']\n",
    "        X['Vintage_Region_Code'] = X['Vintage'] * X['Region_Code']\n",
    "        X['Annual_Premium_Region_Code'] = X['Annual_Premium'] * X['Region_Code']\n",
    "        self.feature_names = X.columns.tolist()\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 00:37:42,504 - __main__ - INFO - Custom transformers defined.\n"
     ]
    }
   ],
   "source": [
    "class PolynomialFeatureGeneration(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "        self.feature_names = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.poly.fit(X[['Age', 'Annual_Premium', 'Vintage']])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        poly_features = self.poly.transform(X[['Age', 'Annual_Premium', 'Vintage']])\n",
    "        poly_feature_names = self.poly.get_feature_names_out(['Age', 'Annual_Premium', 'Vintage'])\n",
    "        poly_df = pd.DataFrame(poly_features, columns=[f'poly_{name.replace(\" \", \"_\")}' for name in poly_feature_names], index=X.index)\n",
    "        X = pd.concat([X, poly_df], axis=1)\n",
    "        self.feature_names = X.columns.tolist()\n",
    "        return X\n",
    "\n",
    "logger.info(\"Custom transformers defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 00:37:42,520 - __main__ - INFO - Preprocessing pipeline defined.\n",
      "2024-07-15 00:37:47,584 - __main__ - INFO - Training set after preprocessing: (9172186, 21)\n",
      "2024-07-15 00:37:47,585 - __main__ - INFO - Validation set after preprocessing: (2293047, 21)\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Preprocessing and Model Preparation\n",
    "class PreprocessingPipeline:\n",
    "    def __init__(self, logger):\n",
    "        self.logger = logger\n",
    "        self.pipeline = self.create_pipeline()\n",
    "\n",
    "    def create_pipeline(self):\n",
    "        pipeline = Pipeline([\n",
    "            ('interactions', InteractionFeatures()),\n",
    "            ('poly_features', PolynomialFeatureGeneration()),\n",
    "            ('scaling', StandardScaler(with_mean=False))  # Preserve feature names\n",
    "        ])\n",
    "        self.logger.info(\"Preprocessing pipeline defined.\")\n",
    "        return pipeline\n",
    "\n",
    "    def preprocess_data(self, X_train, X_val, y_train):\n",
    "        X_train_preprocessed = self.pipeline.fit_transform(X_train, y_train)\n",
    "        X_val_preprocessed = self.pipeline.transform(X_val)\n",
    "\n",
    "        feature_names = self.pipeline.named_steps['poly_features'].feature_names\n",
    "        X_train_preprocessed = pd.DataFrame(X_train_preprocessed, columns=feature_names)\n",
    "        X_val_preprocessed = pd.DataFrame(X_val_preprocessed, columns=feature_names)\n",
    "\n",
    "        self.logger.info(f\"Training set after preprocessing: {X_train_preprocessed.shape}\")\n",
    "        self.logger.info(f\"Validation set after preprocessing: {X_val_preprocessed.shape}\")\n",
    "        return X_train_preprocessed, X_val_preprocessed\n",
    "\n",
    "# Usage Example\n",
    "preprocessor = PreprocessingPipeline(logger)\n",
    "X_train_preprocessed, X_val_preprocessed = preprocessor.preprocess_data(X_train, X_val, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 00:37:47,596 - __main__ - INFO - Starting hyperparameter optimization with Optuna.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Cell 6: Hyperparameter Optimization with Optuna\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'eval_metric': 'AUC',\n",
    "        'iterations': trial.suggest_int('iterations', 500, 1000),  # Higher range\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),  # Focused range\n",
    "        'depth': trial.suggest_int('depth', 6, 16),  # Depth of the tree\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-4, 10.0, log=True),  # L2 regularization term\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),  # Bagging temperature\n",
    "        'random_strength': trial.suggest_float('random_strength', 0.0, 1.0),  # Random strength\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255),  # Number of splits for numerical features\n",
    "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1.0, 10.0)  # Weighting for positive class\n",
    "    }\n",
    "\n",
    "    model = CatBoostClassifier(**param, verbose=100)\n",
    "\n",
    "    model.fit(X_train_preprocessed, y_train, eval_set=(X_val_preprocessed, y_val), early_stopping_rounds=100)\n",
    "    \n",
    "    y_pred = model.predict_proba(X_val_preprocessed)[:, 1]\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    return auc\n",
    "\n",
    "logger.info(\"Starting hyperparameter optimization with Optuna.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 00:37:47,614 - __main__ - INFO - Starting hyperparameter optimization with Optuna.\n",
      "[I 2024-07-15 00:37:48,345] A new study created in RDB with name: my_study_20240715_003747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.8430959\tbest: 0.8430959 (0)\ttotal: 798ms\tremaining: 10m 28s\n",
      "100:\ttest: 0.8668733\tbest: 0.8668733 (100)\ttotal: 1m\tremaining: 6m 53s\n",
      "200:\ttest: 0.8704541\tbest: 0.8704541 (200)\ttotal: 1m 57s\tremaining: 5m 44s\n",
      "300:\ttest: 0.8725848\tbest: 0.8725848 (300)\ttotal: 2m 55s\tremaining: 4m 43s\n",
      "400:\ttest: 0.8739455\tbest: 0.8739455 (400)\ttotal: 3m 52s\tremaining: 3m 44s\n",
      "500:\ttest: 0.8748214\tbest: 0.8748214 (500)\ttotal: 4m 50s\tremaining: 2m 46s\n",
      "600:\ttest: 0.8756290\tbest: 0.8756290 (600)\ttotal: 5m 46s\tremaining: 1m 47s\n",
      "700:\ttest: 0.8761174\tbest: 0.8761174 (700)\ttotal: 6m 41s\tremaining: 49.8s\n",
      "787:\ttest: 0.8765037\tbest: 0.8765037 (787)\ttotal: 7m 29s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.876503697\n",
      "bestIteration = 787\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-15 00:45:21,046] Trial 0 finished with value: 0.8765036970247349 and parameters: {'iterations': 788, 'learning_rate': 0.08266837636003951, 'depth': 6, 'l2_leaf_reg': 0.0006653839603779793, 'bagging_temperature': 0.5268966402061496, 'random_strength': 0.40020198621011127, 'border_count': 187, 'scale_pos_weight': 5.964044965343005}. Best is trial 0 with value: 0.8765036970247349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.8573434\tbest: 0.8573434 (0)\ttotal: 3.06s\tremaining: 48m 9s\n",
      "100:\ttest: 0.8719427\tbest: 0.8719427 (100)\ttotal: 3m 52s\tremaining: 32m 16s\n",
      "200:\ttest: 0.8741726\tbest: 0.8741726 (200)\ttotal: 7m 36s\tremaining: 28m 5s\n",
      "300:\ttest: 0.8750929\tbest: 0.8750929 (300)\ttotal: 11m 22s\tremaining: 24m 18s\n",
      "400:\ttest: 0.8754818\tbest: 0.8754818 (400)\ttotal: 15m 13s\tremaining: 20m 37s\n",
      "500:\ttest: 0.8755999\tbest: 0.8756097 (476)\ttotal: 19m 9s\tremaining: 16m 56s\n",
      "600:\ttest: 0.8756061\tbest: 0.8756256 (580)\ttotal: 23m 6s\tremaining: 13m 11s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.8756256471\n",
      "bestIteration = 580\n",
      "\n",
      "Shrink model to first 581 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-15 01:11:46,579] Trial 1 finished with value: 0.8756256470517518 and parameters: {'iterations': 944, 'learning_rate': 0.07322030796487806, 'depth': 15, 'l2_leaf_reg': 0.10783585578688876, 'bagging_temperature': 0.11435566336197511, 'random_strength': 0.45667090827051815, 'border_count': 122, 'scale_pos_weight': 1.431125686046817}. Best is trial 0 with value: 0.8765036970247349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.8575774\tbest: 0.8575774 (0)\ttotal: 2.52s\tremaining: 26m 33s\n",
      "100:\ttest: 0.8656465\tbest: 0.8656465 (100)\ttotal: 3m 53s\tremaining: 20m 28s\n",
      "200:\ttest: 0.8694602\tbest: 0.8694602 (200)\ttotal: 7m 20s\tremaining: 15m 45s\n",
      "300:\ttest: 0.8718775\tbest: 0.8718775 (300)\ttotal: 10m 37s\tremaining: 11m 43s\n",
      "400:\ttest: 0.8734509\tbest: 0.8734509 (400)\ttotal: 13m 56s\tremaining: 8m 3s\n",
      "500:\ttest: 0.8746802\tbest: 0.8746802 (500)\ttotal: 17m 13s\tremaining: 4m 32s\n",
      "600:\ttest: 0.8757017\tbest: 0.8757017 (600)\ttotal: 20m 31s\tremaining: 1m 5s\n",
      "632:\ttest: 0.8759619\tbest: 0.8759619 (632)\ttotal: 21m 33s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8759619324\n",
      "bestIteration = 632\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-15 01:33:26,897] Trial 2 finished with value: 0.8759619323908174 and parameters: {'iterations': 633, 'learning_rate': 0.021490504945601157, 'depth': 14, 'l2_leaf_reg': 0.005320015004774967, 'bagging_temperature': 0.275332315661884, 'random_strength': 0.09416802742280295, 'border_count': 242, 'scale_pos_weight': 4.865618530809193}. Best is trial 0 with value: 0.8765036970247349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.8457345\tbest: 0.8457345 (0)\ttotal: 744ms\tremaining: 7m 36s\n",
      "100:\ttest: 0.8664239\tbest: 0.8664239 (100)\ttotal: 1m 1s\tremaining: 5m 13s\n",
      "200:\ttest: 0.8683264\tbest: 0.8683264 (200)\ttotal: 2m 1s\tremaining: 4m 10s\n",
      "300:\ttest: 0.8692684\tbest: 0.8692684 (300)\ttotal: 3m 1s\tremaining: 3m 9s\n",
      "400:\ttest: 0.8698032\tbest: 0.8698032 (400)\ttotal: 4m 2s\tremaining: 2m 9s\n",
      "500:\ttest: 0.8701778\tbest: 0.8701778 (500)\ttotal: 5m 3s\tremaining: 1m 9s\n",
      "600:\ttest: 0.8704567\tbest: 0.8704567 (600)\ttotal: 6m 5s\tremaining: 8.51s\n",
      "614:\ttest: 0.8704830\tbest: 0.8704830 (614)\ttotal: 6m 13s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.87048302\n",
      "bestIteration = 614\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-15 01:39:43,792] Trial 3 finished with value: 0.8704830200447227 and parameters: {'iterations': 615, 'learning_rate': 0.09602776012440167, 'depth': 7, 'l2_leaf_reg': 1.1889402626460455, 'bagging_temperature': 0.4527591043844478, 'random_strength': 0.2083722843054907, 'border_count': 35, 'scale_pos_weight': 4.235328011651097}. Best is trial 0 with value: 0.8765036970247349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.8490549\tbest: 0.8490549 (0)\ttotal: 764ms\tremaining: 11m 30s\n",
      "100:\ttest: 0.8634847\tbest: 0.8634847 (100)\ttotal: 1m 7s\tremaining: 8m 59s\n",
      "200:\ttest: 0.8673243\tbest: 0.8673243 (200)\ttotal: 2m 11s\tremaining: 7m 38s\n",
      "300:\ttest: 0.8694939\tbest: 0.8694939 (300)\ttotal: 3m 14s\tremaining: 6m 28s\n",
      "400:\ttest: 0.8710331\tbest: 0.8710331 (400)\ttotal: 4m 18s\tremaining: 5m 24s\n",
      "500:\ttest: 0.8722443\tbest: 0.8722443 (500)\ttotal: 5m 24s\tremaining: 4m 20s\n",
      "600:\ttest: 0.8730666\tbest: 0.8730666 (600)\ttotal: 6m 28s\tremaining: 3m 15s\n",
      "700:\ttest: 0.8738101\tbest: 0.8738101 (700)\ttotal: 7m 33s\tremaining: 2m 11s\n",
      "800:\ttest: 0.8743602\tbest: 0.8743602 (800)\ttotal: 8m 39s\tremaining: 1m 6s\n",
      "900:\ttest: 0.8748273\tbest: 0.8748273 (900)\ttotal: 9m 45s\tremaining: 1.95s\n",
      "903:\ttest: 0.8748345\tbest: 0.8748345 (903)\ttotal: 9m 47s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8748345093\n",
      "bestIteration = 903\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-15 01:49:34,500] Trial 4 finished with value: 0.8748345092511387 and parameters: {'iterations': 904, 'learning_rate': 0.03362739156180403, 'depth': 8, 'l2_leaf_reg': 2.0252122607403105, 'bagging_temperature': 0.30539698180222474, 'random_strength': 0.7057068275372328, 'border_count': 174, 'scale_pos_weight': 7.080110898781119}. Best is trial 0 with value: 0.8765036970247349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.8568741\tbest: 0.8568741 (0)\ttotal: 4.49s\tremaining: 1h 10m 24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training has stopped (degenerate solution on iteration 84, probably too small l2-regularization, try to increase it)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.8670375126\n",
      "bestIteration = 83\n",
      "\n",
      "Shrink model to first 84 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-15 01:55:03,685] Trial 5 finished with value: 0.8670375448444045 and parameters: {'iterations': 941, 'learning_rate': 0.0339022242577684, 'depth': 16, 'l2_leaf_reg': 0.0005424291268140061, 'bagging_temperature': 0.22849207410563943, 'random_strength': 0.508196089662048, 'border_count': 159, 'scale_pos_weight': 7.481409004140483}. Best is trial 0 with value: 0.8765036970247349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.8519262\tbest: 0.8519262 (0)\ttotal: 1.21s\tremaining: 12m 54s\n",
      "100:\ttest: 0.8701715\tbest: 0.8701715 (100)\ttotal: 1m 44s\tremaining: 9m 16s\n",
      "200:\ttest: 0.8734129\tbest: 0.8734129 (200)\ttotal: 3m 23s\tremaining: 7m 25s\n",
      "300:\ttest: 0.8750143\tbest: 0.8750143 (300)\ttotal: 5m 3s\tremaining: 5m 42s\n",
      "400:\ttest: 0.8758532\tbest: 0.8758539 (399)\ttotal: 6m 43s\tremaining: 4m 1s\n",
      "500:\ttest: 0.8763895\tbest: 0.8763895 (500)\ttotal: 8m 24s\tremaining: 2m 20s\n",
      "600:\ttest: 0.8767926\tbest: 0.8767926 (600)\ttotal: 10m 5s\tremaining: 40.3s\n",
      "640:\ttest: 0.8769058\tbest: 0.8769066 (639)\ttotal: 10m 45s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8769066039\n",
      "bestIteration = 639\n",
      "\n",
      "Shrink model to first 640 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-15 02:05:54,505] Trial 6 finished with value: 0.8769066038508856 and parameters: {'iterations': 641, 'learning_rate': 0.08734764043570355, 'depth': 10, 'l2_leaf_reg': 0.05880114235678777, 'bagging_temperature': 0.48456435876067216, 'random_strength': 0.9865673116409905, 'border_count': 152, 'scale_pos_weight': 2.4866155360121747}. Best is trial 6 with value: 0.8769066038508856.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.8582429\tbest: 0.8582429 (0)\ttotal: 5.44s\tremaining: 1h 9m 35s\n",
      "100:\ttest: 0.8691676\tbest: 0.8691676 (100)\ttotal: 8m 4s\tremaining: 53m 22s\n",
      "200:\ttest: 0.8732964\tbest: 0.8732964 (200)\ttotal: 15m 28s\tremaining: 43m 38s\n",
      "300:\ttest: 0.8753693\tbest: 0.8753693 (300)\ttotal: 22m 52s\tremaining: 35m 29s\n",
      "400:\ttest: 0.8767723\tbest: 0.8767723 (400)\ttotal: 30m 15s\tremaining: 27m 41s\n",
      "500:\ttest: 0.8776457\tbest: 0.8776457 (500)\ttotal: 37m 44s\tremaining: 20m 6s\n",
      "600:\ttest: 0.8782715\tbest: 0.8782715 (600)\ttotal: 45m 11s\tremaining: 12m 33s\n",
      "700:\ttest: 0.8786939\tbest: 0.8786939 (700)\ttotal: 52m 48s\tremaining: 5m 2s\n"
     ]
    }
   ],
   "source": [
    "# Increase Optuna verbosity\n",
    "optuna.logging.set_verbosity(optuna.logging.DEBUG)\n",
    "\n",
    "logger.info(\"Starting hyperparameter optimization with Optuna.\")\n",
    "\n",
    "# Generate a unique filename for each run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "sqlite_file_path = os.path.join(r'C:\\Users\\paulo\\OneDrive\\Documents\\Binary-Classification-of-Insurance-Cross-Selling\\model testing\\Catboost', f'optuna_study_{timestamp}.db')\n",
    "\n",
    "study = optuna.create_study(storage=f'sqlite:///{sqlite_file_path}', study_name=f'my_study_{timestamp}', direction='maximize')\n",
    "study.optimize(objective, n_trials=25)  # Adjust the number of trials as needed\n",
    "\n",
    "logger.info(f\"Best trial parameters: {study.best_trial.params}\")\n",
    "logger.info(f\"Best trial AUC: {study.best_trial.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model using the best parameters\n",
    "best_params = study.best_trial.params\n",
    "final_model = CatBoostClassifier(**best_params, verbose=0)\n",
    "final_model.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# Validate the final model\n",
    "final_preds = final_model.predict_proba(X_val_preprocessed)[:, 1]\n",
    "final_auc = roc_auc_score(y_val, final_preds)\n",
    "logger.info(f\"Final model AUC on validation set: {final_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "optuna.visualization.plot_optimization_history(study)\n",
    "optuna.visualization.plot_parallel_coordinate(study)\n",
    "optuna.visualization.plot_slice(study)\n",
    "optuna.visualization.plot_contour(study)\n",
    "optuna.visualization.plot_param_importances(study)\n",
    "study.best_trial\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
