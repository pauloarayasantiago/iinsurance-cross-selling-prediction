{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\dask\\dataframe\\__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "2024-07-13 17:44:42,825 - __main__ - INFO - Train dataset shape: (11465233, 11)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 464, in format\n",
      "    return self._format(record)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 460, in _format\n",
      "    return self._fmt % values\n",
      "           ~~~~~~~~~~^~~~~~~~\n",
      "KeyError: 'levellevel'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 1160, in emit\n",
      "    msg = self.format(record)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 999, in format\n",
      "    return fmt.format(record)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 706, in format\n",
      "    s = self.formatMessage(record)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 675, in formatMessage\n",
      "    return self._style.format(record)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 466, in format\n",
      "    raise ValueError('Formatting field not found in record: %s' % e)\n",
      "ValueError: Formatting field not found in record: 'levellevel'\n",
      "Call stack:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\paulo\\AppData\\Local\\Temp\\ipykernel_1260\\352468796.py\", line 40, in <module>\n",
      "    logger.info(f\"Train dataset shape: {train_df.shape}\")\n",
      "Message: 'Train dataset shape: (11465233, 11)'\n",
      "Arguments: ()\n",
      "2024-07-13 17:44:42,833 - __main__ - INFO - Test dataset shape: (7669866, 10)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 464, in format\n",
      "    return self._format(record)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 460, in _format\n",
      "    return self._fmt % values\n",
      "           ~~~~~~~~~~^~~~~~~~\n",
      "KeyError: 'levellevel'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 1160, in emit\n",
      "    msg = self.format(record)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 999, in format\n",
      "    return fmt.format(record)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 706, in format\n",
      "    s = self.formatMessage(record)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 675, in formatMessage\n",
      "    return self._style.format(record)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 466, in format\n",
      "    raise ValueError('Formatting field not found in record: %s' % e)\n",
      "ValueError: Formatting field not found in record: 'levellevel'\n",
      "Call stack:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\paulo\\AppData\\Local\\Temp\\ipykernel_1260\\352468796.py\", line 41, in <module>\n",
      "    logger.info(f\"Test dataset shape: {test_df.shape}\")\n",
      "Message: 'Test dataset shape: (7669866, 10)'\n",
      "Arguments: ()\n",
      "2024-07-13 17:44:43,224 - __main__ - INFO - Interaction features created\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 464, in format\n",
      "    return self._format(record)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 460, in _format\n",
      "    return self._fmt % values\n",
      "           ~~~~~~~~~~^~~~~~~~\n",
      "KeyError: 'levellevel'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 1160, in emit\n",
      "    msg = self.format(record)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 999, in format\n",
      "    return fmt.format(record)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 706, in format\n",
      "    s = self.formatMessage(record)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 675, in formatMessage\n",
      "    return self._style.format(record)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 466, in format\n",
      "    raise ValueError('Formatting field not found in record: %s' % e)\n",
      "ValueError: Formatting field not found in record: 'levellevel'\n",
      "Call stack:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\paulo\\AppData\\Local\\Temp\\ipykernel_1260\\352468796.py\", line 54, in <module>\n",
      "    logger.info(f\"Interaction features created\")\n",
      "Message: 'Interaction features created'\n",
      "Arguments: ()\n",
      "c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "2024-07-13 17:45:13,825 - __main__ - INFO - Target encoding performed for categorical variables.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 464, in format\n",
      "    return self._format(record)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 460, in _format\n",
      "    return self._fmt % values\n",
      "           ~~~~~~~~~~^~~~~~~~\n",
      "KeyError: 'levellevel'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 1160, in emit\n",
      "    msg = self.format(record)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 999, in format\n",
      "    return fmt.format(record)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 706, in format\n",
      "    s = self.formatMessage(record)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 675, in formatMessage\n",
      "    return self._style.format(record)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 466, in format\n",
      "    raise ValueError('Formatting field not found in record: %s' % e)\n",
      "ValueError: Formatting field not found in record: 'levellevel'\n",
      "Call stack:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\paulo\\AppData\\Local\\Temp\\ipykernel_1260\\352468796.py\", line 60, in <module>\n",
      "    logger.info(f\"Target encoding performed for categorical variables.\")\n",
      "Message: 'Target encoding performed for categorical variables.'\n",
      "Arguments: ()\n",
      "2024-07-13 17:45:15,268 - __main__ - INFO - Polynomial features created\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 464, in format\n",
      "    return self._format(record)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 460, in _format\n",
      "    return self._fmt % values\n",
      "           ~~~~~~~~~~^~~~~~~~\n",
      "KeyError: 'levellevel'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 1160, in emit\n",
      "    msg = self.format(record)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 999, in format\n",
      "    return fmt.format(record)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 706, in format\n",
      "    s = self.formatMessage(record)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 675, in formatMessage\n",
      "    return self._style.format(record)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\logging\\__init__.py\", line 466, in format\n",
      "    raise ValueError('Formatting field not found in record: %s' % e)\n",
      "ValueError: Formatting field not found in record: 'levellevel'\n",
      "Call stack:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\paulo\\AppData\\Local\\Temp\\ipykernel_1260\\352468796.py\", line 73, in <module>\n",
      "    logger.info(f\"Polynomial features created\")\n",
      "Message: 'Polynomial features created'\n",
      "Arguments: ()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from category_encoders import TargetEncoder\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Configure logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Create handlers\n",
    "console_handler = logging.StreamHandler()\n",
    "file_handler = logging.FileHandler('training.log')\n",
    "\n",
    "# Create formatters and add them to the handlers\n",
    "console_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "file_format = logging.Formatter('%(asctime)s - %(name)s - %(levellevel)s - %(message)s')\n",
    "console_handler.setFormatter(console_format)\n",
    "file_handler.setFormatter(file_format)\n",
    "\n",
    "# Add handlers to the logger\n",
    "logger.addHandler(console_handler)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# Load datasets\n",
    "train_df = pd.read_csv(r\"C:\\Users\\paulo\\OneDrive\\Documents\\Binary-Classification-of-Insurance-Cross-Selling\\preprocessed_train.csv\")\n",
    "test_df = pd.read_csv(r\"C:\\Users\\paulo\\OneDrive\\Documents\\Binary-Classification-of-Insurance-Cross-Selling\\preprocessed_test.csv\")\n",
    "\n",
    "# Drop ID column from training and test data\n",
    "train_df.drop(columns=['id'], inplace=True)\n",
    "test_df.drop(columns=['id'], inplace=True)\n",
    "\n",
    "logger.info(f\"Train dataset shape: {train_df.shape}\")\n",
    "logger.info(f\"Test dataset shape: {test_df.shape}\")\n",
    "\n",
    "# Interaction features\n",
    "interaction_features = {\n",
    "    'Age_Annual_Premium': train_df['Age'] * train_df['Annual_Premium'],\n",
    "    'Age_Vintage': train_df['Age'] * train_df['Vintage'],\n",
    "    'Annual_Premium_Vintage': train_df['Annual_Premium'] * train_df['Vintage'],\n",
    "    'Age_Region_Code': train_df['Age'] * train_df['Region_Code'],\n",
    "    'Vintage_Region_Code': train_df['Vintage'] * train_df['Region_Code'],\n",
    "    'Annual_Premium_Region_Code': train_df['Annual_Premium'] * train_df['Region_Code']\n",
    "}\n",
    "train_df = train_df.assign(**interaction_features)\n",
    "\n",
    "logger.info(f\"Interaction features created\")\n",
    "\n",
    "# Target encoding\n",
    "target_enc = TargetEncoder(cols=['Gender', 'Vehicle_Age', 'Vehicle_Damage'])\n",
    "train_df = target_enc.fit_transform(train_df, train_df['Response'])\n",
    "\n",
    "logger.info(f\"Target encoding performed for categorical variables.\")\n",
    "\n",
    "# Polynomial features\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "poly_features = poly.fit_transform(train_df[['Age', 'Annual_Premium', 'Vintage']])\n",
    "poly_feature_names = poly.get_feature_names_out(['Age', 'Annual_Premium', 'Vintage'])\n",
    "\n",
    "# Create a DataFrame for polynomial features ensuring no duplicates with existing feature names\n",
    "poly_df = pd.DataFrame(poly_features, columns=[f'poly_{name.replace(\" \", \"_\")}' for name in poly_feature_names], index=train_df.index)\n",
    "\n",
    "# Concatenate polynomial features with train_df ensuring no duplicates\n",
    "train_df = pd.concat([train_df, poly_df], axis=1)\n",
    "\n",
    "logger.info(f\"Polynomial features created\")\n",
    "\n",
    "# Apply StandardScaler to the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(train_df.drop(columns=['Response']))\n",
    "scaled_df = pd.DataFrame(scaled_features, columns=train_df.columns.drop('Response').str.replace(' ', '_'))\n",
    "scaled_df['Response'] = train_df['Response'].values\n",
    "\n",
    "# Handle imbalanced data using SMOTE\n",
    "X_resampled, y_resampled = SMOTE().fit_resample(scaled_df.drop(columns=['Response']), scaled_df['Response'])\n",
    "\n",
    "logger.info(f\"Data resampled using SMOTE. New shape: {X_resampled.shape}\")\n",
    "\n",
    "# Save the transformed datasets to CSV\n",
    "X_resampled.to_csv('X_transformed.csv', index=False)\n",
    "y_resampled.to_csv('y_transformed.csv', index=False)\n",
    "\n",
    "logger.info(\"Transformed datasets saved to CSV files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, load the transformed datasets from CSV\n",
    "# X_resampled = pd.read_csv('X_transformed.csv')\n",
    "# y_resampled = pd.read_csv('y_transformed.csv')\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n",
    "\n",
    "logger.info(f\"Training set shape: {X_train.shape}\")\n",
    "logger.info(f\"Validation set shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Define the parameter grid\n",
    "param_dist = {\n",
    "    'learning_rate': np.linspace(0.03, 0.1, 10),\n",
    "    'num_leaves': np.arange(60, 121, 10),\n",
    "    'max_depth': np.arange(10, 16),\n",
    "    'min_data_in_leaf': np.arange(10, 51, 10),\n",
    "    'bagging_fraction': np.linspace(0.6, 0.8, 5),\n",
    "    'feature_fraction': np.linspace(0.6, 0.8, 5),\n",
    "    'lambda_l1': np.linspace(0.0, 1.0, 5),\n",
    "    'lambda_l2': np.linspace(0.0, 1.0, 5),\n",
    "    'bagging_freq': np.arange(1, 8)\n",
    "}\n",
    "\n",
    "# Initialize the LightGBM classifier\n",
    "lgb_model = lgb.LGBMClassifier(objective='binary', metric='auc')\n",
    "\n",
    "# Define the scoring function\n",
    "scorer = make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=lgb_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=1,  # Increase number of iterations for better search\n",
    "    scoring=scorer,\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best trial\n",
    "best_model = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "logger.info(f\"Best AUC: {best_score}\")\n",
    "logger.info(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Save the best trial parameters\n",
    "pd.DataFrame([best_params]).to_csv('best_params_randomsearch.csv', index=False)\n",
    "\n",
    "# Load the best parameters from the saved file (if needed)\n",
    "best_params_loaded = pd.read_csv('best_params_randomsearch.csv').to_dict(orient='records')[0]\n",
    "\n",
    "# Optionally, you can refit the model on the entire training set using the best parameters\n",
    "best_model_retrained = lgb.LGBMClassifier(**best_params_loaded)\n",
    "best_model_retrained.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the best model on the training set\n",
    "train_preds = best_model_retrained.predict_proba(X_train)[:, 1]\n",
    "train_auc = roc_auc_score(y_train, train_preds)\n",
    "\n",
    "# Evaluate the best model on the validation set\n",
    "val_preds = best_model_retrained.predict_proba(X_val)[:, 1]\n",
    "val_auc = roc_auc_score(y_val, val_preds)\n",
    "\n",
    "logger.info(f\"Training AUC with best parameters: {train_auc}\")\n",
    "logger.info(f\"Validation AUC with best parameters: {val_auc}\")\n",
    "\n",
    "# Check for overfitting\n",
    "overfit_threshold = 0.05  # Adjust the threshold as needed\n",
    "overfit_metric = abs(train_auc - val_auc)\n",
    "if overfit_metric > overfit_threshold:\n",
    "    logger.warning(f\"Overfitting detected: Train AUC - {train_auc}, Val AUC - {val_auc}, Difference - {overfit_metric}\")\n",
    "else:\n",
    "    logger.info(f\"No overfitting detected: Train AUC - {train_auc}, Val AUC - {val_auc}, Difference - {overfit_metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a LightGBM model with best params\n",
    "train_data = lgb.Dataset(X_train, label=y_train, free_raw_data=False)\n",
    "val_data = lgb.Dataset(X_val, label=y_val, reference=train_data, free_raw_data=False)\n",
    "\n",
    "model = lgb.train(\n",
    "    best_params_loaded,\n",
    "    train_data,\n",
    "    num_boost_round=200,\n",
    "    valid_sets=[train_data, val_data],\n",
    "    early_stopping_rounds=20,\n",
    "    verbose_eval=10\n",
    ")\n",
    "\n",
    "# Predict on train and validation set\n",
    "y_train_pred = model.predict(X_train, num_iteration=model.best_iteration)\n",
    "y_val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "\n",
    "# Evaluation metrics\n",
    "train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "val_auc = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "logger.info(f\"Final Train AUC: {train_auc}\")\n",
    "logger.info(f\"Final Validation AUC: {val_auc}\")\n",
    "\n",
    "# Feature Importance\n",
    "importance = model.feature_importance(importance_type='split')\n",
    "feature_names = model.feature_name()\n",
    "\n",
    "# Create a DataFrame for feature importance\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importance\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Save feature importance to CSV\n",
    "feature_importance_df.to_csv(\"feature_importance.csv\", index=False)\n",
    "logger.info(\"Feature importance saved as feature_importance.csv\")\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(data=feature_importance_df, x='Importance', y='Feature')\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.savefig(\"feature_importance.png\")\n",
    "logger.info(\"Feature importance plot saved as feature_importance.png\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Save the model and metrics\n",
    "joblib.dump(model, \"lightgbm_model_best.pkl\")\n",
    "logger.info(\"Model saved as lightgbm_model_best.pkl\")\n",
    "\n",
    "# Save the metrics to a CSV file\n",
    "metrics = {\n",
    "    \"train_auc\": train_auc,\n",
    "    \"val_auc\": val_auc\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics, index=[0])\n",
    "metrics_df.to_csv(\"model_metrics.csv\", index=False)\n",
    "logger.info(\"Model metrics saved as model_metrics.csv\")\n",
    "\n",
    "# Final log message\n",
    "logger.info(\"Training and evaluation process completed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
