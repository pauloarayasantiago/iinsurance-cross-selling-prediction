{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\dask\\dataframe\\__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "2024-07-13 20:13:36,317 - __main__ - INFO - Setup and Imports complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from category_encoders import TargetEncoder\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the current timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Define the log file name with the timestamp\n",
    "log_file_name = f'training_{timestamp}.log'\n",
    "\n",
    "# Check if a similar log file exists and remove it if necessary\n",
    "if os.path.exists('training.log'):\n",
    "    os.remove('training.log')\n",
    "\n",
    "# Configure logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Create handlers\n",
    "console_handler = logging.StreamHandler()\n",
    "file_handler = logging.FileHandler(log_file_name)\n",
    "\n",
    "# Set log level for handlers\n",
    "console_handler.setLevel(logging.INFO)\n",
    "file_handler.setLevel(logging.INFO)\n",
    "\n",
    "# Create formatters and add them to the handlers\n",
    "console_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "file_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "console_handler.setFormatter(console_format)\n",
    "file_handler.setFormatter(file_format)\n",
    "\n",
    "# Add handlers to the logger\n",
    "logger.addHandler(console_handler)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# Example logging usage\n",
    "logger.info(\"Setup and Imports complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cell 2: Load and Prepare Data\n",
    "# logger.info(\"Loading and preparing data...\")\n",
    "\n",
    "# def reduce_memory_usage(df):\n",
    "#     \"\"\"Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.\"\"\"\n",
    "#     start_mem = df.memory_usage().sum() / 1024**2\n",
    "#     for col in df.columns:\n",
    "#         col_type = df[col].dtype\n",
    "        \n",
    "#         if col_type != object:\n",
    "#             c_min = df[col].min()\n",
    "#             c_max = df[col].max()\n",
    "            \n",
    "#             if str(col_type)[:3] == 'int':\n",
    "#                 if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "#                     df[col] = df[col].astype(np.int8)\n",
    "#                 elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "#                     df[col] = df[col].astype(np.int16)\n",
    "#                 elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "#                     df[col] = df[col].astype(np.int32)\n",
    "#                 elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "#                     df[col] = df[col].astype(np.int64)  \n",
    "#             else:\n",
    "#                 if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "#                     df[col] = df[col].astype(np.float16)\n",
    "#                 elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "#                     df[col] = df[col].astype(np.float32)\n",
    "#                 else:\n",
    "#                     df[col] = df[col].astype(np.float64)\n",
    "#         else:\n",
    "#             df[col] = df[col].astype('category')\n",
    "\n",
    "#     end_mem = df.memory_usage().sum() / 1024**2\n",
    "#     print(f'Memory usage after optimization is: {end_mem:.2f} MB')\n",
    "#     print(f'Decreased by {(100 * (start_mem - end_mem) / start_mem):.2f}%')\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# # Load datasets and reduce memory usage\n",
    "# train_df = pd.read_csv(r\"C:\\Users\\paulo\\OneDrive\\Documents\\Binary-Classification-of-Insurance-Cross-Selling\\preprocessed_train.csv\")\n",
    "# test_df = pd.read_csv(r\"C:\\Users\\paulo\\OneDrive\\Documents\\Binary-Classification-of-Insurance-Cross-Selling\\preprocessed_test.csv\")\n",
    "\n",
    "# train_df = reduce_memory_usage(train_df)\n",
    "# test_df = reduce_memory_usage(test_df)\n",
    "\n",
    "# # Drop ID column from training and test data\n",
    "# train_df.drop(columns=['id'], inplace=True)\n",
    "# test_df.drop(columns=['id'], inplace=True)\n",
    "\n",
    "# logger.info(f\"Train dataset shape: {train_df.shape}\")\n",
    "# logger.info(f\"Test dataset shape: {test_df.shape}\")\n",
    "\n",
    "# # Split the data into training and validation sets before preprocessing\n",
    "# X = train_df.drop(columns=['Response'])\n",
    "# y = train_df['Response']\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# logger.info(f\"Training set shape: {X_train.shape}\")\n",
    "# logger.info(f\"Validation set shape: {X_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cell 3: Define Custom Transformers\n",
    "# logger.info(\"Defining custom transformers...\")\n",
    "\n",
    "# class InteractionFeatures(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "    \n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "    \n",
    "#     def transform(self, X):\n",
    "#         X = X.copy()\n",
    "#         X['Age_Annual_Premium'] = X['Age'] * X['Annual_Premium']\n",
    "#         X['Age_Vintage'] = X['Age'] * X['Vintage']\n",
    "#         X['Annual_Premium_Vintage'] = X['Annual_Premium'] * X['Vintage']\n",
    "#         X['Age_Region_Code'] = X['Age'] * X['Region_Code']\n",
    "#         X['Vintage_Region_Code'] = X['Vintage'] * X['Region_Code']\n",
    "#         X['Annual_Premium_Region_Code'] = X['Annual_Premium'] * X['Region_Code']\n",
    "#         return X\n",
    "\n",
    "# class TargetEncoding(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self):\n",
    "#         self.encoder = TargetEncoder(cols=['Gender', 'Vehicle_Age', 'Vehicle_Damage'])\n",
    "    \n",
    "#     def fit(self, X, y=None):\n",
    "#         self.encoder.fit(X, y)\n",
    "#         return self\n",
    "    \n",
    "#     def transform(self, X):\n",
    "#         return self.encoder.transform(X)\n",
    "\n",
    "# class PolynomialFeatureGeneration(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self):\n",
    "#         self.poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "    \n",
    "#     def fit(self, X, y=None):\n",
    "#         self.poly.fit(X[['Age', 'Annual_Premium', 'Vintage']])\n",
    "#         return self\n",
    "    \n",
    "#     def transform(self, X):\n",
    "#         poly_features = self.poly.transform(X[['Age', 'Annual_Premium', 'Vintage']])\n",
    "#         poly_feature_names = self.poly.get_feature_names_out(['Age', 'Annual_Premium', 'Vintage'])\n",
    "#         poly_df = pd.DataFrame(poly_features, columns=[f'poly_{name.replace(\" \", \"_\")}' for name in poly_feature_names], index=X.index)\n",
    "#         X = pd.concat([X, poly_df], axis=1)\n",
    "#         return X\n",
    "\n",
    "# logger.info(\"Custom transformers defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cell 4: Define Preprocessing Pipeline\n",
    "# logger.info(\"Defining preprocessing pipeline...\")\n",
    "\n",
    "# pipeline = Pipeline([\n",
    "#     ('interactions', InteractionFeatures()),\n",
    "#     ('target_encoding', TargetEncoding()),\n",
    "#     ('poly_features', PolynomialFeatureGeneration()),\n",
    "#     ('scaling', StandardScaler())\n",
    "# ])\n",
    "\n",
    "# # Apply the preprocessing pipeline\n",
    "# X_train_preprocessed = pipeline.fit_transform(X_train, y_train)\n",
    "# X_val_preprocessed = pipeline.transform(X_val)\n",
    "\n",
    "# logger.info(f\"Training set after preprocessing: {X_train_preprocessed.shape}\")\n",
    "# logger.info(f\"Validation set after preprocessing: {X_val_preprocessed.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cell 5: Handle Imbalanced Data and Verify Memory Reduction\n",
    "# logger.info(\"Handling imbalanced data using SMOTE and verifying memory reduction...\")\n",
    "\n",
    "# # Handle imbalanced data using SMOTE on the training data\n",
    "# smote = SMOTE()\n",
    "# X_train_resampled, y_train_resampled = smote.fit_resample(X_train_preprocessed, y_train)\n",
    "\n",
    "# logger.info(f\"Training data resampled using SMOTE. New shape: {X_train_resampled.shape}\")\n",
    "\n",
    "# # Verify and reduce memory usage after SMOTE\n",
    "# X_train_resampled = reduce_memory_usage(pd.DataFrame(X_train_resampled))\n",
    "# X_val_preprocessed = reduce_memory_usage(pd.DataFrame(X_val_preprocessed))\n",
    "\n",
    "# logger.info(f\"Training data shape after memory reduction: {X_train_resampled.shape}\")\n",
    "# logger.info(f\"Validation data shape after memory reduction: {X_val_preprocessed.shape}\")\n",
    "\n",
    "# # Save Transformed Data\n",
    "# def save_csv(dataframe, filename):\n",
    "#     if os.path.exists(filename):\n",
    "#         os.remove(filename)\n",
    "#     dataframe.to_csv(filename, index=False)\n",
    "\n",
    "# save_csv(X_train_resampled, 'X_train_transformed_reduced.csv')\n",
    "# save_csv(X_val_preprocessed, 'X_val_transformed_reduced.csv')\n",
    "# save_csv(pd.DataFrame(y_train_resampled), 'y_train_transformed_reduced.csv')\n",
    "# save_csv(pd.DataFrame(y_val), 'y_val_transformed_reduced.csv')\n",
    "\n",
    "# logger.info(\"Transformed datasets saved to CSV files with reduced memory usage\")\n",
    "\n",
    "# If needed, load the transformed datasets from CSV\n",
    "X_train_resampled = pd.read_csv('X_train_transformed_reduced.csv')\n",
    "X_val_preprocessed = pd.read_csv('X_val_transformed_reduced.csv')\n",
    "y_train_resampled = pd.read_csv('y_train_transformed_reduced.csv')\n",
    "y_val = pd.read_csv('y_val_transformed_reduced.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 20:25:50,079 - __main__ - INFO - Running Bayesian search for hyperparameter tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:548: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7053240474255384, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7053240474255384\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.715713262107033, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.715713262107033\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9038520725066866, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9038520725066866\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7599106883214346, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7599106883214346\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7053240474255384, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7053240474255384\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.715713262107033, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.715713262107033\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9038520725066866, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9038520725066866\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7599106883214346, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7599106883214346\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 8043116, number of negative: 8043116\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.509388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4356\n",
      "[LightGBM] [Info] Number of data points in the train set: 16086232, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 20:35:39,864 - __main__ - INFO - Best AUC: 0.9486205614107845\n",
      "2024-07-13 20:35:39,865 - __main__ - INFO - Best parameters: OrderedDict({'bagging_fraction': 0.7599106883214346, 'bagging_freq': 4, 'feature_fraction': 0.7053240474255384, 'lambda_l1': 0.715713262107033, 'lambda_l2': 0.9038520725066866, 'learning_rate': 0.0801921805811886, 'max_depth': 12, 'min_data_in_leaf': 36, 'num_leaves': 81})\n",
      "c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\paulo\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7053240474255384, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7053240474255384\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.715713262107033, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.715713262107033\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9038520725066866, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9038520725066866\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7599106883214346, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7599106883214346\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7053240474255384, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7053240474255384\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.715713262107033, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.715713262107033\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9038520725066866, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9038520725066866\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7599106883214346, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7599106883214346\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 8043116, number of negative: 8043116\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.562137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4356\n",
      "[LightGBM] [Info] Number of data points in the train set: 16086232, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 20:36:38,853 - __main__ - INFO - Bayesian search complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Run Bayesian Search for Hyperparameter Tuning\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "logger.info(\"Running Bayesian search for hyperparameter tuning...\")\n",
    "\n",
    "def run_bayesian_search(X_train, y_train):\n",
    "    # Define the parameter grid\n",
    "    param_dist = {\n",
    "        'learning_rate': (0.03, 0.1),\n",
    "        'num_leaves': (60, 120),\n",
    "        'max_depth': (10, 15),\n",
    "        'min_data_in_leaf': (10, 50),\n",
    "        'bagging_fraction': (0.6, 0.8),\n",
    "        'feature_fraction': (0.6, 0.8),\n",
    "        'lambda_l1': (0.0, 1.0),\n",
    "        'lambda_l2': (0.0, 1.0),\n",
    "        'bagging_freq': (1, 7)\n",
    "    }\n",
    "\n",
    "    # Initialize the LightGBM classifier\n",
    "    lgb_model = lgb.LGBMClassifier(objective='binary', metric='auc')\n",
    "\n",
    "    # Define the scoring function\n",
    "    scorer = make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)\n",
    "\n",
    "    # Initialize BayesSearchCV\n",
    "    bayes_search = BayesSearchCV(\n",
    "        estimator=lgb_model,\n",
    "        search_spaces=param_dist,\n",
    "        n_iter=5,  # Number of iterations for the search\n",
    "        scoring=scorer,\n",
    "        cv=3,  # 3-fold cross-validation\n",
    "        random_state=42,\n",
    "        verbose=2,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Fit BayesSearchCV\n",
    "    bayes_search.fit(X_train, y_train)\n",
    "\n",
    "    return bayes_search.best_estimator_, bayes_search.best_params_, bayes_search.best_score_\n",
    "\n",
    "# Run Bayesian Search\n",
    "best_model, best_params, best_score = run_bayesian_search(X_train_resampled, y_train_resampled)\n",
    "\n",
    "logger.info(f\"Best AUC: {best_score}\")\n",
    "logger.info(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Save the best trial parameters\n",
    "pd.DataFrame([best_params]).to_csv('best_params_bayesiansearch.csv', index=False)\n",
    "\n",
    "# Load the best parameters from the saved file (if needed)\n",
    "best_params_loaded = pd.read_csv('best_params_bayesiansearch.csv').to_dict(orient='records')[0]\n",
    "\n",
    "# Optionally, you can refit the model on the entire training set using the best parameters\n",
    "best_model_retrained = lgb.LGBMClassifier(**best_params_loaded)\n",
    "best_model_retrained.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "logger.info(\"Bayesian search complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 20:36:38,886 - __main__ - INFO - Evaluating model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7053240474255384, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7053240474255384\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.715713262107033, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.715713262107033\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9038520725066866, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9038520725066866\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7599106883214346, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7599106883214346\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7053240474255384, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7053240474255384\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.715713262107033, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.715713262107033\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9038520725066866, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9038520725066866\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7599106883214346, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7599106883214346\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 20:37:08,139 - __main__ - INFO - Training AUC with best parameters: 0.9493483645407668\n",
      "2024-07-13 20:37:08,139 - __main__ - INFO - Validation AUC with best parameters: 0.8627342805093273\n",
      "2024-07-13 20:37:08,139 - __main__ - WARNING - Overfitting detected: Train AUC - 0.9493483645407668, Val AUC - 0.8627342805093273, Difference - 0.08661408403143944\n",
      "2024-07-13 20:37:08,150 - __main__ - INFO - Model evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Model Evaluation\n",
    "logger.info(\"Evaluating model...\")\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_val, y_val):\n",
    "    # Evaluate the best model on the training set\n",
    "    train_preds = model.predict_proba(X_train)[:, 1]\n",
    "    train_auc = roc_auc_score(y_train, train_preds)\n",
    "\n",
    "    # Evaluate the best model on the validation set\n",
    "    val_preds = model.predict_proba(X_val)[:, 1]\n",
    "    val_auc = roc_auc_score(y_val, val_preds)\n",
    "\n",
    "    logger.info(f\"Training AUC with best parameters: {train_auc}\")\n",
    "    logger.info(f\"Validation AUC with best parameters: {val_auc}\")\n",
    "\n",
    "    # Check for overfitting\n",
    "    overfit_threshold = 0.05  # Adjust the threshold as needed\n",
    "    overfit_metric = abs(train_auc - val_auc)\n",
    "    if overfit_metric > overfit_threshold:\n",
    "        logger.warning(f\"Overfitting detected: Train AUC - {train_auc}, Val AUC - {val_auc}, Difference - {overfit_metric}\")\n",
    "    else:\n",
    "        logger.info(f\"No overfitting detected: Train AUC - {train_auc}, Val AUC - {val_auc}, Difference - {overfit_metric}\")\n",
    "\n",
    "    return train_auc, val_auc\n",
    "\n",
    "# Evaluate the best model\n",
    "train_auc, val_auc = evaluate_model(best_model_retrained, X_train_resampled, y_train_resampled, X_val_preprocessed, y_val)\n",
    "\n",
    "logger.info(\"Model evaluation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 20:37:08,167 - __main__ - INFO - Training final model with callbacks...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.440411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4356\n",
      "[LightGBM] [Info] Number of data points in the train set: 16086232, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.0920605\tvalid_1's l2: 0.11835\n",
      "Evaluated only: l2\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Train Final Model with Callbacks\n",
    "logger.info(\"Training final model with callbacks...\")\n",
    "\n",
    "def train_final_model(params, X_train, y_train, X_val, y_val):\n",
    "    # Create LightGBM datasets\n",
    "    train_data = lgb.Dataset(X_train, label=y_train, free_raw_data=False)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data, free_raw_data=False)\n",
    "\n",
    "    # Define the early stopping callback\n",
    "    early_stopping_callback = lgb.early_stopping(stopping_rounds=20, first_metric_only=True, verbose=True)\n",
    "\n",
    "    # Train the LightGBM model with the best parameters\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=200,\n",
    "        valid_sets=[train_data, val_data],\n",
    "        callbacks=[early_stopping_callback],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Train the final model\n",
    "final_model = train_final_model(best_params_loaded, X_train_resampled, y_train_resampled, X_val_preprocessed, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 20:38:36,862 - __main__ - INFO - Saving model and metrics...\n",
      "2024-07-13 20:39:11,702 - __main__ - INFO - Final Train AUC: 0.9521649122773773\n",
      "2024-07-13 20:39:11,703 - __main__ - INFO - Final Validation AUC: 0.8610571035742743\n",
      "2024-07-13 20:39:11,766 - __main__ - INFO - Feature importance saved as feature_importance.csv\n",
      "2024-07-13 20:39:12,916 - __main__ - INFO - Feature importance plot saved as feature_importance.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 20:39:13,087 - __main__ - INFO - Model saved as lightgbm_model_best.pkl\n",
      "2024-07-13 20:39:13,099 - __main__ - INFO - Model metrics saved as model_metrics.csv\n",
      "2024-07-13 20:39:13,099 - __main__ - INFO - Training and evaluation process completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Save Model and Metrics\n",
    "logger.info(\"Saving model and metrics...\")\n",
    "\n",
    "def save_csv(dataframe, filename):\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "    dataframe.to_csv(filename, index=False)\n",
    "\n",
    "def save_model_and_metrics(model, train_auc, val_auc):\n",
    "    # Predict on train and validation set\n",
    "    y_train_pred = model.predict(X_train_resampled, num_iteration=model.best_iteration)\n",
    "    y_val_pred = model.predict(X_val_preprocessed, num_iteration=model.best_iteration)\n",
    "\n",
    "    # Evaluation metrics\n",
    "    train_auc = roc_auc_score(y_train_resampled, y_train_pred)\n",
    "    val_auc = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "    logger.info(f\"Final Train AUC: {train_auc}\")\n",
    "    logger.info(f\"Final Validation AUC: {val_auc}\")\n",
    "\n",
    "    # Feature Importance\n",
    "    importance = model.feature_importance(importance_type='split')\n",
    "    feature_names = model.feature_name()\n",
    "\n",
    "    # Create a DataFrame for feature importance\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importance\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Save feature importance to CSV\n",
    "    save_csv(feature_importance_df, \"feature_importance.csv\")\n",
    "    logger.info(\"Feature importance saved as feature_importance.csv\")\n",
    "\n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(data=feature_importance_df, x='Importance', y='Feature')\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.title(\"Feature Importance\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.savefig(\"feature_importance.png\")\n",
    "    logger.info(\"Feature importance plot saved as feature_importance.png\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Save the model and metrics\n",
    "    if os.path.exists(\"lightgbm_model_best.pkl\"):\n",
    "        os.remove(\"lightgbm_model_best.pkl\")\n",
    "    joblib.dump(model, \"lightgbm_model_best.pkl\")\n",
    "    logger.info(\"Model saved as lightgbm_model_best.pkl\")\n",
    "\n",
    "    # Save the metrics to a CSV file\n",
    "    metrics = {\n",
    "        \"train_auc\": train_auc,\n",
    "        \"val_auc\": val_auc\n",
    "    }\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics, index=[0])\n",
    "    save_csv(metrics_df, \"model_metrics.csv\")\n",
    "    logger.info(\"Model metrics saved as model_metrics.csv\")\n",
    "\n",
    "    # Final log message\n",
    "    logger.info(\"Training and evaluation process completed successfully.\")\n",
    "\n",
    "# Save the model and metrics\n",
    "save_model_and_metrics(final_model, train_auc, val_auc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
