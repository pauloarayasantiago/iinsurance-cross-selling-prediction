{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import gc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from scipy.optimize import minimize\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a log filename with the notebook name and current datetime\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_filename = f'kaggle_submission_{current_time}.log'\n",
    "\n",
    "# Configure logging to save to a file\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filename),\n",
    "        logging.StreamHandler()  # This ensures logs are also output to the console\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.\"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        logging.info(f'Start memory usage of dataframe: {start_mem:.2f} MB')\n",
    "\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        logging.info(f'End memory usage of dataframe: {end_mem:.2f} MB')\n",
    "        logging.info(f'Decreased by {(100 * (start_mem - end_mem) / start_mem):.1f}%')\n",
    "\n",
    "    return df\n",
    "\n",
    "def safe_map(df, column, mapping):\n",
    "    \"\"\"Map categorical values to numerical values and log any unknown categories.\"\"\"\n",
    "    unknown_categories = set(df[column]) - set(mapping.keys())\n",
    "    if unknown_categories:\n",
    "        logging.warning(f\"Unknown categories in column {column}: {unknown_categories}\")\n",
    "    df[column] = df[column].map(mapping)\n",
    "    return df\n",
    "\n",
    "def import_data(file, **kwargs):\n",
    "    \"\"\"Create a dataframe and optimize its memory usage.\"\"\"\n",
    "    df = pd.read_csv(file, parse_dates=True, keep_date_col=True, **kwargs)\n",
    "    df = reduce_mem_usage(df)\n",
    "    return df\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the dataset.\"\"\"\n",
    "    gender_mapping = {'Male': 1, 'Female': 0}\n",
    "    vehicle_damage_mapping = {'Yes': 1, 'No': 0}\n",
    "    vehicle_age_mapping = {'< 1 Year': 0, '1-2 Year': 1, '> 2 Years': 2}\n",
    "    \n",
    "    df = safe_map(df, 'Gender', gender_mapping)\n",
    "    df = safe_map(df, 'Vehicle_Damage', vehicle_damage_mapping)\n",
    "    df = safe_map(df, 'Vehicle_Age', vehicle_age_mapping)\n",
    "    \n",
    "    df.drop(['Driving_License'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def feature_engineering(df):\n",
    "    \"\"\"Feature engineering on the dataset.\"\"\"\n",
    "    df['Previously_Insured_Annual_Premium'] = pd.factorize((df['Previously_Insured'].astype(str) + df['Annual_Premium'].astype(str)))[0]\n",
    "    df['Previously_Insured_Vehicle_Age'] = pd.factorize((df['Previously_Insured'].astype(str) + df['Vehicle_Age'].astype(str)))[0]\n",
    "    df['Previously_Insured_Vehicle_Damage'] = pd.factorize((df['Previously_Insured'].astype(str) + df['Vehicle_Damage'].astype(str)))[0]\n",
    "    df['Previously_Insured_Vintage'] = pd.factorize((df['Previously_Insured'].astype(str) + df['Vintage'].astype(str)))[0]\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 15:47:53,040 - INFO - Start memory usage of dataframe: 1053.30 MB\n",
      "2024-07-25 15:47:54,721 - INFO - End memory usage of dataframe: 318.18 MB\n",
      "2024-07-25 15:47:54,722 - INFO - Decreased by 69.8%\n",
      "2024-07-25 15:48:04,902 - INFO - Start memory usage of dataframe: 643.68 MB\n",
      "2024-07-25 15:48:06,038 - INFO - End memory usage of dataframe: 204.81 MB\n",
      "2024-07-25 15:48:06,040 - INFO - Decreased by 68.2%\n",
      "2024-07-25 15:48:06,151 - INFO - Data loaded successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after import: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 15:48:08,106 - INFO - Data preprocessed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after preprocessing: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 15:48:41,630 - INFO - Feature engineering completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after feature engineering: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Paths to datasets\n",
    "train_path = r\"C:\\Users\\paulo\\OneDrive\\Documents\\kaggle_competition_2_datasets\\train.csv\"\n",
    "test_path = r\"C:\\Users\\paulo\\OneDrive\\Documents\\kaggle_competition_2_datasets\\test.csv\"\n",
    "\n",
    "# Load and optimize data\n",
    "train_df = import_data(train_path, index_col='id')\n",
    "test_df = import_data(test_path, index_col='id')\n",
    "\n",
    "gc.collect()\n",
    "print(f\"DataFrame after import: {type(train_df)}\")\n",
    "logging.info(\"Data loaded successfully.\")\n",
    "\n",
    "# Apply preprocessing\n",
    "train_df = preprocess_data(train_df)\n",
    "test_df = preprocess_data(test_df)\n",
    "print(f\"DataFrame after preprocessing: {type(train_df)}\")\n",
    "logging.info(\"Data preprocessed successfully.\")\n",
    "\n",
    "# Apply feature engineering\n",
    "train_df = feature_engineering(train_df)\n",
    "test_df = feature_engineering(test_df)\n",
    "\n",
    "gc.collect()\n",
    "print(f\"DataFrame after feature engineering: {type(train_df)}\")\n",
    "logging.info(\"Feature engineering completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['Age', 'Region_Code', 'Annual_Premium', 'Policy_Sales_Channel', 'Vintage']\n",
    "scaler = StandardScaler()\n",
    "train_df[num_cols] = scaler.fit_transform(train_df[num_cols])\n",
    "test_df[num_cols] = scaler.transform(test_df[num_cols])\n",
    "\n",
    "# Separate features and target variable\n",
    "X = train_df.drop('Response', axis=1)\n",
    "y = train_df['Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-25 15:48:43,261] A new study created in memory with name: no-name-c5cbef46-8686-4075-a95b-057a45e5fd34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1132047, number of negative: 8071791\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 9203838, number of used features: 13\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2070 SUPER, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (140.44 MB) transferred to GPU in 0.131377 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import numpy as np\n",
    "import gc\n",
    "import logging\n",
    "\n",
    "# Define the objective function for the Optuna study\n",
    "def objective(trial):\n",
    "    # Define parameter search space with realistic ranges\n",
    "    lgb_params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-2, 10.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-2, 10.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 15),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 50),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 20, 200),\n",
    "        'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10.0),\n",
    "        'min_split_gain': trial.suggest_loguniform('min_split_gain', 1e-3, 1.0),\n",
    "        'max_bin': trial.suggest_int('max_bin', 100, 300),\n",
    "        'device': 'gpu',\n",
    "        'early_stopping_round': 50\n",
    "    }\n",
    "\n",
    "    # Suggest number of boosting rounds\n",
    "    num_boost_round = trial.suggest_int('num_boost_round', 2500, 5000)\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
    "\n",
    "    # Train the model\n",
    "    model = lgb.train(\n",
    "        lgb_params,\n",
    "        train_data,\n",
    "        num_boost_round=num_boost_round,\n",
    "        valid_sets=[train_data, valid_data],\n",
    "    )\n",
    "\n",
    "    # Predict and calculate AUC score\n",
    "    valid_preds = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    auc_score = roc_auc_score(y_valid, valid_preds)\n",
    "\n",
    "    # Save the model from this trial\n",
    "    joblib.dump(model, f'model_trial_{trial.number}.pkl')\n",
    "\n",
    "    return auc_score\n",
    "\n",
    "# Create and optimize the study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best parameters and AUC score\n",
    "best_params = study.best_params\n",
    "best_score = study.best_value\n",
    "\n",
    "logging.info(f\"Best AUC score: {best_score:.6f}\")\n",
    "logging.info(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Load the best model\n",
    "best_model = joblib.load(f'model_trial_{study.best_trial.number}.pkl')\n",
    "\n",
    "# Predict on the test set\n",
    "test_pred = best_model.predict(test_df, num_iteration=best_model.best_iteration)\n",
    "joblib.dump(test_pred, 'test_pred_lgb.pkl')\n",
    "\n",
    "logging.info(\"Final LightGBM model and predictions saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df.index,\n",
    "    'Response': test_pred\n",
    "})\n",
    "\n",
    "# Save the submission file\n",
    "submission_filename = f'submission_{current_time}.csv'\n",
    "submission.to_csv(submission_filename, index=False)\n",
    "\n",
    "logging.info(f\"Submission file {submission_filename} created successfully.\")\n",
    "print(f\"Submission file {submission_filename} created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optuna.visualization.plot_intermediate_values(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optuna.visualization.plot_contour(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optuna.visualization.plot_param_importances(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optuna.visualization.plot_slice(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optuna.visualization.plot_edf(study)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
