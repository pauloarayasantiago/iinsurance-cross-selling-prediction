{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import klib\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from datetime import datetime\n",
    "import os\n",
    "import warnings\n",
    "import gc\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a log filename with the notebook name and current datetime\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_filename = f'kaggle_submission_{current_time}.log'\n",
    "\n",
    "# Configure logging to save to a file\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filename),\n",
    "        logging.StreamHandler()  # This ensures logs are also output to the console\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def import_data(file, **kwargs):\n",
    "    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n",
    "    df = pd.read_csv(file, parse_dates=True, keep_date_col=True, **kwargs)\n",
    "    df = reduce_mem_usage(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1053.30 MB\n",
      "Memory usage after optimization is: 274.30 MB\n",
      "Decreased by 74.0%\n",
      "Memory usage of dataframe is 643.68 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 13:27:18,671 - INFO - Data loaded successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 175.55 MB\n",
      "Decreased by 72.7%\n"
     ]
    }
   ],
   "source": [
    "# Paths to datasets\n",
    "train_path = r\"C:\\Users\\paulo\\OneDrive\\Documents\\kaggle_competition_2_datasets\\train.csv\"\n",
    "test_path = r\"C:\\Users\\paulo\\OneDrive\\Documents\\kaggle_competition_2_datasets\\test.csv\"\n",
    "\n",
    "# Load and optimize data\n",
    "train_df = import_data(train_path, index_col='id')\n",
    "test_df = import_data(test_path, index_col='id')\n",
    "\n",
    "gc.collect()\n",
    "logging.info(\"Data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 13:27:19,073 - INFO - Data preprocessed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Preprocess data\n",
    "def preprocess_data(df):\n",
    "    df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})\n",
    "    df['Vehicle_Damage'] = df['Vehicle_Damage'].map({'Yes': 1, 'No': 0})\n",
    "    vehicle_age_mapping = {'< 1 Year': 0, '1-2 Year': 1, '> 2 Years': 2}\n",
    "    df['Vehicle_Age'] = df['Vehicle_Age'].map(vehicle_age_mapping)\n",
    "    df.drop(['Driving_License'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Apply preprocessing\n",
    "train_df = preprocess_data(train_df)\n",
    "test_df = preprocess_data(test_df)\n",
    "logging.info(\"Data preprocessed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove outliers\n",
    "# def remove_outliers_iqr(df, column):\n",
    "#     Q1 = df[column].quantile(0.25)\n",
    "#     Q3 = df[column].quantile(0.75)\n",
    "#     IQR = Q3 - Q1\n",
    "#     lower_bound = Q1 - 1.5 * IQR\n",
    "#     upper_bound = Q3 + 1.5 * IQR\n",
    "#     return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "# # Apply outlier removal\n",
    "# train_df = remove_outliers_iqr(train_df, 'Annual_Premium')\n",
    "# logging.info(\"Outliers removed successfully.\")\n",
    "# logging.info(f\"Train dataset size after outlier removal: {train_df.shape}\")\n",
    "# logging.info(f\"Train dataset columns after outlier removal:\\n{train_df.dtypes}\")\n",
    "# logging.info(f\"Train dataset missing values after outlier removal:\\n{train_df.isnull().sum()}\")\n",
    "# logging.info(f\"Train dataset descriptive statistics after outlier removal:\\n{train_df.describe(include='all')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 13:27:52,852 - INFO - Feature engineering completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering\n",
    "def feature_engineering(df):\n",
    "    df = df.copy()\n",
    "    df['Previously_Insured_Annual_Premium'] = pd.factorize((df['Previously_Insured'].astype(str) + df['Annual_Premium'].astype(str)))[0]\n",
    "    df['Previously_Insured_Vehicle_Age'] = pd.factorize((df['Previously_Insured'].astype(str) + df['Vehicle_Age'].astype(str)))[0]\n",
    "    df['Previously_Insured_Vehicle_Damage'] = pd.factorize((df['Previously_Insured'].astype(str) + df['Vehicle_Damage'].astype(str)))[0]\n",
    "    df['Previously_Insured_Vintage'] = pd.factorize((df['Previously_Insured'].astype(str) + df['Vintage'].astype(str)))[0]\n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "train_df = feature_engineering(train_df)\n",
    "test_df = feature_engineering(test_df)\n",
    "\n",
    "gc.collect()\n",
    "logging.info(\"Feature engineering completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 13:27:55,810 - INFO - Features and target variable separated and scaled.\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target variable\n",
    "X = train_df.drop('Response', axis=1).values\n",
    "y = train_df['Response'].values\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "test_df_scaled = scaler.transform(test_df.values)\n",
    "\n",
    "gc.collect()\n",
    "logging.info(f\"Features and target variable separated and scaled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Stratified K-Folds\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LightGBM model with validation within each fold\n",
    "def train_lgbm_with_validation(X_train, y_train, params, num_boost_round=1000):\n",
    "    X_train_split, X_valid_split, y_train_split, y_valid_split = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train_split, label=y_train_split)\n",
    "    valid_data = lgb.Dataset(X_valid_split, label=y_valid_split, reference=train_data)\n",
    "    \n",
    "    # Include early_stopping_rounds in the parameter dictionary\n",
    "    params['early_stopping_rounds'] = 100\n",
    "    \n",
    "    bst = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=num_boost_round,\n",
    "        valid_sets=[train_data, valid_data],\n",
    "    )\n",
    "    \n",
    "    gc.collect()\n",
    "    valid_preds = bst.predict(X_valid_split, num_iteration=bst.best_iteration)\n",
    "    auc_score = roc_auc_score(y_valid_split, valid_preds)\n",
    "    logging.info(f'Validation AUC score: {auc_score}')\n",
    "    return bst, bst.best_iteration\n",
    "\n",
    "# Define LightGBM parameters\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'reg_alpha': 0.03432385172267505,\n",
    "    'reg_lambda': 0.2998279059616829,\n",
    "    'colsample_bytree': 0.790292183596673,\n",
    "    'subsample': 0.9046878168822107,\n",
    "    'learning_rate': 0.05035039561309864,\n",
    "    'max_depth': 29,\n",
    "    'num_leaves': 1474,\n",
    "    'min_child_samples': 75,\n",
    "    'min_child_weight': 7.661448090878849,\n",
    "    'min_split_gain': 0.09978597066868167,\n",
    "    'max_bin': 499,\n",
    "    'n_jobs': 8,\n",
    "    'early_stopping_rounds': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Fold 1 ----\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 905638, number of negative: 6457432\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.181401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2029\n",
      "[LightGBM] [Info] Number of data points in the train set: 7363070, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964347\n",
      "[LightGBM] [Info] Start training from score -1.964347\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store out-of-fold predictions and AUC scores\n",
    "oof_preds = []\n",
    "oof_aucs = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for fold, (train_idx, test_idx) in enumerate(skfold.split(X_scaled, y)):\n",
    "    print(f\"\\n---- Fold {fold + 1} ----\\n\")\n",
    "    \n",
    "    X_train, y_train = X_scaled[train_idx], y[train_idx]\n",
    "    X_valid, y_valid = X_scaled[test_idx], y[test_idx]\n",
    "    \n",
    "    # Train the model with validation to find the best iteration\n",
    "    model, best_iteration = train_lgbm_with_validation(X_train, y_train, params)\n",
    "    logging.info(f\"Best iteration found: {best_iteration}\")\n",
    "\n",
    "    # Predict on validation set\n",
    "    valid_preds = model.predict(X_valid, num_iteration=best_iteration)\n",
    "    auc_score = roc_auc_score(y_valid, valid_preds)\n",
    "    oof_aucs.append(auc_score)\n",
    "    print(f\"Validation AUC score for fold {fold + 1}: {auc_score:.6f}\")\n",
    "    \n",
    "    # Predict on test set\n",
    "    test_pred = model.predict(test_df_scaled, num_iteration=best_iteration)\n",
    "    oof_preds.append(test_pred)\n",
    "    \n",
    "    # Clean up to free memory\n",
    "    del X_train, y_train, X_valid, y_valid, model\n",
    "    gc.collect()\n",
    "\n",
    "# Calculate overall AUC score\n",
    "auc_mean = np.mean(oof_aucs)\n",
    "auc_std = np.std(oof_aucs)\n",
    "print(f\"\\n---> Overall ROC-AUC Score: {auc_mean:.6f} Â± {auc_std:.6f}\\n\")\n",
    "\n",
    "# Average the predictions from each fold\n",
    "test_pred_lgb = np.mean(oof_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions to a submission file\n",
    "submission = pd.DataFrame({'id': test_df.index, 'Response': test_pred_lgb})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Submission file created successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
